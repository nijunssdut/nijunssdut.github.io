<!DOCTYPE html>












  


<html class="theme-next gemini use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">






















<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">

<link rel="stylesheet" href="/css/main.css?v=7.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.2.0">


  <link rel="mask-icon" href="/images/logo.svg?v=7.2.0" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.2.0',
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false,"dimmer":false},
    back2top: true,
    back2top_sidebar: false,
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="GBDTGBDT是集成学习Boosting的一种。Gradient Boosting的主要的思想是，每一次建立单个学习器时，是在之前建立的模型的损失函数的梯度下降方向。损失函数越大，说明模型越容易出错，如果我们的模型能够让损失函数持续下降，则说明我们的模型在不停的改进，而最好的方式就是让损失函数在其梯度的方向上下降。 GBDT的核心就在于，每一棵树学的是之前所有树结论和的残差，这个残差就是一个加预">
<meta name="keywords" content="集成学习,监督学习,GBDT,XGBoost">
<meta property="og:type" content="article">
<meta property="og:title" content="集成学习专题（二）">
<meta property="og:url" content="http://nijunssdut.github.io/passages/2019-07-30-集成学习专题（二）/index.html">
<meta property="og:site_name" content="Jun的个人随笔">
<meta property="og:description" content="GBDTGBDT是集成学习Boosting的一种。Gradient Boosting的主要的思想是，每一次建立单个学习器时，是在之前建立的模型的损失函数的梯度下降方向。损失函数越大，说明模型越容易出错，如果我们的模型能够让损失函数持续下降，则说明我们的模型在不停的改进，而最好的方式就是让损失函数在其梯度的方向上下降。 GBDT的核心就在于，每一棵树学的是之前所有树结论和的残差，这个残差就是一个加预">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://nijunssdut.github.io/passages/2019-07-30-集成学习专题（二）/GBDT-Feature.jpg">
<meta property="og:image" content="http://nijunssdut.github.io/passages/2019-07-30-集成学习专题（二）/XGBoost.png">
<meta property="og:image" content="http://nijunssdut.github.io/passages/2019-07-30-集成学习专题（二）/XGBoost%E7%BC%BA%E5%A4%B1%E5%80%BC%E5%A4%84%E7%90%86.png">
<meta property="og:updated_time" content="2019-07-31T11:50:29.379Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="集成学习专题（二）">
<meta name="twitter:description" content="GBDTGBDT是集成学习Boosting的一种。Gradient Boosting的主要的思想是，每一次建立单个学习器时，是在之前建立的模型的损失函数的梯度下降方向。损失函数越大，说明模型越容易出错，如果我们的模型能够让损失函数持续下降，则说明我们的模型在不停的改进，而最好的方式就是让损失函数在其梯度的方向上下降。 GBDT的核心就在于，每一棵树学的是之前所有树结论和的残差，这个残差就是一个加预">
<meta name="twitter:image" content="http://nijunssdut.github.io/passages/2019-07-30-集成学习专题（二）/GBDT-Feature.jpg">





  
  
  <link rel="canonical" href="http://nijunssdut.github.io/passages/2019-07-30-集成学习专题（二）/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>集成学习专题（二） | Jun的个人随笔</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Jun的个人随笔</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>

      
      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>搜索</a>
        </li>
      
    </ul>
  

  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://nijunssdut.github.io/passages/2019-07-30-集成学习专题（二）/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="NI,JUN">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jun的个人随笔">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">集成学习专题（二）

              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-07-30 18:34:00" itemprop="dateCreated datePublished" datetime="2019-07-30T18:34:00+08:00">2019-07-30</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-07-31 19:50:29" itemprop="dateModified" datetime="2019-07-31T19:50:29+08:00">2019-07-31</time>
              </span>
            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="GBDT"><a href="#GBDT" class="headerlink" title="GBDT"></a>GBDT</h1><p>GBDT是集成学习Boosting的一种。Gradient Boosting的主要的思想是，每一次建立单个学习器时，是在之前建立的模型的损失函数的梯度下降方向。损失函数越大，说明模型越容易出错，如果我们的模型能够让损失函数持续下降，则说明我们的模型在不停的改进，而<strong>最好的方式就是让损失函数在其梯度的方向上下降</strong>。</p>
<p>GBDT的核心就在于，每一棵树学的是之前所有树结论和的残差，这个残差就是一个加预测值后能得真实值的累加量。所以为了得到残差，<strong>GBDT中的树都是回归树，不是分类树。</strong></p>
<h2 id="GBDT的算法流程"><a href="#GBDT的算法流程" class="headerlink" title="GBDT的算法流程"></a>GBDT的算法流程</h2><p>输入是训练集样本，最大迭代次数T，每轮迭代输入数据是训练集<strong>无放回采样样本</strong>，损失函数L。</p>
<ol>
<li>初始化弱学习器。</li>
</ol>
<p>$$<br>T(x;\theta_m)<br>$$</p>
<p>T表示决策树，x为输入样本，$\theta_m$为树分裂参数。</p>
<ol start="2">
<li>对迭代轮数m = 1,2,…,T有：</li>
</ol>
<p>（a）计算各个叶子区域损失函数L的负梯度值，将它作为残差的估计<br>$$<br>r_{mi} = -[\frac{\partial L(y,f(x_i))}{\partial f(x_i)}]<em>{f(x)=f</em>{m-1}(x)}<br>$$<br>（b）对$r_{mi}$拟合为一颗新的回归树，根据新的回归树得到m轮产生的叶子节点区域</p>
<p>（c）遍历回归树所有叶子节点区域，在各个区域使损失函数极小化找到残差</p>
<p>（d）更新强学习器</p>
<ol start="3">
<li>得到输出的最终模型</li>
</ol>
<p>$$<br>f_M(x) = \sum_{m =1}^M T(x;\theta_m)<br>$$</p>
<h2 id="GBDT常用的损失函数"><a href="#GBDT常用的损失函数" class="headerlink" title="GBDT常用的损失函数"></a>GBDT常用的损失函数</h2><p>对于分类算法，其损失函数一般有两种：</p>
<p>（1） 指数损失函数：$L(y,h(x)) = \exp(-yh(x))$</p>
<p>（2） 对数损失函数：分为二元分类和多元分类两种。</p>
<ul>
<li>对于二元分类：$L(y,h(x)) = \log(1+\exp(-yh(x)))$</li>
<li>对于多元分类：设类别数为k， $L(y_k,h(x)) = -\sum_{k=1}^Ky_k\log(p_k(x))$，$y_k$为样本数据估计值，当一个样本x属于k时，$y_k=1$，否则$y_k=0$</li>
</ul>
<p>对于回归算法，常用损失函数有4种：</p>
<ol>
<li><p>均方差：$L(y,h(x)) =(y-h(x))^2$</p>
</li>
<li><p>绝对损失：$L(y,h(x)) = |y-h(x)|$</p>
</li>
<li><p>Huber损失：它是均方差和绝对损失的折衷产物，对于远离中心的异常点，采用绝对损失，而中心附近的点采用均方差。这个界限一般用分位数点度量<br>$$<br>L(y,f(x))= \begin{cases}<br> \frac{1}{2}(y-f(x))^2&amp;|y-f(x)|\le \delta\<br> \delta(|y-f(x)|-\frac{\delta}{2})&amp;|y-f(x)|\gt \delta<br>\end{cases}<br>$$</p>
</li>
<li><p>分位树损失：它对应的是分位数回归的损失函数。</p>
</li>
</ol>
<p>$$<br>L(y,f(x)) = \sum_{y\ge f(x)}\theta|y-f(x)|+\sum_{y\lt f(x)}(1-\theta)|y-f(x)|<br>$$</p>
<h2 id="GBDT中为什么用负梯度来拟合残差计算"><a href="#GBDT中为什么用负梯度来拟合残差计算" class="headerlink" title="GBDT中为什么用负梯度来拟合残差计算"></a>GBDT中为什么用负梯度来拟合残差计算</h2><p>其实除了均方误差的情况一阶导是残差外，其他的情况没有残差的概念，GBDT每一轮拟合的都是损失函数负梯度。</p>
<p><strong>使用梯度计算代替的主要原因是为了将GBDT扩展到更复杂的损失函数中。</strong></p>
<p>当损失函数形式简单，可以认为$y^{‘}（模型输出值）= y（实际值）$时损失函数最小，但当损失函数加入了正则项后，并非$y^{‘}=y$时损失函数取得最小值，所以我们需要计算损失函数的梯度，而不能直接使用模型来计算残差。</p>
<h2 id="GBDT不适合使用高维稀疏特征的原因"><a href="#GBDT不适合使用高维稀疏特征的原因" class="headerlink" title="GBDT不适合使用高维稀疏特征的原因"></a>GBDT不适合使用高维稀疏特征的原因</h2><ol>
<li>特征太多，GBDT不一定跑的动，即使可以跑也会耗费时间，因为在每一次分割时需要比较大量的特征。</li>
<li>树的分割往往只考虑了少量特征，大部分特征用不到，少量的特征在多次分裂时被重复用到，剩余的长尾基本用不到，所有高维稀疏特征会造成大量特征的浪费。</li>
</ol>
<h2 id="GBDT减少误差的方式"><a href="#GBDT减少误差的方式" class="headerlink" title="GBDT减少误差的方式"></a>GBDT减少误差的方式</h2><p>机器学习算法的误差分为偏差和方差两个部分。</p>
<p>GBDT迭代每一步都在拟合当前模型预测值和真实值之间的偏差，通过不断的迭代使偏差减小，所以只要选取方差较小的模型作为基分类器，GBDT就可以很好的减小预测误差。</p>
<h2 id="GBDT的优缺点"><a href="#GBDT的优缺点" class="headerlink" title="GBDT的优缺点"></a>GBDT的优缺点</h2><p><strong>GBDT主要的优点有：</strong></p>
<p>（1）可以灵活处理各种类型的数据，包括连续值和离散值。</p>
<p>（2）在相对少的调参时间情况下，预测的准确率也可以比较高</p>
<p>（3）使用一些健壮的损失函数，对异常值的鲁棒性非常强，比如Huber损失函数和Quantile损失函数</p>
<p><strong>GBDT的主要缺点有：</strong></p>
<p>（1）由于弱学习器之间存在依赖关系，难以并行训练数据。</p>
<h2 id="GBDT如何进行正则化"><a href="#GBDT如何进行正则化" class="headerlink" title="GBDT如何进行正则化"></a>GBDT如何进行正则化</h2><p>第一种正则化方式为步长（learning rate）。定义为v，对于前面的弱学习器的迭代<br>$$<br>f_k{x} = f_{k-1}(x)+h_k(x)<br>$$<br>如果我们加上了正则化项，则有<br>$$<br>f_k(x) = f_{k-1}(x)+ vh_k(x)<br>$$<br>v的取值范围为$0\lt v \le 1$。对于同样的训练集学习效果，较小的v意味着我们需要更多的弱学习器的迭代次数，通常我们用步长和迭代最大次数一起来决定算法的拟合效果。</p>
<p>第二种正则化的方式是通过子采样比例（subsample）。取值为(0,1]。<strong>注意这里的子采样和随机森林不一样，随机森林使用的是放回抽样，而这里是不放回抽样。</strong>如果取值为1，则全部样本都使用，等于没有使用子采样。如果取值小于1，则只有一部分样本会去做GBDT的决策树拟合。选择小于1的比例可以减少方差，即防止过拟合，但是会增加样本拟合的偏差，因此取值不能太低。推荐在[0.5,0.8]之间。</p>
<p>第三种是对于弱学习器即CART回归树进行正则化剪枝。</p>
<h2 id="GBDT如何构建特征"><a href="#GBDT如何构建特征" class="headerlink" title="GBDT如何构建特征"></a>GBDT如何构建特征</h2><p>GBDT本身是不能产生特征的，但是我们可以利用GBDT去产生特征的组合，其主要思想是<strong>GBDT每棵树的路径直接作为其他模型的输入特征使用</strong>，例如输入逻辑回归模型。</p>
<p>用已有特征训练GBDT模型，然后利用GBDT模型学习到的树来构造新特征，最后把这些新特征加入原有特征一起训练模型。构造的新特征向量是取值0/1的，向量的每个元素对应于GBDT模型中树的叶子结点。<strong>当一个样本点通过某棵树最终落在这棵树的一个叶子结点上，那么在新特征向量中这个叶子结点对应的元素值为1</strong>，而这棵树的其他叶子结点对应的元素值为0。新特征向量的长度等于GBDT模型里所有树包含的叶子结点数之和。</p>
<p><img src="/passages/2019-07-30-集成学习专题（二）/GBDT-Feature.jpg" alt="GBDT-Feature"></p>
<p>上图的两棵树是GBDT学习到的，第一棵树有3个叶子结点，而第二棵树有2个叶子结点。对于一个输入样本点x，如果它在第一棵树最后落在其中第二个叶子结点，而在第二棵树里最后落在其中的第一个叶子结点。那么通过GBDT获得的新特征向量为[0,1,0,1,0]，其中向量中的前三位对应第一棵树的3个叶子结点，后两位对应第二棵树的2个叶子结点，原来的特征一起组合成为新的组合特征进行训练。实验证明这样会得到比较显著的提升模型效果。</p>
<p>经验证，树的数量最多500棵（500以上就没有提升了），每棵树的节点不多于12。</p>
<h2 id="GBDT如何用于分类"><a href="#GBDT如何用于分类" class="headerlink" title="GBDT如何用于分类"></a>GBDT如何用于分类</h2><p>GBDT无论用于分类还是回归一直都是使用的CART回归树。不会因为我们所选择的任务是分类任务就选用分类树。由于GBDT每轮的训练是在上一轮的训练的残差基础之上进行训练的。这里的残差就是当前模型的负梯度值。这个要求每轮迭代的时候，弱分类器的输出结果相减是有意义的，即残差相减是有意义的。</p>
<p>如果选用的弱分类器是分类树，类别相减是没有意义的。上一轮输出的是样本x属于A类，本一轮训练输出的是样本x属于B类。A和B很多时候甚至都没有比较的意义，A类-B类是没有意义的。</p>
<p>首先，我们在训练的时候，是针对样本X每个可能的类都训练一个分类回归树。举例说明，目前样本有三类，也就是K = 3。样本x属于第二类。那么针对该样本x的分类结果，其实我们可以用一个三维向量[0,1,0]来表示。0表示样本不属于该类，1表示样本属于该类。由于样本已经属于第二类了，所以第二类对应的向量维度为1，其他位置为0。</p>
<p><strong>针对样本有三类的情况，我们实质上是在每轮的训练的时候是同时训练三棵树。</strong>第一棵树针对样本x的第一类，输入为(x,0)。第二棵树输入针对样本x的第二类，输入为(x,1)。第三棵树针对样本x的第三类，输入为(x,0)。</p>
<p>在这里每棵树的训练过程其实就是CART TREE的生成过程。按照生成树的流程可以解出三棵树，以及三棵树对x类别的预测$f_1(x),f_2(x),f_3(x)$。那么在此类训练中，我们仿照多分类的逻辑回归，使用softmax来产生概率，则属于类别1的概率：<br>$$<br>p_1 = exp(f_1(x))/\sum_{k=1}^3\exp(f_k(x))<br>$$<br>并且我们可以针对类别1求出残差$y_{11}(x) =0-p_1(x)$;类别2求出残差$y_{22} =1-p_2(x)$;类别3求出残差$y_{33}(x) = 0-p_3(x)$。</p>
<p>然后开始第二轮训练 针对第一类输入为$(x,y_{11}(x))$，针对第二类输入为$(x,y_{22}(x))$，针对第三类输入为$(x,y_{33}(x))$，继续训练出三棵树。一直迭代M轮。每轮构建3棵树，进行T轮迭代后，生成3*T棵树，样本属于某个类别的概率为：<br>$$<br>p_c = \exp(f_c(x))/\sum_{k=1}^3exp(f_k(x))<br>$$</p>
<h2 id="GBDT需要调试的参数"><a href="#GBDT需要调试的参数" class="headerlink" title="GBDT需要调试的参数"></a>GBDT需要调试的参数</h2><p>GBDT训练中需要调试的参数如下：</p>
<ol>
<li>n_estimators：也就是弱学习器的最大迭代次数，或者说<strong>最大弱学习器的个数</strong>。一般来说n_estimators太小，容易欠拟合，n_estimators太大，容易过拟合，一般选择一个适中的数值。</li>
<li>learning_rate：即每个弱学习器的权重缩减系数v，也称步长。</li>
<li>subsample：不放回抽样。如果取值为1，则全部样本都使用，等于没有使用子采样。如果取值小于1，则只有一部分样本会去做GBDT的决策树拟合。</li>
<li>max_features允许单个决策树使用特征的最大数量。</li>
<li>max_depth决策树最大深度</li>
</ol>
<p>默认决策树在建立子树的时候不会限制子树的深度</p>
<ol start="6">
<li>min_sample_split 内部节点再划分所需最小样本数</li>
</ol>
<p>内部节点再划分所需最小样本数，如果某节点的样本数少于min_samples_split，则不会继续再尝试选择最优特征来进行划分。</p>
<ol start="7">
<li>min_samples_leaf 叶子节点最少样本数</li>
</ol>
<p>这个值限制了叶子节点最少的样本数，如果某叶子节点数目小于样本数，则会和兄弟节点一起被剪枝。</p>
<ol start="8">
<li>max_leaf_nodes 最大叶子节点数</li>
</ol>
<p>通过限制最大叶子节点数，可以防止过拟合，默认是“None”，即不限制最大的叶子节点数。如果加了限制，算法会建立在最大叶子节点数内的最优的决策树。</p>
<ol start="9">
<li>min_impurity_split 节点划分最小不纯度</li>
</ol>
<p>这个值限制了决策树的增长，如果某节点的不纯度（基于基尼系数，均方差）小于这个阈值，则该节点不再生成子节点。即为叶子节点。一般不推荐改动默认值1e-7。</p>
<h1 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h1><h2 id="Xgboost算法思想"><a href="#Xgboost算法思想" class="headerlink" title="Xgboost算法思想"></a>Xgboost算法思想</h2><p><strong>该算法就是不断地添加树，不断地进行特征分裂来生长一棵树，每次添加一个树，其实是学习一个新函数，去拟合上次预测的残差。</strong>当我们训练完成得到k棵树，我们要预测一个样本的分数，其实就是根据这个样本的特征，在每棵树中会落到对应的一个叶子节点，每个叶子节点就对应一个分数，最后只需要将每棵树对应的分数加起来就是该样本的预测值。</p>
<p>如下图例子，训练出了2棵决策树，小孩的预测分数就是两棵树中小孩所落到的结点的分数相加。爷爷的预测分数同理。</p>
<p><img src="/passages/2019-07-30-集成学习专题（二）/XGBoost.png" alt="XGBoost"></p>
<p><strong>分裂结点问题上，XGBoost使用了和CART回归树一样的想法，利用贪婪算法，遍历所有特征的所有特征划分点，不同的是评价函数（分裂后的目标函数值比单子叶子节点的目标函数的增益，CART是MSE），同时限制树生长过深，还加了阈值，当增益大于阈值才能进行分裂。</strong></p>
<h2 id="Xgboost使用泰勒展开的优势"><a href="#Xgboost使用泰勒展开的优势" class="headerlink" title="Xgboost使用泰勒展开的优势"></a>Xgboost使用泰勒展开的优势</h2><p>Xgboost使用了一阶和二阶偏导，二阶导数有利于梯度下降的更快更准，使用泰勒展开取得函数做自变量的二阶导数形式，可以在不选定损失函数具体形式的情况下，仅仅依靠输入数据的值就可以进行叶子节点分裂优化计算，<strong>本质上也就把损失函数的选取和模型算法优化/参数选择分开了。</strong>这种去耦合增加了xgboost的适用性，使得它按需选取损失函数，可以用于分类，也可以用于回归。</p>
<h2 id="Xgboost如何寻找最优特征"><a href="#Xgboost如何寻找最优特征" class="headerlink" title="Xgboost如何寻找最优特征"></a>Xgboost如何寻找最优特征</h2><p>Xgboost在训练的过程中给出各个特征的增益评分，最大增益的特征会被选出来作为分裂依据，从而记忆了每个特征对在模型训练时的重要性，从根到叶子中间节点涉及某特征的次数作为该特征重要性排序。</p>
<h2 id="Xgboost的采样"><a href="#Xgboost的采样" class="headerlink" title="Xgboost的采样"></a>Xgboost的采样</h2><p>Xgboost属于boosting集成学习方法，样本是不放回的，因而每轮计算样本不重复。另一方面，Xgboost支持子采样，也就是每轮计算可以不使用全部样本，以减少过拟合，进一步地，Xgboost还有列采样，每轮计算按百分比随机采样一部分特征，既提高计算速度又减少过拟合。</p>
<h2 id="Xgboost中树的剪枝"><a href="#Xgboost中树的剪枝" class="headerlink" title="Xgboost中树的剪枝"></a>Xgboost中树的剪枝</h2><p>首先看Xgboost分裂的决策函数：<br>$$<br>Gain =\frac{1}{2}[\frac{G_L^2}{H_L+\lambda}+\frac{G_R^2}{H_R+\lambda}-\frac{(G_L+G_R)^2}{H_L+H_R+\lambda}]-\gamma<br>$$<br>其中第一项为树的左孩子的分数，第二项为树的右孩子的分数，第三项为没有分裂的分数，$\gamma$在这里实际上是一个临界值，它的值越大，表示我们对切分后损失函数下降幅度要求越严。这个值也是可以在xgboost中设定的。Gain是正的，并且值越大，就越值得切分。</p>
<p>每一次分类选择Gain值最大的分裂方式，可以通过调节$\gamma$值的大小来改变树的分裂倾向，实现预剪枝。</p>
<p>其次Xgboost会在完整生成一棵决策树后回溯剪枝。</p>
<p><strong>注意：</strong>xgboost的切分操作和普通的决策树切分过程是不一样的。普通的决策树在切分的时候并不考虑树的复杂度，而依赖后续的剪枝操作来控制。xgboost在切分的时候就已经考虑了树的复杂度，就是那个γ参数。所以，它不需要进行单独的剪枝操作。</p>
<h2 id="Xgboost对缺失值的处理"><a href="#Xgboost对缺失值的处理" class="headerlink" title="Xgboost对缺失值的处理"></a>Xgboost对缺失值的处理</h2><p>当数据中含有缺失值的时候，我们可以不再填充缺失值。利用Xgboost的机制自动处理缺失值。</p>
<p><img src="/passages/2019-07-30-集成学习专题（二）/XGBoost%E7%BC%BA%E5%A4%B1%E5%80%BC%E5%A4%84%E7%90%86.png" alt="XGBoost缺失值处理"></p>
<p>Xgboost的处理方式是，<strong>缺失值数据会被分到左子树和右子树分别计算损失，选择较优的那个。如果训练中没有数据缺失，预测时出现了数据缺失，默认分类到右子树。</strong></p>
<h2 id="Xgboost训练通常调整的参数"><a href="#Xgboost训练通常调整的参数" class="headerlink" title="Xgboost训练通常调整的参数"></a>Xgboost训练通常调整的参数</h2><p>Xgboost训练需要调整的参数：</p>
<ol>
<li>booster：选择每次迭代的模型，有两种选择：</li>
</ol>
<ul>
<li><p>gbtree：基于树的模型</p>
</li>
<li><p>gbliner：线性模型</p>
</li>
</ul>
<ol start="2">
<li>n_estimatores：总共迭代的次数，即决策树的个数</li>
<li>eta：学习率，通过减少每一步的权重，可以提高模型的鲁棒性。</li>
<li>max_depth：树的深度</li>
<li>min_child_weight：决定最小叶子节点样本权重和</li>
<li>max_leaf_nodes：树上最大的节点或者叶子的数量</li>
<li>gamma：</li>
</ol>
<p><strong>在节点分裂时，只有分裂后损失函数的值下降了，才会分裂这个节点。</strong></p>
<p>Gamma指定了节点分裂所需的最小损失函数下降值。</p>
<p>这个参数的值越大，算法越保守。这个参数的值和损失函数息息相关，所以是需要调整的。</p>
<ol start="8">
<li>lambda：权重的L2正则化项</li>
<li>alpha：权重的L1正则化项</li>
<li>objective：这个参数定义需要被最小化的损失函数</li>
<li>eval_metric：对于有效数据的度量方法</li>
</ol>
<h1 id="XGBoost和GBDT的异同"><a href="#XGBoost和GBDT的异同" class="headerlink" title="XGBoost和GBDT的异同"></a>XGBoost和GBDT的异同</h1><h2 id="Xgboost-GBDT在调参数时为什么树的深度很少就能达到很高的精度，而随机森林需要的深度相对较高？"><a href="#Xgboost-GBDT在调参数时为什么树的深度很少就能达到很高的精度，而随机森林需要的深度相对较高？" class="headerlink" title="Xgboost/GBDT在调参数时为什么树的深度很少就能达到很高的精度，而随机森林需要的深度相对较高？"></a>Xgboost/GBDT在调参数时为什么树的深度很少就能达到很高的精度，而随机森林需要的深度相对较高？</h2><p>Xgboost/GBDT是基于Boosting思想的集成学习方法，随机森林是基于Bagging思想的集成学习方法。<strong>Boosting主要关注降低偏差，Bagging主要关注降低方差。</strong></p>
<p>Bagging算法是这样做的：每个分类器都随机从原样本中做有放回的采样，然后分别在这些采样后的样本上训练分类器，然后再把这些分类器组合起来，简单的多数投票一般就可以。代表算法是随机森林。Boosting的意思是这样，他通过迭代地训练一系列的分类器，每个分类器采用的样本分布都和上一轮的学习结果有关。其代表算法是Adaboost，GBDT。</p>
<p>机器学习算法来说，其泛化误差可以分解为两部分，偏差和方差。</p>
<p>偏差指的是算法的期望预测与真实预测之间的偏差程度，反应了模型本身的拟合能力；方差度量了同等大小的训练集的变动导致学习性能的变化，刻画了数据扰动所导致的影响。</p>
<p>当模型越复杂时，拟合的程度就越高，模型的训练偏差就越小。但此时如果换一组数据可能模型的变化就会很大，即模型的方差很大。所以模型过于复杂的时候会导致过拟合。</p>
<p>当模型越简单时，即使我们再换一组数据，最后得出的学习器和之前的学习器的差别就不那么大，模型的方差很小。还是因为模型简单，所以偏差会很大。</p>
<p>对于Bagging算法来说，由于我们会并行地训练很多不同的分类器的目的就是降低这个方差，<strong>因为采用了相互独立的基分类器多了以后，方差的值会减小</strong>，所以对于每个基分类器来说，目标就是如何降低这个偏差，所以我们会采用深度很深甚至不剪枝的决策树。</p>
<p>对于Boosting来说，<strong>每一步我们都会在上一轮的基础上更加拟合原数据，所以可以保证偏差，</strong>所以可以保证偏差，对于每个基分类器来说，问题就在于如何选择方差更小的分类器，即更简单的分类器，所以我们选择深度很浅的决策树。</p>
<h2 id="Xgboost和GBDT的区别"><a href="#Xgboost和GBDT的区别" class="headerlink" title="Xgboost和GBDT的区别"></a>Xgboost和GBDT的区别</h2><ol>
<li><p>传统GBDT以CART作为基分类器，Xgboost还支持线性分类器，这个时候Xgboost相当于带L1和L2正则化项的逻辑斯蒂回归（分类问题）或者线性回归（回归问题）。</p>
</li>
<li><p>传统GBDT在优化时只用到一阶导数信息，Xgboost则对代价函数进行二阶泰勒展开，同时用到了一阶和二阶导数。</p>
</li>
<li><p>Xgboost在代价函数里加入了正则项，用于控制模型的复杂度，损失函数如下：<br>$$<br>Obj = \sum_{i=1}^n l(y_i,\hat{y_i})+\sum_{k=1}^K\Omega(f_k)<br>$$<br>正则项里包含了树的叶子节点个数、每个叶子节点上输出的score的L2模的平方和。<br>$$<br>\Omega(f_t) = \gamma T+\frac{1}{2}\lambda \sum_{j=1}^T w_j^2<br>$$</p>
</li>
<li><p>Xgboost支持列抽样</p>
</li>
</ol>
<p>Xgboost借鉴了随机森林的做法，支持列抽样，不仅能降低过拟合，还能减少计算。</p>
<p>传统的GBDT在每轮迭代时使用全部的数据。</p>
<ol start="5">
<li><p>传统的GBDT没有设计对缺失值进行处理，Xgboost能够自动学习出缺失值的处理策略。</p>
</li>
<li><p>Xgboost工具支持并行</p>
</li>
</ol>
<p>Xgboost的并行不是tree粒度的并行，Xgboost也是一次迭代完才能进行下一次迭代的（第t次迭代的代价函数里包含了前面t-1次迭代的预测值）。<strong>Xgboost的并行是在特征粒度上的。</strong>决策树的学习最耗时的一个步骤就是对特征的值进行排序（因为要确定最佳分割点），Xgboost在训练之前，预先对数据进行了排序，然后保存为block结构，后面的迭代中重复地使用这个结构，大大减小计算量。这个block结构也使得并行成为了可能，在进行节点的分裂时，需要计算每个特征的增益，最终选增益最大的那个特征去做分裂，那么各个特征的增益计算就可以开多线程进行。</p>
<p>可并行的近似直方图算法：</p>
<p>树节点在进行分裂时，我们需要计算每个特征的每个分割点对应的增益，即用贪心法枚举所有可能的分割点。当数据无法一次载入内存或者在分布式情况下，贪心算法效率就会变得很低，所以Xgboost提出了一种可并行的近似直方图算法，用于高效地生成候选的分割点。</p>

      
    </div>

    

    
    
    

    

    
      
    
    
      <div>
        <div id="reward-container">
  <div></div>
  <button id="reward-button" disable="enable" onclick="var qr = document.getElementById(&quot;qr&quot;); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">

    
      
      
        
      
      <div style="display: inline-block">
        <img src="/images/wechat.png" alt="NI,JUN 微信支付">
        <p>微信支付</p>
      </div>
    
      
      
        
      
      <div style="display: inline-block">
        <img src="/images/alipay.png" alt="NI,JUN 支付宝">
        <p>支付宝</p>
      </div>
    

  </div>
</div>

      </div>
    

    

    <footer class="post-footer">
      
        
          
        
        <div class="post-tags">
          
            <a href="/tags/集成学习/" rel="tag"># 集成学习</a>
          
            <a href="/tags/监督学习/" rel="tag"># 监督学习</a>
          
            <a href="/tags/GBDT/" rel="tag"># GBDT</a>
          
            <a href="/tags/XGBoost/" rel="tag"># XGBoost</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/passages/2019-07-30-集成学习专题（一）/" rel="next" title="集成学习专题（一）">
                <i class="fa fa-chevron-left"></i> 集成学习专题（一）
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">NI,JUN</p>
              <div class="site-description motion-element" itemprop="description"></div>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">26</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  
                    
                      <a href="/categories/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">5</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                      <a href="/tags/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">44</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          

          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://github.com/nijunssdut" title="GitHub &rarr; https://github.com/nijunssdut" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="mailto:nijun@mail.dlut.edu.com" title="E-Mail &rarr; mailto:nijun@mail.dlut.edu.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                </span>
              
            </div>
          

          

          
          

          
            
          
          

        </div>
      </div>

      
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#GBDT"><span class="nav-number">1.</span> <span class="nav-text">GBDT</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#GBDT的算法流程"><span class="nav-number">1.1.</span> <span class="nav-text">GBDT的算法流程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#GBDT常用的损失函数"><span class="nav-number">1.2.</span> <span class="nav-text">GBDT常用的损失函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#GBDT中为什么用负梯度来拟合残差计算"><span class="nav-number">1.3.</span> <span class="nav-text">GBDT中为什么用负梯度来拟合残差计算</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#GBDT不适合使用高维稀疏特征的原因"><span class="nav-number">1.4.</span> <span class="nav-text">GBDT不适合使用高维稀疏特征的原因</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#GBDT减少误差的方式"><span class="nav-number">1.5.</span> <span class="nav-text">GBDT减少误差的方式</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#GBDT的优缺点"><span class="nav-number">1.6.</span> <span class="nav-text">GBDT的优缺点</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#GBDT如何进行正则化"><span class="nav-number">1.7.</span> <span class="nav-text">GBDT如何进行正则化</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#GBDT如何构建特征"><span class="nav-number">1.8.</span> <span class="nav-text">GBDT如何构建特征</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#GBDT如何用于分类"><span class="nav-number">1.9.</span> <span class="nav-text">GBDT如何用于分类</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#GBDT需要调试的参数"><span class="nav-number">1.10.</span> <span class="nav-text">GBDT需要调试的参数</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#XGBoost"><span class="nav-number">2.</span> <span class="nav-text">XGBoost</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Xgboost算法思想"><span class="nav-number">2.1.</span> <span class="nav-text">Xgboost算法思想</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Xgboost使用泰勒展开的优势"><span class="nav-number">2.2.</span> <span class="nav-text">Xgboost使用泰勒展开的优势</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Xgboost如何寻找最优特征"><span class="nav-number">2.3.</span> <span class="nav-text">Xgboost如何寻找最优特征</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Xgboost的采样"><span class="nav-number">2.4.</span> <span class="nav-text">Xgboost的采样</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Xgboost中树的剪枝"><span class="nav-number">2.5.</span> <span class="nav-text">Xgboost中树的剪枝</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Xgboost对缺失值的处理"><span class="nav-number">2.6.</span> <span class="nav-text">Xgboost对缺失值的处理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Xgboost训练通常调整的参数"><span class="nav-number">2.7.</span> <span class="nav-text">Xgboost训练通常调整的参数</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#XGBoost和GBDT的异同"><span class="nav-number">3.</span> <span class="nav-text">XGBoost和GBDT的异同</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Xgboost-GBDT在调参数时为什么树的深度很少就能达到很高的精度，而随机森林需要的深度相对较高？"><span class="nav-number">3.1.</span> <span class="nav-text">Xgboost/GBDT在调参数时为什么树的深度很少就能达到很高的精度，而随机森林需要的深度相对较高？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Xgboost和GBDT的区别"><span class="nav-number">3.2.</span> <span class="nav-text">Xgboost和GBDT的区别</span></a></li></ol></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

      

    </div>
  </aside>
  


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">NI,JUN</span>

  

  
</div>


  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.9.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.2.0</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>














  
    
    
  
  <script color="0,0,255" opacity="0.8" zindex="-1" count="199" src="/lib/canvas-nest/canvas-nest.min.js"></script>



  
  



  
  





  
  
  <script id="ribbon" size="300" alpha="0.1" zindex="-1" src="/lib/canvas-ribbon/canvas-ribbon.js"></script>





  
  <script src="/lib/jquery/index.js?v=3.4.1"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script src="/lib/three/three.min.js"></script>

  
  <script src="/lib/three/three-waves.min.js"></script>

  
  <script src="/lib/three/canvas_lines.min.js"></script>


  


  <script src="/js/utils.js?v=7.2.0"></script>

  <script src="/js/motion.js?v=7.2.0"></script>



  
  


  <script src="/js/affix.js?v=7.2.0"></script>

  <script src="/js/schemes/pisces.js?v=7.2.0"></script>




  
  <script src="/js/scrollspy.js?v=7.2.0"></script>
<script src="/js/post-details.js?v=7.2.0"></script>



  


  <script src="/js/next-boot.js?v=7.2.0"></script>


  

  

  

  


  


  
  <script>
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url).replace(/\/{2,}/g, '/');
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x"></i></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x"></i></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  
  

  
  

  
    
      <script type="text/x-mathjax-config">
  

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });
  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') { next = next.nextSibling }
        if (next && next.nodeName.toLowerCase() === 'br') { next.parentNode.removeChild(next) }
      }
    });
  });
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      document.getElementById(all[i].inputID + '-Frame').parentNode.className += ' has-jax';
    }
  });
</script>
<script src="//cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    
  


  

  

  

  

  

  

  

  

  

  

  

</body>
</html>
