<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Long and Short Term Memory（LSTM）的理解</title>
    <url>/passages/2019-06-29-Long-and-Short-Term-Memory%EF%BC%88LSTM%EF%BC%89%E7%9A%84%E7%90%86%E8%A7%A3/</url>
    <content><![CDATA[<h1 id="1-LSTM网络定义"><a href="#1-LSTM网络定义" class="headerlink" title="1. LSTM网络定义"></a>1. LSTM网络定义</h1><p>长短期记忆网络——通常被称为 LSTM，是一种特殊的 RNN，能够学习长期依赖性。由 Hochreiter 和 Schmidhuber（1997）提出的，并且在接下来的工作中被许多人改进和推广。LSTM 在各种各样的问题上表现非常出色，现在被广泛使用。</p>
<p>LSTM 被明确设计用来避免长期依赖性问题。长时间记住信息实际上是 LSTM 的默认行为，而不是需要努力学习的东西！</p>
<p>所有递归神经网络都具有神经网络的链式重复模块。在标准的 RNN 中，这个重复模块具有非常简单的结构，只有单个 tanh 层。</p>
<p>LSTM 也具有这种类似的链式结构，但重复模块具有不同的结构。不是一个单独的神经网络层，而是四个，并且以非常特殊的方式进行交互。</p>
<h1 id="2-LSTM的核心思想"><a href="#2-LSTM的核心思想" class="headerlink" title="2. LSTM的核心思想"></a>2. LSTM的核心思想</h1><p>LSTM 的关键是细胞状态（cell state），即图中上方的水平线。它贯穿整个链条，只有一些次要的线性交互作用。信息很容易以不变的方式流过。LSTM可以通过“门”结构实现向细胞状态添加或移除信息的操作。</p>
<p><img src="/passages/2019-06-29-Long-and-Short-Term-Memory（LSTM）的理解/LSTM-cell.png" alt="LSTM-cell"></p>
<p>“门”结构通过一个 sigmoid 的神经层和一个逐点相乘的操作来实现信息选择通过。LSTM通过三个这样的门结构来实现信息的保护和控制。这三个门分别输入门（input gate）、遗忘门（forget gate）和输出门（output gate）。</p>
<h2 id="2-1-遗忘门"><a href="#2-1-遗忘门" class="headerlink" title="2.1 遗忘门"></a>2.1 遗忘门</h2><p>LSTM 中的第一步是决定我们会从细胞状态中丢弃什么信息，这一过程由遗忘门来完成，其过程如下图所示。</p>
<p><img src="/passages/2019-06-29-Long-and-Short-Term-Memory（LSTM）的理解/LSTM-forget-gate.png" alt="LSTM-forget-gate"></p>
<p>遗忘门会读取$h<em>{t-1}$和$x_t$，输出一个在 0到 1之间的数值给每个在细胞状态$C</em>{t-1}$中的数字。1表示“完全保留”，0 表示“完全舍弃”。</p>
<p>对于语言模型，若已知先前的词汇预测下一词汇，当前一刻细胞状态包括当前主语的性别，这信息需要保留下来帮助我们使用正确的代词。但当我们看到一个新的主语时，我们需要忘记先前的主语。</p>
<h2 id="2-2-输入门"><a href="#2-2-输入门" class="headerlink" title="2.2 输入门"></a>2.2 输入门</h2><p>下一步是决定让多少新的信息加入到细胞状态中来。实现这个需要包括两个步骤：</p>
<ul>
<li><p>一个“输入门”的 sigmoid网络层确定哪些信息需要更新</p>
</li>
<li><p>一个 tanh 网络层创建一个新的备选值向量—— $ \hat C_t $可以用来添加到细胞状态</p>
</li>
</ul>
<p>之后，我们把这两部分联合起来，对细胞状态进行一个更新，其过程如下图。</p>
<p><img src="/passages/2019-06-29-Long-and-Short-Term-Memory（LSTM）的理解/LSTM-input-gate.png" alt="LSTM-input-gate"></p>
<p>在语言模型的例子中，这就是我们实际根据前面确定的目标，丢弃旧代词的性别信息并添加新的信息的地方。</p>
<h2 id="2-3-输出门"><a href="#2-3-输出门" class="headerlink" title="2.3 输出门"></a>2.3 输出门</h2><p>现在更新旧的细胞状态 $C_{t-1}$ 更新到 $C_t$。然后，我们对旧的状态乘 $f_t$，用来忘记我们决定忘记的事。然后我们加上 $i_t*\hat C_t$，这是新的候选值，根据我们对每个状态决定的更新值按比例进行缩放。</p>
<p>最终，我们需要确定输出什么值。这个输出将会基于我们的细胞状态，但是也是一个过滤后的版本。首先，我们运行一个 sigmoid 层来确定细胞状态的哪些部分将输出出去。然后，我们把细胞状态输入 $tanh$处理（把数值调整到 $−1$和 $1$ 之间）再和 sigmoid 网络层的输出相乘，这样我们就可以输出想要输出的部分。</p>
<p><img src="/passages/2019-06-29-Long-and-Short-Term-Memory（LSTM）的理解/LSTM-output-gate.png" alt="LSTM-output-gate"></p>
<p>同样，以语言模型为例子，一旦出现一个主语，主语的信息会影响到随后出现的动词。例如，知道主语是单数还是复数，就可以知道随后动词的形式。</p>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ol>
<li><a href="https://machinelearningmastery.com/stacked-long-short-term-memory-networks/" target="_blank" rel="noopener">Stacked Long Short-Term Memory Networks</a></li>
<li><a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="noopener">Understanding LSTM Networks</a></li>
</ol>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>笔试面试</tag>
        <tag>神经网络</tag>
        <tag>RNN</tag>
      </tags>
  </entry>
  <entry>
    <title>排序算法比较</title>
    <url>/passages/2019-06-29-%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E6%AF%94%E8%BE%83/</url>
    <content><![CDATA[<h1 id="各种排序算法比较"><a href="#各种排序算法比较" class="headerlink" title="各种排序算法比较"></a>各种排序算法比较</h1><table>
  <tr>
    <th rowspan="2">类别</th>
    <th rowspan="2">排序方法</th>
    <th colspan="3">时间复杂度</th>
    <th>空间复杂度</th>
    <th rowspan="2">稳定性</th>
  </tr>
  <tr>
    <td>平均情况</td>
    <td>最好情况</td>
    <td>最坏情况</td>
    <td>辅助空间</td>
  </tr>
  <tr>
    <td rowspan="2">插入排序</td>
    <td>直接插入</td>
    <td>O($n^2$)</td>
    <td>O($n$)</td>
    <td>O($n^2$)</td>
    <td>O($1$)</td>
    <td>稳定</td>
  </tr>
  <tr>
    <td>Shell排序</td>
    <td>O($n^{1.3}$)</td>
    <td>O($n$)</td>
    <td>O($n^2$)</td>
    <td>O($1$)</td>
    <td>不稳定</td>
  </tr>
  <tr>
    <td rowspan="2">选择排序</td>
    <td>直接选择</td>
    <td>O($n^2$)</td>
    <td>O($n^2$)</td>
    <td>O($n^2$)</td>
    <td>O($1$)</td>
    <td>不稳定</td>
  </tr>
  <tr>
    <td>堆排序</td>
    <td>O($n\log_{2}{n}$)</td>
    <td>O($n\log_{2}{n}$)</td>
    <td>O($n\log_{2}{n}$)</td>
    <td>O($1$)</td>
    <td>不稳定</td>
  </tr>
  <tr>
    <td rowspan="2">交换排序</td>
    <td>冒泡排序</td>
    <td>O($n^2$)</td>
    <td>O($n$)</td>
    <td>O($n^2$)</td>
    <td>O($1$)</td>
    <td>稳定</td>
  </tr>
  <tr>
    <td>快速排序</td>
    <td>O($n\log_{2}{n}$)</td>
    <td>O($n\log_{2}{n}$)</td>
    <td>O($n^2$)</td>
    <td>O($n\log_{2}{n}$)</td>
    <td>不稳定</td>
  </tr>
  <tr>
    <td colspan="2">归并排序</td>
    <td>O($n\log_{2}{n}$)</td>
    <td>O($n\log_{2}{n}$)</td>
    <td>O($n\log_{2}{n}$)</td>
    <td>O($n$)</td>
    <td>稳定</td>
  </tr>
  <tr>
    <td colspan="2">基数排序</td>
    <td>O($d(r+n)$)</td>
    <td>O($d(n+rd)$)</td>
    <td>O($d(r+n)$)</td>
    <td>O($rd+n$)</td>
    <td>稳定</td>
  </tr>
</table>

<p><strong>Note:</strong>基数排序的复杂度中，r代表关键字的基数，d代表长度，n代表关键字的个数。</p>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>笔试面试</tag>
        <tag>排序算法</tag>
        <tag>复杂度</tag>
      </tags>
  </entry>
  <entry>
    <title>快速排序</title>
    <url>/passages/2019-06-30-%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/</url>
    <content><![CDATA[<h1 id="快速排序"><a href="#快速排序" class="headerlink" title="快速排序"></a>快速排序</h1><h2 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1. 介绍"></a>1. 介绍</h2><p>快速排序是一种高效的排序算法，它采用“分而治之”的思想。其原理是：对于一组给定的记录，通过一趟排序后，将原序列分成两部分，其中前部分的所有记录均比后面部分的所有记录小，然后再依次对前后两部分的记录进行快速排序，递归该过程，直到序列中的所有记录均有序为止。</p>
<p>具体算法步骤如下：</p>
<p>(1) 分解: 将输入的序列array[m,…,n]划分成两个非空子序列array[m,…,k]和array[k+1,…,n]，使array[m,..,k]和array[k+1,…,n]，使array[m,…,k]中任一元素的值不大于array[k+1,…,n]中任一元素的值。</p>
<p>(2) 递归求解：通过递归调用快速排序算法分别对array[m,…,k]和array[k+1,…,n]进行排序。</p>
<p>(3) 合并: 由于对分解出的两个子序列的排序是就地进行的，所以在array[m,…k]和array[k+1,…,n]都是排好序后，不需要执行任何计算，array[m,…,n]就已排好序。</p>
<h2 id="2-Python代码实现"><a href="#2-Python代码实现" class="headerlink" title="2. Python代码实现"></a>2. Python代码实现</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 如何进行快速排序</span></span><br><span class="line"><span class="comment"># 整体有序,基准左边或右边样本为空，比较次数多，最坏时间复杂度，例如基准最小，排序递增</span></span><br><span class="line"><span class="comment"># 最坏时间复杂度为O(n^2),最好时间复杂度为O(nlogn),平均时间复杂度为O(nlogn)</span></span><br><span class="line"><span class="comment"># 平均空间复杂度为O(nlogn)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">quick_sort</span><span class="params">(left,right,lists)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> left &gt; right:</span><br><span class="line">        <span class="keyword">return</span> lists</span><br><span class="line">    key = lists[left]</span><br><span class="line">    low = left</span><br><span class="line">    high = right</span><br><span class="line">    <span class="keyword">while</span> left &lt; right:</span><br><span class="line">        <span class="keyword">while</span> left &lt;right <span class="keyword">and</span> lists[right]&gt;=key:</span><br><span class="line">            right -= <span class="number">1</span></span><br><span class="line">        lists[left] = lists[right]</span><br><span class="line">        <span class="keyword">while</span> left &lt;right <span class="keyword">and</span> lists[left] &lt;= key:</span><br><span class="line">            left += <span class="number">1</span></span><br><span class="line">        lists[right] = lists[left]</span><br><span class="line">    lists[left] = key</span><br><span class="line">    quick_sort(low,left<span class="number">-1</span>,lists)</span><br><span class="line">    quick_sort(left+<span class="number">1</span>,high,lists)</span><br><span class="line">    <span class="keyword">return</span> lists</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    lists = [<span class="number">3</span>,<span class="number">4</span>,<span class="number">2</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">5</span>,<span class="number">1</span>]</span><br><span class="line">    print(<span class="string">"排序前序列为："</span>,end=<span class="string">""</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> lists:</span><br><span class="line">        print(i,end=<span class="string">" "</span>)</span><br><span class="line">    print(<span class="string">"\n排序后序列为："</span>,end=<span class="string">""</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> (quick_sort(<span class="number">0</span>,len(lists)<span class="number">-1</span>,lists)):</span><br><span class="line">        print(i,end=<span class="string">" "</span>)</span><br></pre></td></tr></table></figure>
<h2 id="3-参考资料"><a href="#3-参考资料" class="headerlink" title="3 参考资料"></a>3 参考资料</h2><ol>
<li>《Python程序员面试算法宝典》</li>
</ol>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>笔试面试</tag>
        <tag>排序算法</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>经典笔试——找到数组第k大或第k小的数</title>
    <url>/passages/2019-06-30-%E6%89%BE%E5%88%B0%E6%95%B0%E7%BB%84%E7%AC%ACk%E5%A4%A7%E6%88%96%E7%AC%ACk%E5%B0%8F%E7%9A%84%E6%95%B0/</url>
    <content><![CDATA[<h1 id="1-问题"><a href="#1-问题" class="headerlink" title="1. 问题"></a>1. 问题</h1><p>在未排序的数组中找到第k个最大的元素，<strong>找到数组排序后的第k个最大的元素</strong>。</p>
<p><strong>示例：</strong></p>
<p>输入：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[3,2,3,1,2,4,5,5,6] 和 k=4</span><br></pre></td></tr></table></figure>
<p>输出：4</p>
<h1 id="2-解题思路"><a href="#2-解题思路" class="headerlink" title="2. 解题思路"></a>2. 解题思路</h1><p>类快速排序思想，找到数组中元素的位置，当分界点的索引为k-1的时候，它就是第k大元素，第k小的数只需找<strong>（组数长度+1-k）</strong>大的数即可。其时间复杂度应小于$O(n\log_2n)$。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">findKthLargest</span><span class="params">(self,nums,k)</span>:</span></span><br><span class="line">		<span class="keyword">return</span> self.findKthSmallest(nums,len(nums)+<span class="number">1</span>-k)</span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">findKthSmallest</span><span class="params">(self,nums,k)</span>:</span>  </span><br><span class="line">		<span class="keyword">if</span> nums:</span><br><span class="line">			pos = self.partition(nums,<span class="number">0</span>,len(nums)<span class="number">-1</span>)</span><br><span class="line">			<span class="keyword">if</span> k&gt;pos+<span class="number">1</span>:</span><br><span class="line">				<span class="keyword">return</span> self.findKthSmallest(nums[pos+<span class="number">1</span>:],k-pos<span class="number">-1</span>)</span><br><span class="line">			<span class="keyword">elif</span> k&lt;pos+<span class="number">1</span>:</span><br><span class="line">				<span class="keyword">return</span> self.findKthSmallest(nums[:pos],k)</span><br><span class="line">			<span class="keyword">else</span>:</span><br><span class="line">				<span class="keyword">return</span> nums[pos]</span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">partition</span><span class="params">(self,nums,l,r)</span>:</span></span><br><span class="line">		low = l</span><br><span class="line">		<span class="keyword">while</span> l&lt;r:</span><br><span class="line">			<span class="keyword">if</span> nums[l] &lt; nums[r]:</span><br><span class="line">				nums[l],nums[low] = nums[low],num[l]</span><br><span class="line">				low += <span class="number">1</span></span><br><span class="line">			l += <span class="number">1</span></span><br><span class="line">		nums[low],nums[r] = nums[r],nums[low]</span><br><span class="line">		<span class="keyword">return</span> low</span><br></pre></td></tr></table></figure>
<h1 id="3-其他解法"><a href="#3-其他解法" class="headerlink" title="3. 其他解法"></a>3. 其他解法</h1><p>堆排序方法</p>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>笔试面试</tag>
        <tag>python</tag>
        <tag>必会题目</tag>
      </tags>
  </entry>
  <entry>
    <title>支持向量机(SVM)原理与推导</title>
    <url>/passages/2019-06-30-%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA-SVM-%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8E%A8%E5%AF%BC/</url>
    <content><![CDATA[<h2 id="1-支持向量机的原理"><a href="#1-支持向量机的原理" class="headerlink" title="1. 支持向量机的原理"></a>1. 支持向量机的原理</h2><p>Support Vector Machine (SVM)是一种二类分类模型。它的基本模型是在特征空间中寻找间隔最大化的分隔超平面的线形分类器。（间隔最大是它有别于感知机），通过该超平面实现对未知样本集的分类。</p>
<ol>
<li>当训练样本线性可分时，通过硬间隔最大化，学习一个线性分类器，即线性可分支持向量机；</li>
<li>当训练数据近似线性可分时，引入松弛变量，通过软间隔最大化，学习一个线性分类器，即线性支持向量机；</li>
<li>当训练数据线性不可分时，通过使用核技巧及间隔最大化，学习非线性支持向量机。</li>
</ol>
<h1 id="2-SVM推导"><a href="#2-SVM推导" class="headerlink" title="2. SVM推导"></a>2. SVM推导</h1><p>线性分类器是最简单的有效分类器形式，SVM则在线性分类器基础上演化而成。</p>
<p>所谓线性函数，在一维空间中就是一个点，在二维空间中就是一条直线，三维空间就是一个平面，随着维度不断增加，线性函数也不断改变，被叫做超平面。</p>
<p>SVM的目标就是找到图中的超平面，在任意维空间中，超平面可以表示为函数：</p>
<script type="math/tex; mode=display">
G(x)=W^TX+b</script><p>一个样本点到$P(X_i,Y_i)$超平面的几何距离为：</p>
<script type="math/tex; mode=display">
\frac{\left|W^TX_i+b\right|}{\left\|{W}\right\|}</script><p><strong>Note:</strong>这里的几何距离是距离而非间隔。</p>
<p>对于正样本$Y_i=1$，意味着该点在超平面正样本一侧：</p>
<script type="math/tex; mode=display">
W^TX_i+b>0</script><p>对于负样本$Y_i =-1$，意味着该点在超平面负样本一侧：</p>
<script type="math/tex; mode=display">
W^TX_i+b<0</script><p>所以可用下述公式表示点到超平面的几何距离：</p>
<script type="math/tex; mode=display">
\frac{Y_i(W^TX_i+b)}{\left\|W\right\|}</script><p>其中，分子部分表示函数间隔。</p>
<p>几何间隔可以表示点到超平面的距离，在进行分类过程中使分类更加准确，需要优化所有样本中到分类超平面几何间隔最小点的间隔值更大，所以对于SVM公式的求解转换为了一个最优化问题：</p>
<script type="math/tex; mode=display">
\max_{W,b}[\min_{X_i}\frac{Y_i(W^TX_i+b)}{\left\|W\right\|}]</script><p>即求解出最优的$W,b$使得到超平面最近的样本几何间隔最大。</p>
<p>对于一个超平面，如果等比例缩放$W,b$的值其公式表示的超平面不变，我们可以假设到超平面距离最小的样本点到超平面的函数间隔都大于1（通过缩放可$W,b$以实现）：</p>
<script type="math/tex; mode=display">
Y_i(W^TX_i+b)\ge1</script><p>由此可以将原最优化问题进行改变为带约束条件的最优化问题，优化目标为：</p>
<script type="math/tex; mode=display">
\max_{W,b}\frac{1}{\left\|W\right\|}</script><p>约束条件为：</p>
<script type="math/tex; mode=display">
Y_i(W^TX_i+b)\ge1，i=1,2,3...k</script><p>为了便于求解，目标函数等价于：</p>
<script type="math/tex; mode=display">
\min_{W,b}\frac{1}{2}\left\|w\right\|^2</script><p>下面便对该式子进行求解。对于没有约束的最优化问题，我们可以采用求导的方式求解出最优解。针对带约束最优化问题，一个比较好的方法是将其转化为没有约束条件的最优化问题，我们将带约束最优化问题泛化为：</p>
<script type="math/tex; mode=display">
\min_xf(x)\\\\s.t.\\\\g(x)\le0,i=1,2,3...k\\\\h(x)=0,i=1,2,3...l</script><p>泛化问题可以等价于求：</p>
<script type="math/tex; mode=display">
\min_{x}\max_{\alpha,\beta}f(x)+\sum_{i=1}^k\alpha g_i(x)+\sum_{j=1}^l\beta h_j(x)</script><p>其中$\alpha$大于零，$\beta$不等于零。若$g(x)$大于零，而$\alpha$也大于零，对于可变$\alpha$项则不存在极大值，关于$\beta$同理，其可正可负不为0，若$h(x)$不能满足等于零，在该项上也不存在极大值，通过max求极值实现了对原有约束条件的保留。</p>
<p>基于此SVM最优化方程转化为：</p>
<script type="math/tex; mode=display">
\min_{W,b}\max_{\alpha}\frac{1}{2}\left\|w\right\|^2+\sum_{i=1}^k\alpha_{i}(1-Y_i(W^TX_i+b))\\\\
s.t.\\\\
\alpha_i\gt0,i=1,2,3...k</script><p>在满足KTT条件的情况下满足拉格朗日对偶性，其等价于优化方程：</p>
<script type="math/tex; mode=display">
\max_{\alpha}\min_{W,b}\frac{1}{2}\left\|w\right\|^2+\sum_{i=1}^k\alpha_{i}(1-Y_i(W^TX_i+b))\\\\
s.t.\\\\
\alpha_i\gt0,i=1,2,3...k\\\\
1-Y_i(W^TX_i+b)\le0,i=1,2,3...k\\\\
\alpha_{i}(1-Y_i(W^TX_i+b))=0,i=1,2,3...k</script><p>对于该最优化的方程内部进行求导：</p>
<script type="math/tex; mode=display">
\frac{\partial L}{\partial W} =W-\sum_{i=1}^k\alpha_{i}Y_iX_i\\\\
\frac{\partial L}{\partial b} =-\sum_{i=1}^k\alpha_{i}Y_i</script><p>在偏导数为0时取得极值。</p>
<script type="math/tex; mode=display">
W= \sum_{i=1}^k\alpha_{i}Y_iX_i\\\\
\sum_{i=1}^k\alpha_{i}Y_i=0</script><p>将求导后的等式带入原方程可以得到最终关于$\alpha$的最优化方程：</p>
<script type="math/tex; mode=display">
\max_{\alpha}\sum_{i=1}^k\alpha_i-\frac{1}{2}\sum_{i=1}^k\alpha_{i}Y_iX_i^T\sum_{j=1}^k\alpha_jY_jX_j\\\\
s.t.\\\\
\alpha_i\gt0,i=1,2,3...k\\\\
1-Y_i(W^TX_i+b)\le0,i=1,2,3...k\\\\
\alpha_{i}(1-Y_i(W^TX_i+b))=0,i=1,2,3...k\\\\
\sum_{i=1}^k\alpha_iY_i=0</script><p>求出该式子中各个$\alpha$的值，由于$W,b$与$\alpha$均有等价关系，便可以得到SVM模型的$W,b$参数。上面式子显然无法通过求导得到最优的$\alpha$值，可以使用Sequential Minimal Optimization(SMO)方法去进行求解。</p>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>笔试面试</tag>
        <tag>SVM</tag>
      </tags>
  </entry>
  <entry>
    <title>Line实习面</title>
    <url>/passages/2019-07-01-Line%E5%AE%9E%E4%B9%A0%E9%9D%A2/</url>
    <content><![CDATA[<h1 id="1-笔试"><a href="#1-笔试" class="headerlink" title="1. 笔试"></a>1. 笔试</h1><p><strong>问题1：</strong>平衡二叉树的性质（笔者菜，画蛇添足了…）</p>
<p><strong>正确解答：</strong>平衡二叉树或者是棵空树，或者是具有下列性质的二叉树：</p>
<ul>
<li>它的左子树和右子树都是平衡二叉树，且左子树和右子树的深度之差的绝对值不超过1。</li>
<li>若将二叉树节点的平衡因子（Balance Factor）定义为该节点的左子树的深度减去它的右子树的深度，则平衡二叉树上所有节点的平衡因子只可能为-1，0，1。</li>
<li>只要二叉树上有一个节点的平衡因子的绝对值大于1，那么这颗平衡二叉树就失去平衡了</li>
</ul>
<p><strong>问题2：</strong>在浏览器中输入 www.xxxx.com 后执行的全部过程。</p>
<p><strong>正确解答：</strong></p>
<ol>
<li>客户端浏览器通过DNS解析到 www.xxxx.com 的IP地址，然后通过TCP进行封装数据包，输入到网络层。</li>
<li>在客户端的传输层，把HTTP会话请求分成报文段，添加源和目的端口，如服务器使用80端口监听客户端的请求，客户端由系统随机选择一个端口如5000，与服务器进行交换，服务器把相应的请求返回给客户端的5000端口。然后使用IP层的IP地址查找目的端。</li>
<li>客户端的网络层不必关心应用层或者传输层的东西，主要做的是通过查找路由表确定如何到达服务器，期间可能经过多个路由器，这些都是由路由器来完成的工作，就是通过查找路由表决定通过哪个路径到达服务器。</li>
<li>客户端的链路层，包通过链路层发送到路由器，通过邻居协议查找给定IP地址的MAC地址，然后发送ARP请求查找目的地址，如果得到回应后就可以使用ARP的请求应答交换IP数据包。现在就可以传输了，然后发送IP数据包到达服务器的地址。</li>
</ol>
<p><strong>问题3：</strong> 设计实现HashTable类。(这题博主见过两次了，都没答对，是真的菜…)</p>
<p>HashTable有两个问题需要解决，首先是key值哈希化，我们可以借助Python自带的hash函数解决key的哈希编码问题。其次是Hash 冲突的解决机制，在这里只考虑最简单的一种，即将同一个 hash 值下的不同的 key 存放在数组的同一个位置，以链表形式保存。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class MyDict(object):</span><br><span class="line">	def __init__(self,size = 10000):</span><br><span class="line">		self.hash_list = [list() for _ in range(size)]</span><br><span class="line">		self.size = size</span><br><span class="line">	def __setitem__(self,key,value):</span><br><span class="line">		# 利用python自带的hash函数，对key哈希并对size取模</span><br><span class="line">		# hashed_key位置没有值就追加，否则覆盖</span><br><span class="line">		hashed_key = hash(key)%self.size</span><br><span class="line">		for item in self.hash_list[hashed_key]:</span><br><span class="line">			if item[0] == key:</span><br><span class="line">				item[1] = value</span><br><span class="line">				break</span><br><span class="line">			else:</span><br><span class="line">				self.hash_list[hashed_key].append([key,value])</span><br><span class="line">	def __getitem__(self,key):</span><br><span class="line">		# return: key所对应的value</span><br><span class="line">		# 没有key，就抛出keyError</span><br><span class="line">		for item in self.hash_list[hash(key)%self.size]:</span><br><span class="line">			if item[0] == key:</span><br><span class="line">				return item[1]</span><br><span class="line">			raise keyError(key)</span><br><span class="line">	def __repr__(self):</span><br><span class="line">		# hashtable打印</span><br><span class="line">		result = []</span><br><span class="line">		for sub_list in self.hash_list:</span><br><span class="line">			if not sub_list:</span><br><span class="line">				continue</span><br><span class="line">			for item in sub_list:</span><br><span class="line">				result.append(str(item[0])+&quot;:&quot;+str(item[1]))</span><br><span class="line">		return &quot;&#123;&quot;+&quot;,&quot;.join(result)+&quot;&#125;&quot;</span><br></pre></td></tr></table></figure>
<p><strong>参考答案：</strong><a href="https://blog.csdn.net/lzw2016/article/details/85222322" target="_blank" rel="noopener">不用 Python 自带的 Dict 实现自己的 HashTable</a></p>
<h1 id="2-面试"><a href="#2-面试" class="headerlink" title="2. 面试"></a>2. 面试</h1><p>主要问博主与简历相关的工作与能力，后续博主会陆续更新自己的研究内容。（博主过了，但不能实习可惜…）</p>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      <categories>
        <category>个人笔经面经</category>
      </categories>
      <tags>
        <tag>算法岗</tag>
      </tags>
  </entry>
  <entry>
    <title>神策数据实习</title>
    <url>/passages/2019-07-01-%E7%A5%9E%E7%AD%96%E6%95%B0%E6%8D%AE%E5%AE%9E%E4%B9%A0%E9%9D%A2%E8%AF%95/</url>
    <content><![CDATA[<h1 id="1-笔试"><a href="#1-笔试" class="headerlink" title="1. 笔试"></a>1. 笔试</h1><p>拓扑排序：可以实现有向图以及无向图判断是否有环存在。</p>
<p>稳定排序算法：归并排序、基数排序、冒泡排序和直接插入排序</p>
<h1 id="2-面试"><a href="#2-面试" class="headerlink" title="2. 面试"></a>2. 面试</h1><p>时间很短，每人只有15分钟，本人大概面试了20分钟左右，面试官不是做算法的，技术能力很强（认识…），效果不理想，主要是自己菜—&gt;.</p>
<p><strong>问题1：</strong>描述一下过拟合。</p>
<p><strong>问题2：</strong>给一些数据，如何选取模型去挑选数据，判断与随机取数据的好坏。</p>
<p><strong>问题3：</strong>分布式了解吗？MR工作机制？</p>
<p><strong>问题4：</strong>给文章数据让你统计词频，你怎么实现会有哪些问题？大量数据怎么处理？正常字典法请手撕代码。</p>
<p><strong>问题5：</strong>针对于分词那么换行问题“hell-\nO world”如何处理，文章应当一部分一部分去处理，如果分句针对较长的句子该怎么办？（面试官不看好replace(“-\n”,””)）我也没有合适的解决方案…..</p>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      <categories>
        <category>个人笔经面经</category>
      </categories>
      <tags>
        <tag>算法岗</tag>
      </tags>
  </entry>
  <entry>
    <title>作业帮算法卷笔试</title>
    <url>/passages/2019-07-02-%E4%BD%9C%E4%B8%9A%E5%B8%AE%E7%AE%97%E6%B3%95%E5%8D%B7%E7%AC%94%E8%AF%95/</url>
    <content><![CDATA[<h1 id="博主问题笔记"><a href="#博主问题笔记" class="headerlink" title="博主问题笔记"></a>博主问题笔记</h1><p>不包含博主经历所有题目只记录典型问题（估计也差不多全部了，因为博主菜…..）</p>
<p><strong>问题1：</strong>交叉熵公式</p>
<p><strong>解答：</strong>交叉熵公式如下：</p>
<script type="math/tex; mode=display">
H(x,y) = -\sum_{i=1}^nx_i\ln{y_i}</script><p>这里公式定义，x、y都是表示概率分布。其中x是正确的概率分布，而y是我们预测出来的概率分布，这个公式算出来的结果，表示y与正确答案x之间的错误程度（即：y错得有多离谱），结果值越小，表示y越准确，与x越接近。</p>
<p><strong>问题2：</strong>随机森林与GDBT的异同</p>
<p><strong>解答：</strong></p>
<h2 id="理论知识"><a href="#理论知识" class="headerlink" title="理论知识"></a>理论知识</h2><h3 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h3><p>随机森林是一个用随机方式建立的，包括多个决策树的集成分类器。其输出的类别由各个树投票而定（如果是回归树则取平均）。假设样本总数为n，每个样本的特征数为a。则随机森林生成过程如下：</p>
<ol>
<li>从原始样本中采用有放回抽样的方法选取n个样本;</li>
<li>对n个样本选取a个特征中的随机k个，用建立决策树的方法获得最佳分割点；</li>
<li>重复m次，获取m个决策树；</li>
<li>对输入样例进行预测时，每个子树都产生一个结果，采用多数投票机制输出。</li>
</ol>
<p>随机森林的随机性主要体现在两个方面：</p>
<ol>
<li>数据集的随机选取：从原始的数据集中采取有放回的抽样(bagging)，构造子数据集，子数据集的数据量是和原始数据集相同的。不同子数据集的元素可以重复，同一个子数据集中的元素也可以重复。</li>
<li>待选特征的随机选取：与数据集的随机选取类似，随机森林中的子树的每一个分裂过程并未用到所有的待选特征，而是从所有的待选特征中随机选取一定的特征，之后再在随机选取的特征中选择最优的特征。</li>
</ol>
<p><strong>随机森林的优点：</strong></p>
<ul>
<li>实现简单，训练速度快，泛化能力强，可以并行实现，因为训练时树与树之间是相互独立的；</li>
<li>相比单一决策树，能学习到特征之间的相互影响，且不容易过拟合；</li>
<li>能够处理高维数据（即特征很多），并且不用做特征选择，因为特征子集是随机选取的；</li>
<li>对于不平衡的数据集，可以平衡误差；</li>
<li>相比SVM，不是很怕特征缺失，因为待选特征也是随机选取；</li>
<li>训练完成后可以给出哪些特征比较重要。</li>
</ul>
<p><strong>随机森林的缺点：</strong></p>
<ul>
<li>在噪声过大的分类和回归问题还是容易过拟合；</li>
<li>相比于单一决策树，它的随机性让我们难以对模型进行解释。</li>
</ul>
<h3 id="GBDT"><a href="#GBDT" class="headerlink" title="GBDT"></a>GBDT</h3><p>GBDT （Gradient Boost Decision Tree）是以决策树为学习器迭代算法，注意GDBT里的决策树都是回归树而不是分类树。Boost是“提升”的意思，一般Boosting算法都是一个迭代的过程，每一次新的训练都是为了改进上一次的结果。 </p>
<p>GBDT的核心就在于：每一棵树学的是之前所有树结果和的残差，这个残差就是一个加预测值后能得真实值的累加量。比如A的真实年龄是18岁，但第一棵树的预测年龄是12岁，差了6岁，即残差为6岁。那么在第二棵树里我们把A的年龄设为6岁去学习，如果第二棵树真的能把A分到6岁的叶子节点，那累加两棵树的结论就是A的真实年龄；如果第二棵树的结论是5岁，则A仍然存在1岁的残差，第三棵树里A的年龄就变成1岁，继续学习。<br>GBDT优点是适用面广，离散或连续的数据都可以处理，几乎可用于所有回归问题（线性/非线性），亦可用于二分类问题（设定阈值，大于阈值为正例，反之为负例）。缺点是由于弱分类器的串行依赖，导致难以并行训练数据。</p>
<h3 id="随机森林和GBDT的区别"><a href="#随机森林和GBDT的区别" class="headerlink" title="随机森林和GBDT的区别"></a>随机森林和GBDT的区别</h3><ol>
<li>随机森林采用的bagging思想，而GBDT采用的boosting思想。这两种方法都是Bootstrap思想的应用，Bootstrap是一种有放回的抽样方法思想。虽然都是有放回的抽样，但二者的区别在于：Bagging采用有放回均匀取样，而boosting根据错误率来取样（Boosting 初始化时对每一个训练样例赋相等的权重$\frac{1}{n}$，然后用该算法对训练集训练t轮，每次训练后，对训练失败的样本赋以较大的权重），因此Boosting的分类京都要优于Bagging。Bagging的训练集的选择是随机的，各训练集之间相互独立，弱分类器可并行，而boosting的训练集的选择与前一轮的学习结果有关，是串行的。</li>
<li>组成随机森林的树可以是分类树，也可以是回归树；而GBDT只能由回归树组成。</li>
<li>组成随机森林的树可以并行生成；而GBDT只能是串行生成。</li>
<li>对于最终的输出结果而言，随机森林采用多数投票等；而GBDT则是将所有结果累加起来，或者加权累加起来。</li>
<li>随机森林对异常值不敏感；GDBT对异常值非常敏感。</li>
<li>随机森林对训练集一视同仁；GBDT是基于权值的弱分类器的集成。</li>
<li>随机森林是通过减少模型方差提高性能，GBDT是通过减少模型偏差提高性能。</li>
</ol>
<p>参考资料：<a href="https://blog.csdn.net/wfei101/article/details/82531516" target="_blank" rel="noopener">机器学习：随机森林和GDBT的区别</a></p>
<p><strong>问题3：</strong>对后验概率估计的思考</p>
<p><strong>解答：</strong>对于很多条件概率问题，可以等价于$P(B) =\frac{P(AB)}{P(A)}$求后验概率问题。</p>
<p><strong>问题4：</strong>针对归一化问题的数据线性排序思考</p>
<p><strong>解答：</strong>基数排序是一种针对该问题很好的解决方式，往往因为其平均复杂度为$O(d(r+n))$被忽略其线性。</p>
<p><strong>问题5：</strong>带有容错的最长公共子串如何实现（动态规划问题）</p>
<p><strong>解答：</strong> 暂时还没想到。</p>
<p><strong>问题6：</strong>剑指Offer原题，螺旋遍历</p>
<p><strong>解答：</strong>主要找规律找出循环条件：$columns \gt startX * 2$并且$rows \gt startY*2$。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="comment"># matrix类型为二维列表，需要返回列表</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">printMatrix</span><span class="params">(self, matrix)</span>:</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        <span class="keyword">if</span> matrix <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        res = []</span><br><span class="line">        start = <span class="number">0</span></span><br><span class="line">        column = len(matrix[<span class="number">0</span>])</span><br><span class="line">        row = len(matrix)</span><br><span class="line">        <span class="keyword">while</span> column &gt; <span class="number">2</span>*start <span class="keyword">and</span> row &gt; start*<span class="number">2</span>:</span><br><span class="line">            self.PrintMatrixIncicle(matrix,column,row,start,res)</span><br><span class="line">            start += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> res</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">PrintMatrixIncicle</span><span class="params">(self,matrix,column,row,start,res)</span>:</span></span><br><span class="line">        endX = column<span class="number">-1</span>-start</span><br><span class="line">        endY = row<span class="number">-1</span>-start</span><br><span class="line">        i = start</span><br><span class="line">        <span class="keyword">while</span> i &lt;= endX:</span><br><span class="line">            number = matrix[start][i]</span><br><span class="line">            self.printNumber(number,res)</span><br><span class="line">            i += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> start &lt; endY:</span><br><span class="line">            i = start+<span class="number">1</span></span><br><span class="line">            <span class="keyword">while</span> i &lt;= endY:</span><br><span class="line">                number= matrix[i][endX]</span><br><span class="line">                self.printNumber(number,res)</span><br><span class="line">                i += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> start &lt; endX <span class="keyword">and</span> start &lt; endY:</span><br><span class="line">            i = endX<span class="number">-1</span></span><br><span class="line">            <span class="keyword">while</span> i &gt;= start:</span><br><span class="line">                number = matrix[endY][i]</span><br><span class="line">                self.printNumber(number,res)</span><br><span class="line">                i -= <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span>  start &lt; endX <span class="keyword">and</span> start &lt; endY<span class="number">-1</span>:</span><br><span class="line">            i = endY<span class="number">-1</span></span><br><span class="line">            <span class="keyword">while</span> i &gt;= start+<span class="number">1</span>:</span><br><span class="line">                number = matrix[i][start]</span><br><span class="line">                self.printNumber(number,res)</span><br><span class="line">                i -= <span class="number">1</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">printNumber</span><span class="params">(self,number,res)</span>:</span></span><br><span class="line">        res.append(number)</span><br></pre></td></tr></table></figure>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      <categories>
        <category>个人笔经面经</category>
      </categories>
      <tags>
        <tag>算法岗</tag>
      </tags>
  </entry>
  <entry>
    <title>MapReduce原理与排序应用</title>
    <url>/passages/2019-07-01-MapReduce%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8E%92%E5%BA%8F%E5%BA%94%E7%94%A8/</url>
    <content><![CDATA[<h1 id="1-MapReduce工作机制"><a href="#1-MapReduce工作机制" class="headerlink" title="1. MapReduce工作机制"></a>1. MapReduce工作机制</h1><p><strong>MapReduce执行总流程</strong></p>
<p><img src="/passages/2019-07-01-MapReduce原理与排序应用/MapReduce-Framework.png" alt="MapReduce-Framework"></p>
<p>MapReduce Framework如上图所示。</p>
<p>JobTracker: 初始化作业，分配作业，与TaskManager通信，协调整个作业的执行</p>
<p>TaskTracker: 保持与JobTracker的通信，执行map或者reduce任务</p>
<p>HDFS；保存作业的数据，配置信息等，保存作业结果</p>
<h2 id="具体相关流程"><a href="#具体相关流程" class="headerlink" title="具体相关流程"></a>具体相关流程</h2><h3 id="提交作业"><a href="#提交作业" class="headerlink" title="提交作业"></a>提交作业</h3><p>客户端编写完程序代码后，打成jar，然后通过相关命令向集群提交自己想要跑的MR任务，具体过程如下：</p>
<ol>
<li>通过调用JobTracker的getNewJobId()获取当前作业id</li>
<li>检查作业相关路径</li>
<li>计算作业的输入划分，并将划分信息写到Job.split文件中</li>
<li>将运行作业所需要的资源包括作业jar包，配置文件和打算所得的输入划分，复制到作业对应的HDFS上</li>
<li>调用JobTracker的summitJob()提交，告诉JobTracker作业准备执行</li>
</ol>
<h3 id="初始化作业"><a href="#初始化作业" class="headerlink" title="初始化作业"></a>初始化作业</h3><ol>
<li>从HDFS中读取作业对应的job.split，得到输入数据的划分信息</li>
<li>创建并且初始化Map任务和Reduce任务：为每个map/reduce task生成一个TaskInProgress去监控和调度该task。例如创建两个初始化task，一个初始化Map，一个初始化Reduce</li>
</ol>
<h3 id="分配任务"><a href="#分配任务" class="headerlink" title="分配任务"></a>分配任务</h3><p>JobTracker会将任务分配到TaskTracker去执行，但是怎么判断哪些TaskTracker，怎么分配任务呢？所以，我们要实现JobTracker和TaskTracker中的通信，也就是TaskTracker循环向JobTracker发送心跳，向上级报告自己这边是不是还活着，活干的怎么样了，可以接些新活等。作为JobTracker，接收到心跳信息，如果有待分配任务，就会给这个TaskTracker分配一个任务，然后taskTracker就把这个任务加入到他的任务队列中。我们可以主要看看TaskTracker中的transmitHeartBeart()和JobTracker的heartbeat()方法。</p>
<h3 id="执行任务"><a href="#执行任务" class="headerlink" title="执行任务"></a>执行任务</h3><p>TaskTracker申请到任务后，在本地执行，主要有以下几个步骤来完成本地的步骤化:</p>
<ol>
<li>将job.split复制到本地</li>
<li>将job.jar复制到本地</li>
<li>将job的配置信息写入到Job.xml</li>
<li>创建本地任务目录，解压job.rar</li>
<li>调用launchTaskForJob()方法发布任务</li>
</ol>
<p>发布任务后，TaskRunner会启动新的java虚拟机来运行每个任务，以map任务为例，流程如下：</p>
<ol>
<li>配置任务执行参数（获取java程序的执行环境和配置参数等）</li>
<li>在child临时文件表中添加Map任务信息</li>
<li>配置log文件夹，配置Map任务的执行环境和配置参数；</li>
<li>根据input split,生成RecordReader读取数据</li>
<li>为Map任务生成MapRunnable，一次从RecordReader中接收数据，并调用map函数进行处理</li>
<li>将Map函数的输出调用collect收集到MapOUtputBuffer中</li>
</ol>
<h1 id="2-MapReduce中排序应用"><a href="#2-MapReduce中排序应用" class="headerlink" title="2. MapReduce中排序应用"></a>2. MapReduce中排序应用</h1><h2 id="实现过程"><a href="#实现过程" class="headerlink" title="实现过程"></a>实现过程</h2><h3 id="Map阶段"><a href="#Map阶段" class="headerlink" title="Map阶段"></a>Map阶段</h3><p>Read(读取)      ==&gt;  Collect(生成Key-Value)     ==&gt;  Spill(溢写)</p>
<p><strong>Read:</strong>从HDFS读取inputSplit（由InputFormat根据文件生成）</p>
<p><strong>Collect:</strong>分为map过程和partition过程，map根据inputSplit生成Key-Value对，而Partition添加分区标记（辅助排序用），并写入环形缓存区。</p>
<p><strong>Spill:</strong>分为sort过程、compress过程以及combine过程。数据不断的写入环形缓存区，达到阈值之后开始溢写，在溢写的过程中进行一次Sort，这里使用的排序是快排（QuickSort）；一次溢出生成一个file，并且在生成file的过程中进行压缩（compress）；多个file又会进行一次文件合并，在文件合并的过程中进行排序，这里使用的排序是归并排序（MergeSort）。</p>
<h3 id="Shuffle阶段"><a href="#Shuffle阶段" class="headerlink" title="Shuffle阶段"></a>Shuffle阶段</h3><p>Shuffle阶段主要就是一个数据拷贝的过程，Map端合成的大文件之后，通过HTTP服务(jetty server)拷贝到Reduce端。拷贝到Reduce端的数据并不是马上写入文件，而是同样放在缓存中，达到阈值则进行溢写。</p>
<h3 id="Reduce阶段"><a href="#Reduce阶段" class="headerlink" title="Reduce阶段"></a>Reduce阶段</h3><p>合并溢写生成的file，这里使用的排序为归并排序(MegerSort)，生成一些更大的文件(进一步减少文件个数)。在归并之后留下少量的大文件，最后对大文件进行一次最终合并，合并成一个有序的大文件(只有一个)，这里使用的排序算法为堆排序(HeapSort)。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>综上所述，一个MapReduce过程涉及到了一次快排、两次归并以及一次堆排的操作。</p>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://www.cnblogs.com/wangkeustc/p/7338369.html" target="_blank" rel="noopener">Hadoop入门第三篇-MapReduce试手以及MR工作机制</a></p>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      <tags>
        <tag>分布式</tag>
        <tag>方法优化</tag>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>Attention机制整理</title>
    <url>/passages/2019-07-03-Attention%E6%9C%BA%E5%88%B6%E6%95%B4%E7%90%86/</url>
    <content><![CDATA[<h1 id="Attention的定义与作用"><a href="#Attention的定义与作用" class="headerlink" title="Attention的定义与作用"></a>Attention的定义与作用</h1><p>按照Stanford大学课件上的描述，attention的通用定义如下：</p>
<ul>
<li>给定一组向量集合values，以及一个向量query，attention机制是一种根据该query计算values的加权求和的机制。</li>
<li>attention的重点就是这个集合values中的每个value的“权值”的计算方法。</li>
<li>有时候也把这种attention的机制叫做query的输出关注了原文的不同部分。（Query attends to the values）</li>
</ul>
<p>换句话说，attention机制就是一种根据某些规则或者某些额外信息（query）从向量表达集合（values）中抽取特定的向量进行加权组合（attention）的方法。简单来讲，只要我们从部分向量里面搞了加权求和，那就算用了attention。</p>
<p>Attention-based Model其实就是一个相似性的度量，当前的输入与目标状态越相似，那么在当前的输入的权重就会越大，说明当前的输出越依赖于当前的输入。</p>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul>
<li><p><a href="https://blog.csdn.net/u014665013/article/details/82619808" target="_blank" rel="noopener">浅谈attention机制</a></p>
</li>
<li><p><a href="https://blog.csdn.net/hahajinbu/article/details/81940355" target="_blank" rel="noopener">自然语言处理中的Attention机制总结</a></p>
</li>
</ul>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>Attention</tag>
      </tags>
  </entry>
  <entry>
    <title>动态规划</title>
    <url>/passages/2019-07-04-%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/</url>
    <content><![CDATA[<h1 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h1><p>动态规划与分治方法相似，都是通过组合子问题的解来求解原问题。分治方法将问题划分为互不相交的子问题，递归地求解子问题，再将它们的解组合起来，求出原问题的解。与之相反，动态规划应用于子问题重叠的情况，即不同的子问题具有公共的子子问题（子问题的求解是递归进行的，将其划分为更小的子子问题）。动态规划算法对每个子子问题只求解一次，将其保存在一个表格中，避免了这种不必要的计算工作。</p>
<p>动态规划方法通常用来求解最优化问题。这类问题可以有很多可行解，每个解都有一个值，我们希望寻找具有最优值的解。我们称这样的解为问题的<strong>一个</strong>最优解，因为可能有多个解都达到最优值。</p>
<h1 id="设计方法"><a href="#设计方法" class="headerlink" title="设计方法"></a>设计方法</h1><p>通常按如下4个步骤来设计一个动态规划算法：</p>
<ol>
<li>刻画一个最优解的结构特征。</li>
<li>递归地定义最优解的值。</li>
<li>计算最优解的值，采用自底向上的方法。</li>
<li>利用计算出的信息构造一个最优解。</li>
</ol>
<h1 id="经典题目——最长公共子序列问题-LCS-与最长公共子串问题"><a href="#经典题目——最长公共子序列问题-LCS-与最长公共子串问题" class="headerlink" title="经典题目——最长公共子序列问题(LCS)与最长公共子串问题"></a>经典题目——最长公共子序列问题(LCS)与最长公共子串问题</h1><h2 id="最长公共子序列问题（LCS问题）"><a href="#最长公共子序列问题（LCS问题）" class="headerlink" title="最长公共子序列问题（LCS问题）"></a>最长公共子序列问题（LCS问题）</h2><p>给定两个字符串A和B，长度分别为m和n，要求找出它们最长的公共子序列，并返回其长度。例如：</p>
<center>A = "HelloWorld"</center>
<center>B="loop"</center>

<p>则A与B的最长公共子序列为 “loo”,返回的长度为3。此处只给出动态规划的解法：定义子问题<strong>$dp[i][j]$</strong>为字符串<strong>A</strong>的第一个字符到第 <strong>i</strong> 个字符串和字符串<strong>B</strong>的第一个字符到第 <strong>j</strong> 个字符的<strong>最长公共子序列</strong>。</p>
<p>为了求解$dp[i][j]$，我们要先判断<strong>A的第i个元素B的第j个元素</strong>是否相同即判断<strong>A[i - 1]</strong>和 <strong>B[j -1]</strong>是否相同，如果相同它就是$dp[i-1][j-1]+ 1$，相当于在两个字符串都去掉一个字符时的<strong>最长公共子序列</strong>再加 <strong>1</strong>；否则<strong>最长公共子序列</strong>取$dp[i][j-1]$和$dp[i-1][j]$中大的那个。</p>
<p>问题的初始状态为：</p>
<script type="math/tex; mode=display">
dp[i][0] = 0,dp[0][j] = 0</script><p>相应的状态转移方程为：</p>
<script type="math/tex; mode=display">
dp[i][j] =\begin{cases}
\max{(dp[i-1][j],dp[i][j-1])}& A[i-1]!=B[j-1]\\\\
dp[i-1][j-1]+1&A[i-1] == B[j-1]
\end{cases}</script><p>代码实现如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">LongestSubstring</span><span class="params">(str1,str2)</span>:</span></span><br><span class="line">    res = <span class="number">0</span></span><br><span class="line">    str1_len = len(str1)</span><br><span class="line">    str2_len = len(str2)</span><br><span class="line">    <span class="keyword">if</span> str1_len == <span class="number">0</span> <span class="keyword">or</span> str2_len == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> res</span><br><span class="line">    dp = [[<span class="number">0</span> <span class="keyword">for</span> j <span class="keyword">in</span> range(str1_len)] <span class="keyword">for</span> i <span class="keyword">in</span> range(str1_len)]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(str1_len):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(str2_len):</span><br><span class="line">            <span class="keyword">if</span> str1[i] == str2[j]:</span><br><span class="line">                <span class="keyword">if</span> i == <span class="number">0</span> <span class="keyword">or</span> j == <span class="number">0</span>:</span><br><span class="line">                    dp[i][j] = <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    dp[i][j] = dp[i<span class="number">-1</span>][j<span class="number">-1</span>]+<span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                dp[i][j] = max(dp[i<span class="number">-1</span>][j],dp[i][j<span class="number">-1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dp[i][j]</span><br></pre></td></tr></table></figure>
<p>该算法的时间复杂度为$O(n*m)$，空间复杂度为$O(n*m)$。</p>
<p><strong>Note：</strong>需要考虑空串的判定条件</p>
<h2 id="最长公共子串问题"><a href="#最长公共子串问题" class="headerlink" title="最长公共子串问题"></a>最长公共子串问题</h2><p>给定两个字符串A和B，长度分别为m和n，要求找出它们最长的公共子串，并返回其长度。例如：</p>
<p><center>A = "HelloWorld"</center></p>
<p><center>B = "loop"</center><br>则A与B的最长公共子串为 “lo”,返回的长度为2。我们可以看到子序列和子串的区别：<strong>子序列和子串都是字符集合的子集，但是子序列不一定连续，但是子串一定是连续的</strong>。</p>
<p>整个问题的初始状态为：</p>
<script type="math/tex; mode=display">
dp[i][0] = 0,dp[0][j] = 0</script><p>相应的状态转移方程为：</p>
<script type="math/tex; mode=display">
dp[i][j] =\begin{cases}0& A[i-1] !=B[j-1]\\\\
dp[i-1][j-1]+1 & A[i-1] == B[j-1]
\end{cases}</script><p>代码实现如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lcsubstr</span><span class="params">(str1,str2)</span>:</span></span><br><span class="line">	res = <span class="number">0</span></span><br><span class="line">	str1_len = len(str1)</span><br><span class="line">	str2_len = len(str2)</span><br><span class="line">	<span class="keyword">if</span> str1_len == <span class="number">0</span> <span class="keyword">or</span> str2_len == <span class="number">0</span>:</span><br><span class="line">		<span class="keyword">return</span> res</span><br><span class="line">	dp = [[<span class="number">0</span> <span class="keyword">for</span> j <span class="keyword">in</span> range(str1_len)] <span class="keyword">for</span> i <span class="keyword">in</span> range(str1_len)]</span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> range(str1_len):</span><br><span class="line">		<span class="keyword">for</span> j <span class="keyword">in</span> range(str2_len):</span><br><span class="line">			<span class="keyword">if</span> str1[i] == str2[j]:</span><br><span class="line">				<span class="keyword">if</span> i == <span class="number">0</span> <span class="keyword">or</span> j == <span class="number">0</span>:</span><br><span class="line">					dp[i][j] = <span class="number">1</span></span><br><span class="line">				<span class="keyword">else</span>:</span><br><span class="line">					dp[i][j] = dp[i<span class="number">-1</span>][j<span class="number">-1</span>]+<span class="number">1</span></span><br><span class="line">			<span class="keyword">if</span> dp[i][j]&gt; res:</span><br><span class="line">				res = dp[i][j]</span><br><span class="line">	<span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<p>该算法的时间复杂度为$O(n*m)$ ，空间复杂度为$O(n*m)$。</p>
<p><strong>Note：</strong>需要考虑空串的判定条件</p>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul>
<li>《算法导论第三版》</li>
</ul>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>笔试面试</tag>
        <tag>经典算法</tag>
        <tag>动态规划</tag>
      </tags>
  </entry>
  <entry>
    <title>TF-IDF算法介绍</title>
    <url>/passages/2019-07-05-TF-IDF%E7%AE%97%E6%B3%95%E4%BB%8B%E7%BB%8D/</url>
    <content><![CDATA[<h1 id="TF-IDF定义"><a href="#TF-IDF定义" class="headerlink" title="TF-IDF定义"></a>TF-IDF定义</h1><p><strong>TF-IDF（term frequency–inverse document frequency，词频-逆向文件频率）</strong>是一种加权技术。采用一种统计方法，根据字词在文本中出现的次数和在整个语料中出现的文档频率来计算一个字词在整个语料中的重要程度。</p>
<h1 id="TF-IDF的主要思想"><a href="#TF-IDF的主要思想" class="headerlink" title="TF-IDF的主要思想"></a>TF-IDF的主要思想</h1><p>TF-IDF是一种统计方法，用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。<strong>字词的重要性随着它在文件中出现的次数成正比增加，但同时会随着它在语料库中出现的频率成反比下降。</strong></p>
<p><strong>TF-IDF的主要思想是</strong>：如果某个单词在一篇文章中出现的频率TF高，并且在其他文章中很少出现，则认为此词或者短语具有很好的类别区分能力，适合用来分类。</p>
<h2 id="TF是词频-Term-Frequency"><a href="#TF是词频-Term-Frequency" class="headerlink" title="TF是词频(Term Frequency)"></a>TF是词频(Term Frequency)</h2><p><strong>词频（TF）</strong>表示<strong>词条（关键字）</strong>在文本中出现的频率。</p>
<p>这个数字通常会被归一化（一般是词频除以文章总词数），以防止它偏向长的文件。其公式如下：</p>
<script type="math/tex; mode=display">
tf_{ij}=\frac{n_{i,j}}{\sum_kn_{k,j}}</script><script type="math/tex; mode=display">
TF_w=\frac{在某一类中词条w出现的次数}{该类中所有的词条数目}</script><p>其中$n_{i,j}$是该词在文件$d_j$中出现的次数，分母则是文件$d_j$中所有词汇出现的次数总和。</p>
<h2 id="IDF是逆向文件频率-Inverse-Document-Frequency"><a href="#IDF是逆向文件频率-Inverse-Document-Frequency" class="headerlink" title="IDF是逆向文件频率(Inverse Document Frequency)"></a>IDF是逆向文件频率(Inverse Document Frequency)</h2><p><strong>逆向文件频率（IDF）：</strong>某一特定词语的IDF，可以由<strong>总文件数目除以包含该词语的文件的数目，再将得到的商取对数得到。</strong></p>
<p>如果包含词条$t$的文档越少，IDF越大，则说明词条具有很好的类别区分能力。其公式如下：</p>
<script type="math/tex; mode=display">
idf_{i}=\log{\frac{|D|}{|\{j:t_i\in d_j\}|}}</script><p>其中，<strong>$|D|$</strong> <strong>是语料库中的文件总数</strong>。 $|{j:t<em>i\in d_j}|$<strong>表示包含词语 $t_i$ 的文件数目</strong>（即 $n</em>{i,j}≠0$ 的文件数目）。如果该词语不在语料库中，就会导致分母为零，因此<strong>一般情况下使用$1+|{j:t_i\in d_j}|$ ，</strong>即：</p>
<script type="math/tex; mode=display">
IDF = \log(\frac{语料库的文档总数}{包括词条w的文档数+1})</script><h2 id="TF-IDF实际上是：TF-IDF"><a href="#TF-IDF实际上是：TF-IDF" class="headerlink" title="TF-IDF实际上是：TF * IDF"></a>TF-IDF实际上是：TF * IDF</h2><p>某一特定文件内的高词语频率，以及该词语在整个文件集合中的低文件频率，可以产生出高权重的TF-IDF。因此，TF-IDF倾向于过滤掉常见的词语，保留重要的词语。</p>
<script type="math/tex; mode=display">
TF-IDF = TF\*IDF</script><p><strong>Note：</strong>TF-IDF算法非常容易理解，并且很容易实现，但是其简单结构并没有考虑词语的语义信息，无法处理一词多义与一义多词的情况。</p>
<h1 id="TF-IDF的应用"><a href="#TF-IDF的应用" class="headerlink" title="TF-IDF的应用"></a>TF-IDF的应用</h1><ol>
<li>搜索引擎</li>
<li>关键词提取</li>
<li>文本相似性</li>
<li>文本摘要 </li>
</ol>
<p><strong>python sklearn工具包下的TF-IDF调用</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class sklearn.feature_extraction.text.TfidfTransformer(norm=’l2’, use_idf=True, smooth_idf=True, sublinear_tf=False)</span><br></pre></td></tr></table></figure>
<p><strong>norm：词向量归一化</strong> </p>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul>
<li><p>TF-IDF算法介绍及实现</p>
</li>
<li><p>文本特征提取之TFIDF与Word2Vec</p>
</li>
</ul>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>NLP</tag>
        <tag>文本表示</tag>
      </tags>
  </entry>
  <entry>
    <title>特征工程知识点整理概述（一）</title>
    <url>/passages/2019-07-06-%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%E7%9F%A5%E8%AF%86%E7%82%B9%E6%95%B4%E7%90%86%E6%A6%82%E8%BF%B0%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    <content><![CDATA[<h1 id="特征归一化"><a href="#特征归一化" class="headerlink" title="特征归一化"></a>特征归一化</h1><p>为了消除数据特征之间的量纲影响，我们需要对特征进行归一化处理，使得不同指标之间具有可比性。</p>
<h2 id="数值类型特征常用归一化方法"><a href="#数值类型特征常用归一化方法" class="headerlink" title="数值类型特征常用归一化方法"></a>数值类型特征常用归一化方法</h2><p>最常用的方法主要有以下两种：</p>
<p><strong>（1）线性函数归一化 (Min-Max Scaling)</strong></p>
<p>它对原始数据进行线性变换，使结果映射到$[0,1]$的范围，实现对原始数据的等比缩放。归一化公式如下：</p>
<script type="math/tex; mode=display">
X_{norm} = \frac{X-X_{min}}{X_{max}-X_{min}}</script><p>其中$X$为原始数据，$X<em>{max}、X</em>{min}$分别为数据最大值和最小值。</p>
<p><strong>（2）零均值归一化（Z-Score Normalization）</strong></p>
<p>它将原始数据映射到均值为0、标准差为1的分布上。具体来说，假设原始特征的均值为$\mu$、标准差为$\alpha$的分布上，那么归一化公式定义为：</p>
<script type="math/tex; mode=display">
z = \frac{x-\mu}{\sigma}</script><p>数据归一化不是万能的。在实际应用中，通过梯度下降法求解的模型通常是需要归一化的，包括线性回归、逻辑回归、支持向量机、神经网络等模型。但对于决策树模型则并不适用。</p>
<h2 id="类别型特征处理办法"><a href="#类别型特征处理办法" class="headerlink" title="类别型特征处理办法"></a>类别型特征处理办法</h2><p>类别型特征原始输入通常是字符串形式，除了决策树等少数模型能够直接处理字符串形式，对于逻辑回归、支持向量机等模型来说，类别型的特征必须经过处理转换成数值型特征才能正确工作。</p>
<p>常用的类别型特征处理方法如下：</p>
<h3 id="序号编码"><a href="#序号编码" class="headerlink" title="序号编码"></a>序号编码</h3><p>序号编码通常用于处理类别间具有大小关系的数据。例如成绩，可以分为低、中、高三档，并且“高&gt;中&gt;低”的排序关系。序号编码会按照大小关系对类别型特征赋予一个数值ID。</p>
<h3 id="独热编码"><a href="#独热编码" class="headerlink" title="独热编码"></a>独热编码</h3><p>独热编码通常用于处理类别间不具有大小关系的特征。对于类别取值较多的情况下使用独热编码需要注意以下问题。</p>
<ol>
<li>使用稀疏向量来节省空间。在独热编码下，特征向量只有某一维取值为1，其他位置均取值为0。因此可以利用向量的稀疏表示有效地节省空间，并且目前大部分的算法均接受稀疏向量形式的输入。</li>
<li>配合特征选择来降低维度。高维度特征会带来几方面的问题。一是在K近邻算法中，高维空间下两点之间的距离很难得到有效的衡量；二是在逻辑回归模型中，参数的数量会随着维度的增高而增加，容易引起过拟合问题；三是通常只有部分维度是对分类、预测有帮助，因此可以考虑配合特征选择来降低维度。</li>
</ol>
<h3 id="二进制编码"><a href="#二进制编码" class="headerlink" title="二进制编码"></a>二进制编码</h3><p>二进制编码主要分为两步，先用序号编码给每个类别赋予一个类别ID，然后将类别ID对应的二进制编码作为结果。</p>
<p>其他编码方式还有很多，比如Helmert Constrast、Sum Contrast、Polynomial Contrast、Backward Difference Contrast等。</p>
<h2 id="组合特征"><a href="#组合特征" class="headerlink" title="组合特征"></a>组合特征</h2><h3 id="组合特征定义"><a href="#组合特征定义" class="headerlink" title="组合特征定义"></a>组合特征定义</h3><p>为了提高复杂关系的拟合能力，在特征工程中经常会把一阶离散特征两两组合，构成高阶组合特征。</p>
<p>以逻辑回归为例，假设数据的向量特征为$X = (x_1,x_2,…,x_k)$，则有</p>
<script type="math/tex; mode=display">
Y = sigmoid(\sum_i\sum_yw_{ij}<x_i,x_j>)</script><p>其中$<x_i,x_j>$表示$x<em>i$和$x_j$的组合特征，$w</em>{ij}$的维度等于$|x_i|\cdot|x_j|$，$|x_i|$和$|x_j|$分别代表第$i$个特征和第$j$个特征不同取值的个数。</x_i,x_j></p>
<p>对于推荐算法，若用户数量为$m$，物品数量为$n$，那么需要学习参数的规模为$m*n$。在互联网环境下，用户数量和物品数量都可以达到千万量级，几乎无法学习$m*n$规模的参数。在这种情况下，一种行之有效的方法是将用户和物品分别用k维的低维向量表示$(k&lt;&lt;m,k&lt;&lt;n)$</p>
<script type="math/tex; mode=display">
Y = sigmoid(\sum_i\sum_yw_{ij}<x_i,x_j>)</script><p>这里$w<em>{ij}=x</em>{i}^{‘} \cdot x<em>{j}^{‘}$，$x</em>{i}^{‘}$和$x_{j}^{‘}$分别表示$x_i$和$x_j$ 对应的低维向量。那么在推荐问题中，需要学习的参数的规模变为$m*k+n*k$，这其实等价于矩阵分解。这就是利用降维方法来减少两个高维特征组合后需要学习的参数。</p>
<h3 id="怎样有效地找到组合特征"><a href="#怎样有效地找到组合特征" class="headerlink" title="怎样有效地找到组合特征"></a>怎样有效地找到组合特征</h3><p>实际问题中并不是所有的特征组合都是有意义的。这里介绍一种基于决策树的特征组合寻找方法。于是，每一条从根节点到叶节点的路径都可以看成一种特征组合的方式。假设我们有4种特征组合方式，如果样本满足1，2特征组合方式，则其特征表示可以表示为$(1,1,0,0)$。</p>
<p>对于利用原始数据有效的构造决策树，我们可以采用基于boosting的GBDT梯度提升决策树，该方法的思想是每次都在之前构造的决策树的残差上构建下一棵决策树。</p>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul>
<li>《百面机器学习》</li>
</ul>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>笔试面试</tag>
        <tag>特征工程</tag>
        <tag>归一化</tag>
        <tag>预处理</tag>
      </tags>
  </entry>
  <entry>
    <title>Word2Vec知识简述</title>
    <url>/passages/2019-07-08-Word2Vec/</url>
    <content><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>谷歌2013年提出的Word2Vec是目前最常用的词嵌入模型之一。Word2Vec实际是一种浅层的神经网络模型，它有两种网络结构，分别是CBOW（Continues Bag of Words）和Skip-gram。</p>
<p><strong>负采样（Negative Sample）和层次softmax（Hierarchical Softmax）则是两种加速训练的方法</strong>。</p>
<h1 id="工作流程"><a href="#工作流程" class="headerlink" title="工作流程"></a>工作流程</h1><p>CBOW的目标是根据上下文出现的词语来预测当前词的生成概率；而Skip-gram是根据当前词来预测上下文中各词的生成概率。</p>
<p><img src="/passages/2019-07-08-Word2Vec/CBOW模型.png" alt="CBOW模型">                                      <img src="/passages/2019-07-08-Word2Vec/Skip-gram模型.png" alt="CBOW模型"></p>
<p>其中$w(t)$是当前所关注的词，$w(t-2)、w(t-1)、w(t+1)、w(t+2)$是上下文中出现的词。这里前后滑动窗口大小均设为2。</p>
<p>CBOW和Skip-gram都可以表示成由输入层（Input）、映射层（Projection）和输出层（Output）组成的神经网络。</p>
<p>输入层中的每个词由独热编码方式表示，即所有词均表示成一个N维向量，其中N为词汇表中单词的总数。在向量中，每个词都将与之对应的维度置为1，其余维度的值均设为0。</p>
<p>在映射层（又称隐含层）中，K个隐含单元（Hidden Units）的取值可以由N维输入向量以及连接输入和隐含单元之间的N*K维权重矩阵计算得到。在CBOW中，还需要将各个输入词所计算出的隐含单元求和。</p>
<p>同理，输出层向量的值可以通过隐含层向量（K维），以及连接隐含层和输出层之间的K*N维权重矩阵计算得到。输出层也是一个N维向量，每维与词汇表中的一个单词相对应。最后，对输出层向量应用softmax激活函数，可以计算出每个单词的生成概率。Softmax函数定义为：</p>
<script type="math/tex; mode=display">
p(y=w_n|x) = \frac{e^{x_{n}}}{\sum_{k=1}^{N}e^{x_{k}}}</script><p>其中$x$代表N维的原始输出向量，$x_n$为在原始输出向量中，与单词$w_n$所对应维度的取值。</p>
<p>接下来的任务就是训练神经网络的权重，使得语料库中所有单词的整体生成概率最大化。从输入层到隐含层需要一个维度为N*K的权重矩阵，从隐含层到输入层需要一个维度K*N的权重矩阵，学习权重可以用反向传播算法实现。但由于Softmax中存在归一化项的缘故，推导出的迭代公式需要对词汇表中的所有单词进行遍历，使得每次迭代过程非常缓慢，因此需要改进。最终训练得到维度为N*K和K*N的两个权重矩阵之后，可以选择其中一个作为N个词的K维向量表示。</p>
<h2 id="负采样"><a href="#负采样" class="headerlink" title="负采样"></a>负采样</h2><p>最后的softmax分出来的类是整个词袋的大小，那么是不是可以把词袋大小减小，因为有些出现概率低的词我们根本可以不考虑。这就是负采样的核心思想。</p>
<p>假设我们有一个训练样本，中心词是$w$，它周围上下文共有$2c$个词，记为$context(w)$。由于这个中心词$w$的确和$content(w)$相关存在，因此它是一个真实的正例。通过Negative Sampling 采样，得到n个和$w$不同的中心词$w_i,i =1,2,…,n$，这样$context(w)$和$w_i$就组成了n个并不存在的负例。利用这一个正例和n个负例，进行二元逻辑回归，得到负采样对应的每个词$w_i$对应的模型参数$\theta_i$和每个词的词向量。整个过程相比Hierarchical Softmax简单。</p>
<p>但需要明确两个问题：（1）如何通过一个正例和n个负例进行二元逻辑回归？（2）如何进行负采样？</p>
<h3 id="梯度计算"><a href="#梯度计算" class="headerlink" title="梯度计算"></a>梯度计算</h3><p>这里我们将正例定义为$w_0$。</p>
<p>在逻辑回归中，正例期望满足：</p>
<script type="math/tex; mode=display">
P(context(w_0),w_i)=\sigma(x_{w_0}^T\theta^{w_i}),y_i=1,i=0</script><p>负期望满足：</p>
<script type="math/tex; mode=display">
P(context(w_0),w_i)=1-\sigma(x_{w_0}^T\theta^{w_i}),y_i=0,i=1,2,..n</script><p>其对应的对数似然函数为：</p>
<script type="math/tex; mode=display">
L= \sum_{i=0}^ny_ilog(\sigma(x_{w_0}^T\theta^{w_i}))+(1-y_i)log(1-\sigma(x_{w_0}^T\theta^{w_i}))</script><p>和层次Softmax类似，采用随机梯度上升法，仅仅每次只用一个样本更新梯度，来进行迭代更新得到我们需要的$x_{w_i},\theta^{w_i}$。求导得梯度表达式，用梯度上升法进行一步步的求解。</p>
<h3 id="负采样方法"><a href="#负采样方法" class="headerlink" title="负采样方法"></a>负采样方法</h3><p>word2vec采用的方法不复杂，如果词汇表的大小为V，那么我们就将一段长度为1的线段分成V份，每份对应词汇表中的一个词。当然每个词对应的线段长度是不一样的，高频词对应的线段长，低频词对应的线段短，每个词$w$的线段长度由下式决定：</p>
<script type="math/tex; mode=display">
len(w) =\frac{count(w)}{\sum_{\mu\in vocab}count(\mu)}</script><p>在word2vec中，分子和分母都取了3/4次幂如下：</p>
<script type="math/tex; mode=display">
len(w) =\frac{count(w)^{3/4}}{\sum_{\mu\in vocab}count(\mu)^{3/4}}</script><p>　在采样前，我们将这段长度为1的线段划分成$M$等份，这里$M&gt;&gt;V$，这样可以保证每个词对应的线段都会划分成对应的小块。而M份中的每一份都会落在某一个词对应的线段上。在采样的时候，我们只需要从$M$个位置中采样出$n$个位置就行，此时采样到的每一个位置对应到的线段所属的词就是我们的负例词。</p>
<p><img src="/passages/2019-07-08-Word2Vec/Negative_Sampling.png" alt="Negative Sampling"></p>
<p>在word2vec中，$M$取值默认为$10^8$</p>
<h2 id="层次softmax"><a href="#层次softmax" class="headerlink" title="层次softmax"></a>层次softmax</h2><p>Hierarchical Softmax，层次softmax是一种加速训练的技巧，要解决的问题是原来softmax的参数太多的问题，所以<strong>不管是层次softmax也好，还是负采样也好，都是对最后的softmax做一个处理</strong>。</p>
<p>层次softmax的核心内容是哈夫曼树（Huffman Tree）。树的核心概念是 <strong>出现概率越高的符号使用较短的编码（层次越浅），出现概率低的符号则使用较长的编码（层次越深）。</strong></p>
<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><p>使用霍夫曼树来替代传统的神经网络，可以提高模型训练的效率。但是如果我们的训练样本里的中心词$w$是一个很生僻的词，那么就得在霍夫曼树中辛苦的向下走很久了。负采样比之而言考虑了该问题，不再使用霍夫曼树。</p>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul>
<li>《百面机器学习》</li>
<li><a href="https://www.jianshu.com/p/d8bfaae28fa9" target="_blank" rel="noopener">word2vector的原理，结构，训练过程</a></li>
<li><a href="https://www.cnblogs.com/pinard/p/7249903.html" target="_blank" rel="noopener">word2vec原理</a></li>
</ul>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>笔试面试</tag>
        <tag>NLP</tag>
        <tag>Word2Vec</tag>
      </tags>
  </entry>
  <entry>
    <title>高斯混合模型</title>
    <url>/passages/2019-07-22-%E9%AB%98%E6%96%AF%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<h1 id="高斯混合模型"><a href="#高斯混合模型" class="headerlink" title="高斯混合模型"></a>高斯混合模型</h1><p>高斯混合模型（Gaussian Mixed Model，GMM）是一种常见的聚类算法，与K均值算法类似，同样使用了EM算法进行迭代计算。高斯混合模型假设每个簇的数据都符合高斯分布（又叫正态分布）。</p>
<h1 id="高斯混合模型的核心思想"><a href="#高斯混合模型的核心思想" class="headerlink" title="高斯混合模型的核心思想"></a>高斯混合模型的核心思想</h1><p>高斯混合模型的核心思想是，假设数据可以看作多个高斯分布中生成出来的。在该假设下，每个单独的分模型都是标准高斯模型，其均值$\mu_i$和方差$\sum_i$是待估计的参数。此外，每个分模型都还有一个参数$\pi_i$，可以理解为权重或生成数据的概率。高斯混合模型的公式为：</p>
<script type="math/tex; mode=display">
p(x) = \sum_{i=1}^K\pi_iN(x|\mu_i,\sum_i)</script><h1 id="高斯混合模型与K均值算法的异同"><a href="#高斯混合模型与K均值算法的异同" class="headerlink" title="高斯混合模型与K均值算法的异同"></a>高斯混合模型与K均值算法的异同</h1><p>高斯混合模型与K均值算法的相同点是，它们都是可用于聚类算法；都需要指定K值；都是使用EM算法来求解；都往往只能收敛于局部最优。<strong>而它相比于K均值算法的优点是，</strong>可以给出一个样本属于某类的概率是多少；不仅仅可以用于聚类，还可以用于概率密度的估计；并且可以用于生成新的样本点。</p>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>聚类</tag>
        <tag>面试笔试</tag>
      </tags>
  </entry>
  <entry>
    <title>特征工程知识点整理概述(二)</title>
    <url>/passages/2019-07-07-%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%E7%9F%A5%E8%AF%86%E7%82%B9%E6%95%B4%E7%90%86%E6%A6%82%E8%BF%B0-%E4%BA%8C/</url>
    <content><![CDATA[<h1 id="文本表示"><a href="#文本表示" class="headerlink" title="文本表示"></a>文本表示</h1><p>文本是一类非常重要的非结构化数据，如何表示文本数据一直是机器学习领域的一个重要研究方向。</p>
<h2 id="词袋模型（Bag-of-Words）"><a href="#词袋模型（Bag-of-Words）" class="headerlink" title="词袋模型（Bag of Words）"></a>词袋模型（Bag of Words）</h2><p>最基础的文本表示模型是词袋模型。顾名思义，就是将每篇文章看成一袋子词，并忽略每个词出现的顺序。具体地说，就是将整段文本以词为单位切分开，然后每篇文章可以表示成一个长向量，向量中的每一维代表一个单词，而该维对应的权重则反映了这个词在原文章中的重要程度。常用TF-IDF来计算权重。TF-IDF内容详见我的博客：<a href="https://nijunssdut.github.io/passages/2019-07-05-TF-IDF算法介绍/#more">TF-IDF算法介绍</a></p>
<p>将文章进行单词级别的划分有时候并不是一种好的做法，比如英文中的natural language processing（自然语言处理）一词，如果将natural，language，processing这三个词拆分开来，所表达的含义与三个词连续出现时大相径庭。通常，可以将连续出现的n个词$(n\le N)$组成的词组（N-gram）也作为一个单独的特征放到向量表示中去，构成N-gram模型。另外，同一个词可能有多种词性变化，却具有相似的含义。在实际应用中，一般会对单词进行词干抽取（word Stemming）处理，即将不同词性的单词统一成为同一词干形式。</p>
<h2 id="主题模型（Topic-Model）"><a href="#主题模型（Topic-Model）" class="headerlink" title="主题模型（Topic Model）"></a>主题模型（Topic Model）</h2><p>主题模型用于从文本库中发现有代表性的主题（得到每个主题上面词的分布特性），并且能够计算出每篇文章的主题分布。具体处理方法在后续的博文中楼主会详细介绍……</p>
<h2 id="词嵌入模型-（Word-Embedding）"><a href="#词嵌入模型-（Word-Embedding）" class="headerlink" title="词嵌入模型 （Word Embedding）"></a>词嵌入模型 （Word Embedding）</h2><p>词嵌入是一类将词向量化的模型的统称，核心思想是将每个词都映射成低维空间（通常K = 50~300维）上的一个稠密向量（Dense Vector）。K维空间的每一维也可以看作一个隐含的主题，只不过不像主题模型中的主题那样直观。</p>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul>
<li>《百面机器学习》</li>
</ul>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>笔试面试</tag>
        <tag>NLP</tag>
        <tag>文本表示</tag>
        <tag>特征工程</tag>
      </tags>
  </entry>
  <entry>
    <title>概率图模型概述</title>
    <url>/passages/2019-07-23-%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B%E6%A6%82%E8%BF%B0/</url>
    <content><![CDATA[<h1 id="概率图"><a href="#概率图" class="headerlink" title="概率图"></a>概率图</h1><p>概率图中的节点分为隐含节点和观测节点，边分为有向边和无向边。从概率论的角度，节点对应于随机变量，边对应于随机变量的依赖或相关关系，其中有向边表示单向的依赖，无向边表示相互依赖关系。</p>
<p>概率图模型分为贝叶斯网络（Bayesian Network）和马尔可夫网络（Markov Network）两大类。贝叶斯网络可以用一个有向图结构表示，马尔可夫网络可以表示成一个无向图的网络结构。更详细地说，概率图模型包括了朴素贝叶斯模型、最大熵模型、隐马尔可夫模型、条件随机场、主题模型等，在机器学习的诸多场景中都有着广泛的应用。</p>
<h1 id="马尔可夫网络的联合概率分布"><a href="#马尔可夫网络的联合概率分布" class="headerlink" title="马尔可夫网络的联合概率分布"></a>马尔可夫网络的联合概率分布</h1><p>在马尔可夫网络中，联合概率分布的定义为</p>
<script type="math/tex; mode=display">
P(x) = \frac{1}{Z}\prod_{Q \in C}\varphi_{Q}(X_Q)</script><p>其中$C$为图中最大团所构成的集合，$Z = \sum<em>{x} \prod</em>{Q \in C}\varphi<em>{Q}(X_Q)$为归一化因子，用来保证$P(x)$是被正确定义的概率，$\varphi</em>{Q}$是与团$Q$对应的势函数。势函数是非负的，并且应该在概率较大的变量上取得较大的值，例如指数函数</p>
<script type="math/tex; mode=display">
\varphi_{Q}(X_Q)=e^{-H_{Q}(x_Q)}</script><p>其中，</p>
<script type="math/tex; mode=display">
H_Q(x_Q)= \sum_{\mu,v \in Q,\mu \neq v}\alpha_{\mu,v}x_{\mu}x_v+\sum_{v \in Q}\beta_vx_v</script><p>对于图中所有节点$x={x_1,x_2,…,x_n}$所构成的一个子集，如果在这个子集中，任意两点之间都存在边相连，则这个子集中的所有节点构成了一个团。如果在这个子集中加入任意其他节点，都不能构成一个团，则称这样的子集构成了一个最大团。</p>
<p>对于由A，B，C，D四个点构成的四边形无向图，其联合概率分布为：</p>
<script type="math/tex; mode=display">
P(A,B,C,D)=\frac{1}{Z}e^{-H(A,B,C,D)}</script><h1 id="概率图表示"><a href="#概率图表示" class="headerlink" title="概率图表示"></a>概率图表示</h1><h2 id="解释朴素贝叶斯模型原理"><a href="#解释朴素贝叶斯模型原理" class="headerlink" title="解释朴素贝叶斯模型原理"></a>解释朴素贝叶斯模型原理</h2><p>朴素贝叶斯模型通过预测指定样本属于特定类别的概率$P(y_i|x)$来预测该样本的所属类别，即</p>
<script type="math/tex; mode=display">
y = \max_{y_i}P(y_i|x)</script><p>$P(y_i|x)$可以写成</p>
<script type="math/tex; mode=display">
P(y_i|x) = \frac{P(x|y_i)P(y_i)}{P(x)}</script><p>其中$x= (x_1,x_2,x_3,…,x_n)$为样本对应的特征向量，$P(x)$为样本的先验概率。对于特定的样本x和任意类别$y_i$，$P(x)$的取值均相同，在计算中可以被忽略。假设特征相互独立，$P(y_i)$可以通过训练样本统计得到，<strong>后验概率$P(x_j|y_i)$的取值决定了分类的结果。</strong>并且任意特征$x_j$都由$y_i$的取值所影响。</p>
<h2 id="解释最大熵模型的原理"><a href="#解释最大熵模型的原理" class="headerlink" title="解释最大熵模型的原理"></a>解释最大熵模型的原理</h2><p>信息是指人们对事物理解的不确定性的降低或消除，而<strong>熵是不确定性的度量，熵越大，不确定性也就越大。</strong></p>
<p>最大熵原理是概率模型学习的一个准则，指导思想是在满足约束条件的模型集合中选取熵最大的模型，即不确定性最大的模型。</p>
<p><strong>在对训练数据集一无所知的情况下，最大熵模型认为$P(y|x)$是符合均匀分布的。</strong></p>
<p>给定离散随机变量$x$和$y$上的条件概率分布$P(x|y)$，定义在条件概率分布上的条件熵为：</p>
<script type="math/tex; mode=display">
H(p) =  -\sum_{x,y}\tilde{P}(x)P(y|x)\log P(y|x)</script><p>其中$\tilde{P}(x)$为样本在训练数据集上的经验分布，即$x$的各个取值在样本中出现的频率统计。</p>
<p>当我们有了训练数据集之后，我们希望从中找到一些规律，从而消除一些不确定性，这时就需要用到特征函数$f(x,y)$。特征函数$f$描述了输入$x$和输出$y$之间的一个规律。为了使学习到的模型能够正确捕捉训练数据集中的特征，我们加入一个约束，使得特征函数$f(x,y)$关于经验分布$\tilde{P}(x,y)$的期望值与关于模型$P(y|x)$和经验分布$\tilde{P}(x)$的期望值相等。</p>
<script type="math/tex; mode=display">
E_{\tilde{P}}(f) = \sum_{x,y}\tilde{P}(x,y)f(x,y)</script><script type="math/tex; mode=display">
E_p(f) = \sum_{x,y}\tilde{P}(x)P(y|x)f(x,y)</script><p>综上，给定训练数据集$T={(x_1,y_1),(x_2,y_2),…,(x_N,y_N)}$，以及M个特征函数${f_i(x,y),i=1,2,…,M}$，最大熵模型的学习等价于约束最优化问题：</p>
<script type="math/tex; mode=display">
\max_{p}H(P) = -\sum_{x,y}\tilde{P}(x)P(y|x)\log P(y|x)
\\ s.t., E_{\tilde{P}}(f) = E_p(f), \forall i =1,2,...,M,
\\ \sum_{y}P(y|x) = 1</script><p>求解之后可以得到最大熵模型的表达形式为</p>
<script type="math/tex; mode=display">
P_w(y|x) = \frac{1}{Z}exp(\sum_{i=1}^{M}w_if_i(x,y))</script><p>最终，最大熵模型归结为学习最佳的参数$w$，使得$P_w(y|x)$最大化。</p>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul>
<li>《百面机器学习》</li>
</ul>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>概率图模型</tag>
      </tags>
  </entry>
  <entry>
    <title>K均值聚类</title>
    <url>/passages/2019-07-22-k%E5%9D%87%E5%80%BC%E8%81%9A%E7%B1%BB/</url>
    <content><![CDATA[<h1 id="K均值的基本思想"><a href="#K均值的基本思想" class="headerlink" title="K均值的基本思想"></a>K均值的基本思想</h1><p>k均值是最基础和最常用的聚类算法。它的基本思想是通过迭代方式寻找K个簇（cluster）的一种划分方案，使得聚类结果对应的代价函数最小。代价函数可以定义为各个样本距离所属簇中心点的误差平方和：</p>
<script type="math/tex; mode=display">
J(c,\mu) = \sum_{i=1}^{M}||x_i-\mu_{c_i}||^2</script><p>其中$x<em>i$代表第i个样本，$c_i$是$x_i$所属于的簇，$\mu</em>{c_i}$代表簇对应的中心点，$M$是样本总数。</p>
<h1 id="K均值算法的优缺点是什么？如何对其进行调优？"><a href="#K均值算法的优缺点是什么？如何对其进行调优？" class="headerlink" title="K均值算法的优缺点是什么？如何对其进行调优？"></a>K均值算法的优缺点是什么？如何对其进行调优？</h1><p>k均值算法有一些缺点，例如受初值和离群点的影响每次的结果不稳定、结果通常不是全局最优而是局部最优解、无法很好地解决数据簇分布差别比较大的情况（比如一类是另一类样本数量的100倍）、不太适用于离散分类等。但是瑕不掩瑜，k均值聚类的优点也很明显：主要体现在：对于大数据集，K均值聚类算法相对是可伸缩和高效的，它的计算复杂度是O(NKt)近乎线性，其中N是数据对象的数目，K是聚类的簇数。尽管算法经常以局部最优结束，但一般情况下达到的局部最优已经可以满足聚类的需求。</p>
<p><strong>K均值算法的调优一般可以从以下几个角度出发。</strong></p>
<p>（1）数据归一化和离群点处理</p>
<p>K均值聚类本质上是一种基于欧式距离度量的数据划分方法，<strong>均值和方差大的维度</strong>将对数据的聚类结果产生决定性的影响，所以未做归一化处理和统一单位的数据是无法直接参与运算和比较的。同时，离群点或者少量噪声数据就会对均值产生较大的影响，导致中心偏移，因此使用K均值聚类算法之前通常需要对数据做预处理。</p>
<p>（2）合理选择K值</p>
<p>K值的选择是K均值聚类最大的问题之一，这也是K均值聚类算法的主要缺点。K值的选择一般基于经验和多次实验结果。例如采用手肘法，K值越大，距离和越小。手肘法认为拐点就是K的最佳值。</p>
<p>了解：Gap Statistic算法</p>
<p>（3）采用核函数</p>
<p>传统的欧式距离度量方式，使得K均值算法本质上假设了各个数据簇的数据具有一样的先验概率，并呈现球形或者高维球形分布，这种分布在实际生活中并不常见。面对非凸的数据分布形状时，可能需要引入核函数来优化。<strong>核聚类方法的主要思想是通过一个非线性映射，将输入空间中的数据点映射到高位的特征空间中，并在新的特征空间中进行聚类。</strong></p>
<h1 id="针对K均值算法的缺点，有哪些改进的模型？"><a href="#针对K均值算法的缺点，有哪些改进的模型？" class="headerlink" title="针对K均值算法的缺点，有哪些改进的模型？"></a>针对K均值算法的缺点，有哪些改进的模型？</h1><p><strong>K均值算法的主要缺点：</strong></p>
<p>（1） 需要人工预先确定初始K值，且该值和真实的数据分布未必吻合。</p>
<p>（2） K均值只能收敛到局部最优，效果受到初始值影响很大。</p>
<p>（3） 易受到噪点的影响。</p>
<p>（4） 样本点只能被划分到单一的类中。</p>
<p><strong>K-means++算法：</strong></p>
<p>在原始K均值算法的随机选择聚集中心的基础上改进，后面过程中都是一样的。K-means++按照如下的思想选取K个聚类中心。假设已经选取了n个初始聚类中心（0&lt;n&lt;K），则在选择第n+1个聚类中心时，距离当前n个聚类中心越远的点会有更高的概率被选为第n+1个聚类中心。</p>
<p><strong>ISODATA算法：</strong></p>
<p><strong>当K值的大小不确定时，可以使用ISODATA算法。</strong>当遇到高维度、海量的数据集时，人们往往很难准确地估计出K的大小。ISODATA针对这个问题进行了改进。ISODATA的全称为迭代自组织数据分析法。</p>
<p>ISODATA算法在K均值算法的基础之上增加了两个操作：一是分裂操作，对应着增加聚类中心数；二是合并操作，对应减少聚类中心数。<strong>其缺点时需要指定的参数比较多。</strong>ISODATA算法的各个输入参数：</p>
<p>（1）预期的聚类中心数目$K_o$。最终输出的聚类中心数目常见范围是从$K_o$的一半，到两倍$K_o$。</p>
<p>（2）每个类所要求的最少样本数目$N_{min}$。如果分裂后会导致某个子类别包含样本数目小于该阈值，就不会对该类别进行分裂操作。</p>
<p>（3）最大方差Sigma。用于控制某个类别中样本的分散程度。当样本的分散程度超过这个阈值时，且分裂后满足（2），进行分裂操作。</p>
<p>（4）两个聚类中心之间所允许最小距离$D_{min}。$如果两个类靠的非常近（即这两个类别对应聚类中心之间的距离非常小），小于该阈值时，则对两个类进行合并操作。</p>
<p>如果希望样本不划分到单一的类中，可以使用模糊C均值或者高斯混合模型。</p>
<h1 id="最大期望算法（EM算法）"><a href="#最大期望算法（EM算法）" class="headerlink" title="最大期望算法（EM算法）"></a>最大期望算法（EM算法）</h1><p>K均值聚类的迭代算法实际上是一种最大期望算法。简称EM算法。EM算法解决的是在概率模型中含有无法观测的隐含变量情况下的参数估计问题。由于隐变量是未知的，无法直接通过最大似然估计求解参数，这时需要利用EM算法来求解。</p>
<p>EM算法框架总结如下，由以下两个步骤交替进行直到收敛：</p>
<p>（1）E步骤：计算隐变量的期望</p>
<script type="math/tex; mode=display">
Q_i(z^{(i)}) = P(z^{(i)}|x^{(i)},\theta)</script><p>（2） M步骤：最大化，目的是通过最大化这个下界可以使得待优化函数向更好的方向改进。</p>
<script type="math/tex; mode=display">
\theta = argmax\sum_{i=1}^{m}\sum_{z^{(i)}}Q_i(z^{(i)})\log\frac{P(x^{(i)},z^{(i)}| \theta)}{Q_i(z^{(i)})}</script><p>K均值算法等价于用EM算法求解含隐变量的最大似然问题。</p>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul>
<li>《百面机器学习》</li>
</ul>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>笔试面试</tag>
        <tag>聚类</tag>
        <tag>无监督学习</tag>
      </tags>
  </entry>
  <entry>
    <title>主题模型专题</title>
    <url>/passages/2019-07-25-%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B%E4%B8%93%E9%A2%98/</url>
    <content><![CDATA[<h1 id="主题模型产生背景"><a href="#主题模型产生背景" class="headerlink" title="主题模型产生背景"></a>主题模型产生背景</h1><p>基于词袋模型或N-gram模型的文本表示模型有一个明显的缺陷，就是无法识别出两个不同的词或词组具有相同的主题。因此，需要一种技术能够将具有相同主题的词或词组映射到同一维度上去，于是产生了主题模型。</p>
<p>假设有K个主题，我们就把任意文章表示成一个K维的主题向量，其中向量的每一维代表一个主题，权重代表这篇文章属于这个特定主题的概率。主题模型所解决的事情，<strong>就是从文本库中发现有代表性的主题(得到每个主题上面词的分布)，并且计算出每篇文章对应着哪些主题。</strong></p>
<h1 id="常见的主题模型"><a href="#常见的主题模型" class="headerlink" title="常见的主题模型"></a>常见的主题模型</h1><h2 id="pLSA-Probabilistic-Latent-Semantic-Analysis"><a href="#pLSA-Probabilistic-Latent-Semantic-Analysis" class="headerlink" title="pLSA (Probabilistic Latent Semantic Analysis)"></a>pLSA (Probabilistic Latent Semantic Analysis)</h2><p>pLSA是用一个生成模型来建模文章的生成过程，增加了主题模型，形成简单的贝叶斯网络，可以使用EM算法学习模型参数。</p>
<p>pLSA图模型如下图所示：</p>
<p><img src="/passages/2019-07-25-主题模型专题/pLSA.png" alt="pLSA模型"></p>
<p>假设有K个主题，M篇文章；对语料库中的任意文章d，假设该文章有N个词，则对于其中的每一个词，我们首先选择一个主题z，然后在当前主题的基础上生成一个词w。</p>
<p>（1）D代表文档，Z代表主题（隐含类别），W代表单词；$P(d_i)$表示文档$d_i$的出现概率，$P(z_k|d_i)$表示文档$d_i$中主题$z_k$的出现概率，$P(w_j|z_k)$表示给定主题$z_k$出现单词$w_j$的概率。</p>
<p>（2）每个主题在所有词项上服从多项分布，每个文档在所有主题上服从多项分布。</p>
<p>（3）给定文章d，生成词w的概率可以表示为：</p>
<script type="math/tex; mode=display">
p(w|d) = \sum_zp(w|z,d)p(z|d)</script><p>这里我们做一个简化，假设给定主题z的条件下，生成词w的概率是与特定的文章无关的，则公式可以简化为：</p>
<script type="math/tex; mode=display">
p(w|d) =\sum_zp(w|z)p(z|d)</script><p>（4）整个语料库中的文本生成概率可以用似然函数表示为：</p>
<script type="math/tex; mode=display">
L=\prod_m^M\prod_m^Mp(d_w,w_n)^{c(d_m,w_n)}</script><p>其中$p(d_m,w_n)$是在第m篇文章$d_m$中，出现单词$w_n$的概率，<strong>即联合概率分布</strong>；$c(d_m,w_m)$是在第m篇文章$d_m$中，单词$w_n$出现的次数。<strong>利用对数似然简化计算得：</strong></p>
<script type="math/tex; mode=display">
L = \sum_m^M\sum_m^Mc(d_m,w_m)\log(d_m,w_n)\\
= \sum_m^M\sum_n^Mc(d_m,w_n)\log\sum_k^Kp(d_m)p(z_k|d_m)p(w_n|z_k)</script><p>在上面的公式中，定义在文章上的主题分布$p(z_k|d_m)$和定义在主题上的词分布$p(w_n|z_k)$是待估计的参数。<strong>由于参数中包含的$z_k$是隐含变量（即无法直接观测到的变量），因此无法利用最大似然估计直接求解，可以利用最大期望算法（EM）来解决。</strong></p>
<p>（5）EM算法的求解过程</p>
<p>需要求解隐变量$z_k$的后验概率，目标函数建立将约束问题求解使用Lagrange乘子法处理。</p>
<p>关于EM算法迭代如下：</p>
<p><strong>M-step：</strong></p>
<script type="math/tex; mode=display">
p(w_j|z_k) = \frac{\sum_{i}n(d_i,w_j)p(z_k|d_i,w_j)}{\sum_{m=1}^M\sum_in(d_i,w_j)p(z_k|d_i,w_j)}</script><script type="math/tex; mode=display">
p(z_k|d_i) = \frac{\sum_{j}n(d_i,w_j)p(z_k|d_i,w_j)}{\sum_{k=1}^K\sum_jn(d_i,w_j)p(z_k|d_i,w_j)}</script><p><strong>E-step：</strong></p>
<script type="math/tex; mode=display">
p(z_k|d_i,w_j) = \frac{p(w_j|z_k)p(z_k|d_i)}{\sum_{i=1}^Kp(w_j|z_i)p(z_i|d_i)}</script><p>（6）pLSA总结</p>
<ul>
<li>pLSA应用于信息检索、过滤、自然语言处理等领域，pLSA考虑到词分布和主题分布，使用EM算法来学习参数。</li>
<li>虽然推导略显复杂，但最终公式简洁清晰，很符合直观理解，需用心琢磨；此外，推导过程使用了EM算法，也是学习EM算法的重要素材。</li>
</ul>
<h2 id="LDA"><a href="#LDA" class="headerlink" title="LDA"></a>LDA</h2><p>LDA可以看作是pLSA的贝叶斯版本，其文本生成过程与pLSA基本相同，<strong>不同的是为主题分布分别加了两个狄利克雷(Dirichlet)先验。</strong></p>
<p>为什么要加入狄利克雷先验呢？pLSA采用的是频率派思想，将每篇文章对应的主题分布$p(z_k|d_m)$和每个主题对应的词分布$p(w_n|z_k)$看作确定的未知常数，并可以求解出来；而LDA采用的是贝叶斯学派的思想，认为待估计的参数（主题分布和词分布）不再是一个固定的常数，而是服从一定分布的随机变量。这个分布符合一定的先验概率分布（即狄利克雷分布），并且在观察到样本信息之后，可以对先验分布进行修正，从而得到后验分布。<strong>LDA之所以选择狄利克雷分布作为先验分布，是因为它为多项式分布的共轭先验概率分布，后验概率依然服从狄利克雷分布，这样做可以为计算带来便利。</strong>下图为LDA的图模型，其中$\alpha,\beta$分别为两个狄利克雷分布的超参数，<strong>为人工设定</strong>。图中m为文章数，K为主题数，n表示文章的第n个词。</p>
<p><img src="/passages/2019-07-25-主题模型专题/LDA.png" alt="LDA"></p>
<p>语料库的生成过程为：对文本库中的每一篇文档$d_i$，采用以下操作：</p>
<p>（1）从超参数为$\alpha$的狄利克雷分布中抽样生成文档$d_i$的主题分布$\theta_i$。</p>
<p>（2）对文档$d_i$中的每一个词进行以下3个操作。</p>
<ul>
<li>从代表主题的多项式分布$\theta<em>i$中抽样生成它所对应的主题$z</em>{i,j}$。</li>
<li>从超参数为$\beta$的狄利克雷分布中抽样生成主题$z<em>{i,j}$对应的词分布$\psi</em>{z_{i,j}}$。</li>
<li>从代表词的多项式分布$\psi<em>{z</em>{i,j}}$中抽样生成词$w_{i,j}$。</li>
</ul>
<p>求解主题分布$\theta<em>i$以及词分布$\psi</em>{z_{i,j}}$的期望，可以用吉布斯采样(Gibbs Sampling)的方式实现。</p>
<p>首先随机给定每个单词的主题，然后在其他变量固定的情况下，根据转移概率抽样生成每个单词的新主题。对于每个单词来说，<strong>转移概率可以理解为：给定文章中的所有单词以及除自身以外其他所有单词的主题，在此条件下该单词对应为各个新主题的概率。</strong>最后，经过反复迭代，我们可以根据收敛后的采样结果计算主题分布和词分布的期望。</p>
<h3 id="如何确定LDA模型中的主题个数"><a href="#如何确定LDA模型中的主题个数" class="headerlink" title="如何确定LDA模型中的主题个数"></a>如何确定LDA模型中的主题个数</h3><p>在LDA中，主题的个数K是一个预先指定的超参数。对于模型超参数的选择，实践中的做法一般是将全部数据集分为训练集、验证集和测试集三个部分，然后利用验证集对超参数进行选择。</p>
<p>为了衡量LDA模型在验证集和测试集上的效果，需要寻找一个合适的评估指标。一个常用的评估指标是困惑度（perplexity）。在文档集合D上，模型的困惑度被定义为：</p>
<script type="math/tex; mode=display">
perplexity(D) = exp\{-\frac{\sum_{d=1}^Mlogp(w_d)}{\sum_{d=1}^MN_d}\}</script><p>其中M为文档的总数，$w_d$为文档d中单词所组成的词袋向量，$p(w_d)$为模型所预测的文档d的生成概率，$N_d$为文档d中单词的总数。</p>
<p>一开始，随着主题数的增多，模型在训练集和验证集的困惑度呈下降趋势，但当主题数目足够大的时候，会出现过拟合，导致困惑度指标在训练集上继续下降但在验证集上反而增长。这时可以取验证集的困惑度极小值点可能出现在主题数目非常大的时候，然而实际应用并不能承受如此大的主题数目，这时需要在实际应用中合理的主题数目范围内进行选择，比如选择合理范围内困惑度的下降明显变慢（拐点）的时候。</p>
<p>另一种方法是在LDA基础上融入分层狄利克雷过程（Hierarchical Dirichlet Process,HDP），构成一种非参数主题模型HDP-LDA。非参数主题模型的好处是不需要预先指定主题的个数，模型可以随着文档数目的变化而自动对主题个数进行调整；它的缺点是在LDA基础上融入HDP之后使得整个概率图模型更加复杂，训练速度也更加缓慢，因此在实际应用中还是经常采用第一种方法确定合适的主题数目。</p>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul>
<li><a href="https://www.cnblogs.com/softzrp/p/6964951.html" target="_blank" rel="noopener">主题模型（概率潜语义分析PLSA、隐含狄利克雷分布LDA）</a></li>
</ul>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>概率图模型</tag>
        <tag>pLSA</tag>
        <tag>LDA</tag>
      </tags>
  </entry>
  <entry>
    <title>朴素贝叶斯专题</title>
    <url>/passages/2019-07-24-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%B8%93%E9%A2%98/</url>
    <content><![CDATA[<h1 id="朴素贝叶斯算法"><a href="#朴素贝叶斯算法" class="headerlink" title="朴素贝叶斯算法"></a>朴素贝叶斯算法</h1><h2 id="“朴素”的含义"><a href="#“朴素”的含义" class="headerlink" title="“朴素”的含义"></a>“朴素”的含义</h2><p>朴素贝叶斯模型（Naive Bayesian Model）朴素的含义：建立在两个前提假设上：</p>
<ol>
<li><strong>特征之间相互独立</strong></li>
<li><strong>每个特征同等重要</strong></li>
</ol>
<p>然而这种属性独立性假设在实际情况中很难成立，但朴素贝叶斯仍能取得较好的效果原因在于：</p>
<p>（1）对于分类任务来说，只要各类别的条件概率排序正确、无需精准概率值即可导致正确分类；</p>
<p>（2）如果属性间依赖对所有类别影响相同，或依赖关系的影响能够相互抵消，则属性条件独立性假设在降低计算开销的同时不会对性能产生负面影响</p>
<h2 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h2><ol>
<li>假设现在有样本$x = (a_1,a_2,a_3,…a_n)$这个待分类项（并认为x里面是特征独立的）</li>
<li>再假设现在有分类目标$Y = {y_1,y_2,y_3,..y_n}$</li>
<li>那么$\max(P(y_1|x),P(y_2|x),P(y_3|x)…,P(y_n|x))$就是最终的分类类别</li>
<li>$P(y_i|x) = \frac{P(x|y_i)*P(y_i)}{P(x)}$</li>
<li>因为x对于每个分类目标来说都一样，所以就是求$\max(P(x|y_i)*P(y_i))$</li>
<li>$P(x|y_i)*p(y_i)= p(y_i)*\prod{P(a_i|y_i)}$</li>
<li>而具体的$P(a_i|y_i)$和$P(y_i)$都是能从训练样本中统计出来</li>
</ol>
<p>$P(a_i|y_i)$表示该类别下该特征出现的频率，$P(y_i)$表示全部类别中这个类别出现的概率。</p>
<h2 id="工作流程"><a href="#工作流程" class="headerlink" title="工作流程"></a>工作流程</h2><ol>
<li><p><strong>准备阶段</strong>   </p>
<p>确定特征属性，并对每个特征属性适当划分，然后由人工对一部分待分类项进行分类，形成训练样本。<strong>这一阶段是整个朴素贝叶斯分类中唯一需要人工完成的阶段</strong>，其质量对整个过程将有重要影响，分类器的质量很大程度上由特征属性、特征属性划分及训练样本质量决定。  </p>
</li>
<li><p><strong>训练阶段</strong></p>
<p>计算每个类别在训练样本中的出现频率以及每个特征属性划分对每个类别的条件概率估计</p>
</li>
<li><p><strong>应用阶段</strong></p>
<p>使用分类器进行分类，输入是分类器和待分类样本，输出是样本属于的分类类别</p>
</li>
</ol>
<h2 id="朴素贝叶斯的应用场景"><a href="#朴素贝叶斯的应用场景" class="headerlink" title="朴素贝叶斯的应用场景"></a>朴素贝叶斯的应用场景</h2><ol>
<li>文本分类/垃圾文本过滤/情感判别</li>
<li>多分类实时预测</li>
<li>推荐系统</li>
</ol>
<p>朴素贝叶斯和协同过滤是一对好搭档，协同过滤是强相关性，但泛化能力略弱，朴素贝叶斯和协同过滤一起，能增强推荐的覆盖度和效果。</p>
<h2 id="贝叶斯决策理论"><a href="#贝叶斯决策理论" class="headerlink" title="贝叶斯决策理论"></a>贝叶斯决策理论</h2><p>将分类看做决策，进行贝叶斯决策时考虑各类的先验概率和类条件概率，即后验概率。考虑先验概率意味着对样本总体的认识，考虑类条件概率是对每一类中某个特征出现频率的认识。由此不难发现，贝叶斯决策的理论依据就是贝叶斯公式。</p>
<ol>
<li>最小错误率贝叶斯决策<br>贝叶斯决策的基本理论依据就是贝叶斯公式，判决遵从最大后验概率。这种仅根据后验概率作决策的方式称为最小错误率贝叶斯决策，可以从理论上证明这种决策的平均错误率是最低的。</li>
<li>最小风险贝叶斯决策<br>另一种方式是考虑决策风险，加入了损失函数，称为最小风险贝叶斯决策。</li>
</ol>
<h2 id="朴素贝叶斯三种常用的分类模型"><a href="#朴素贝叶斯三种常用的分类模型" class="headerlink" title="朴素贝叶斯三种常用的分类模型"></a>朴素贝叶斯三种常用的分类模型</h2><p><strong>朴素贝叶斯的三个常用模型：高斯、多项式、伯努利。</strong></p>
<ol>
<li><p>高斯模型主要处理包含连续型变量的数据，使用高斯分布概率密度来计算类的条件概率密度；</p>
</li>
<li><p>多项式模型：</p>
<script type="math/tex; mode=display">
P(x_i|y_k) = \frac{N_{y_kx_i}+\alpha}{N_{y_k}+\alpha n}</script><p>其中$\alpha$是拉普拉斯平滑，加和的是属性出现的总次数，也防止了零概率问题。在文本分类问题中，反映一个词出现的词频，类似投骰子问题n次出现m次这个点数的场景。</p>
</li>
<li><p>伯努利模型：</p>
<p>伯努利模型特征的取值为布尔型，即出现为true，没有出现为false，在文本分类中，就是一个单词有没有在一个文档中出现。</p>
</li>
</ol>
<h1 id="朴素贝叶斯细节问题"><a href="#朴素贝叶斯细节问题" class="headerlink" title="朴素贝叶斯细节问题"></a>朴素贝叶斯细节问题</h1><h2 id="零概率问题"><a href="#零概率问题" class="headerlink" title="零概率问题"></a>零概率问题</h2><p><strong>描述：</strong>在计算实例的概率时，如果某个量x，在观察样本库（训练集）中没有出现过，会导致整个实例的概率结果为0。</p>
<p><strong>解决方案：</strong>通常解决这个问题的方法是要进行平滑处理，常用拉普拉斯修正。</p>
<p>拉普拉斯修正的含义是，在训练集中总共的分类数，用 N 表示；di 属性可能的取值数用 $N_i$ 表示，因此，</p>
<p>原来的先验概率$P(c)$的计算公式由：$P(c) = \frac{D_c}{D}$</p>
<p>被拉普拉斯修正为：$P(c) = \frac{D_c+1}{D+N}$</p>
<p>类的条件概率$P(x|c)$的计算公式由：$P(x<em>i|c) = \frac{D</em>{c,st}}{D_c}$</p>
<p>被拉普拉斯修正为：$P(x<em>i|c) = \frac{D</em>{c,st}+1}{D_c+N_i}$</p>
<h3 id="使用拉普拉斯平滑，拉普拉斯因子的大小如何确定？"><a href="#使用拉普拉斯平滑，拉普拉斯因子的大小如何确定？" class="headerlink" title="使用拉普拉斯平滑，拉普拉斯因子的大小如何确定？"></a>使用拉普拉斯平滑，拉普拉斯因子的大小如何确定？</h3><p>朴素贝叶斯中的拉普拉斯因子$\alpha$无法通过公式求出最优大小，需要根据程序员的经验去设置，使用交叉验证的方式求取最优大小。</p>
<h2 id="下溢问题"><a href="#下溢问题" class="headerlink" title="下溢问题"></a>下溢问题</h2><p><strong>问题描述：</strong>在计算过程中，需要对特定分类中各个特征出现的概率进行连乘，小数相乘，越乘越小，造成下溢出，计算结果变成0。</p>
<p><strong>解决方案：</strong>通过log运算增大概率的绝对值。log运算不会影响函数的趋势和极值只是扩大值得范围。将小数的乘法操作转化为取对数后的加法操作，规避了变为零的风险同时并不影响分类结果。</p>
<h2 id="异常值敏感问题"><a href="#异常值敏感问题" class="headerlink" title="异常值敏感问题"></a>异常值敏感问题</h2><p>朴素贝叶斯是一种对异常值不敏感的分类器，保留数据中的异常值，常常可以保持贝叶斯算法的整体精度，如果对原始数据进行降噪训练，分类器可能会因为失去部分异常值的信息而导致泛化能力下降。</p>
<p><strong>异常值不敏感原因：</strong>可能是因为朴素贝叶斯分类器是一个概率模型，如果输入是一个正常的样本，则异常值并不会影响到正常样本的后验概率。因为对于正常样本而言$p(x|y_i)*p(y_i)=p(y_i)\prod_j{p(x_j|y_i)}$，其中$x_j$是正常的，并不会使用到异常值。如果是一个异常的$p(x_j|y_i)$，反而已有的异常值可以帮助到该异常样本更好的分类。</p>
<p><strong>异常值有影响的情况：</strong>如果是对于<strong>连续型属性的异常值</strong>则会产生对分类器产生一定的影响，因贝叶斯对连续值的处理往往是通过估计其概率分布的参数，若有异常值存在则其概率分布将会产生偏移。若是分类变量则之间统计出现次数是不会产生偏移的。</p>
<h2 id="缺失值敏感问题"><a href="#缺失值敏感问题" class="headerlink" title="缺失值敏感问题"></a>缺失值敏感问题</h2><p><strong>不敏感</strong></p>
<p><strong>原因：</strong>朴素贝叶斯算法能够处理缺失的数据，<strong>在算法的建模时和预测时数据的属性都是单独处理的</strong>。因此如果一个数据实例缺失了一个属性的数值，在建模时将被忽略，不影响类条件概率的计算，在预测时，计算数据实例是否属于某类的概率时也将忽略缺失属性，不影响最终结果。</p>
<h2 id="数据的属性是连续型变量的情况"><a href="#数据的属性是连续型变量的情况" class="headerlink" title="数据的属性是连续型变量的情况"></a>数据的属性是连续型变量的情况</h2><p>当朴素贝叶斯算法数据的属性为连续型变量时，有<strong>两种方法</strong>可以计算属性的类条件概率。</p>
<p>第一种方法是把一个<strong>连续的属性离散化</strong>，然后用相应的离散区间替换连续属性值，之后用频率去表示类条件概率。<strong>但这种方法不好控制离散区间划分的粒度。</strong>如果粒度太细，就会因为每个区间内训练记录太少而不能对做出可靠估计，如果粒度太粗，那么有些区间就会有来自不同类的记录，因此失去了正确的决策边界。</p>
<p>第二种方法是假设连续变量服从某种概率分布，然后<strong>使用训练数据估计分布的参数</strong>，例如可以使用高斯分布来表示连续属性的类条件概率分布。</p>
<script type="math/tex; mode=display">
P(X_i = x_i|Y=y_i) =\frac{1}{\sqrt{2\pi\sigma_{i,j}}}e^{-\frac{(x_i-\mu_{i,j})^2}{2\sigma_{i,j}^2}}</script><p>其中$\mu<em>{i,j}$为类$y_j$的所有训练记录关于$X_i$的样本均值估计，$\sigma</em>{i,j}^2$为类$y_i$的所有训练记录关于$X_i$的样本方差估计。通过高斯分布估计出类条件概率。</p>
<h2 id="高度相关的特征对朴素贝叶斯的影响"><a href="#高度相关的特征对朴素贝叶斯的影响" class="headerlink" title="高度相关的特征对朴素贝叶斯的影响"></a>高度相关的特征对朴素贝叶斯的影响</h2><p>假设有两个特征高度相关，相当于该特征在模型中发挥了两次作用（计算两次条件概率），使得朴素贝叶斯获得的结果向该特征所希望的方向进行了偏移，影响了最终结果的准确性，所以朴素贝叶斯算法应先处理特征，把相关特征去掉。</p>
<h2 id="朴素贝叶斯的增量计算"><a href="#朴素贝叶斯的增量计算" class="headerlink" title="朴素贝叶斯的增量计算"></a>朴素贝叶斯的增量计算</h2><p>传统的贝叶斯方法在有新的训练样本加入时，需要重新学习已经学习过的样本，耗费大量时间。增量计算就是在原有分类器的基础之上，自主选择学习新的文本来修正分类器。因为<strong>朴素贝叶斯在训练过程中实际只需要计算出各个类别的概率（先验）和各个特征的类条件概率</strong>，这些概率值可以快速的根据增量数据进行更新，无需重新全量训练，所以其十分适合增量计算，该特性可以使用在超出内存的大量数据计算和随时间等（流数据）获取数据的计算中。</p>
<h1 id="朴素贝叶斯总结"><a href="#朴素贝叶斯总结" class="headerlink" title="朴素贝叶斯总结"></a>朴素贝叶斯总结</h1><h2 id="朴素贝叶斯是高偏差低方差"><a href="#朴素贝叶斯是高偏差低方差" class="headerlink" title="朴素贝叶斯是高偏差低方差"></a>朴素贝叶斯是高偏差低方差</h2><p>在统计学习框架下，大家刻画模型复杂度的时候，有这么个观点，认为Error = Bias+Variance。这里的Error大概可以理解为模型的预测错误率，是有两部分组成的，一部分是由于模型太简单而带来的估计不准确的部分（Bias），另一部分是由于模型太复杂而带来的更大的变化空间和不确定性（Variance）。</p>
<p>Error反映的是整个模型的准确度，Bias反映的是模型在样本上的输出与真实值之间的误差，即模型本身的精准度，Variance反映的是模型每一次输出结果与模型输出期望（平均值）之间的误差，即模型的稳定性，数据是否集中。</p>
<p>对于朴素贝叶斯，它简单的假设了各个数据之间是无关的，是一个被严重简化了的模型，对于复杂模型，充分拟合了部分数据，使得他们的偏差较小，而由于对部分数据的过度拟合，对于部分数据预测效果不好，整体来看可能引起方差较大，简单模型与之相反，大部分场合偏差部分大于方差部分，也就是高偏差低方差。</p>
<p>在实际中，为了让Error尽量小，我们在选择模型的时候需要平衡Bias和Variance所占的比例，也就是平衡over-fitting和under-fitting。</p>
<h2 id="朴素贝叶斯的优缺点"><a href="#朴素贝叶斯的优缺点" class="headerlink" title="朴素贝叶斯的优缺点"></a>朴素贝叶斯的优缺点</h2><p><strong>优点：</strong></p>
<ol>
<li>对数据的训练快，分类也快</li>
<li>对缺失数据不太敏感，对异常值也不太敏感，算法也比较简单</li>
<li>对小规模的数据表现很好，能够处理多分类任务，适合增量式训练，尤其是数据量超出内存时，可以一批批的去增量训练</li>
</ol>
<p><strong>缺点：</strong></p>
<ol>
<li>由于朴素贝叶斯的“朴素”特点，所以会带来一些准确率上的损失。</li>
<li>由于我们是通过先验和数据来决定后验的概率从而决定分类，所以分类决策存在一定的错误率。</li>
<li>对输入数据的表达形式很敏感。（离散的类别之间统计频率即可，连续值就要估计概率分布。）</li>
</ol>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul>
<li><a href="https://blog.csdn.net/weixin_44915167/article/details/89363034" target="_blank" rel="noopener">机器学习面试题之NB——朴素贝叶斯</a></li>
</ul>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>概率图模型</tag>
        <tag>贝叶斯网络</tag>
      </tags>
  </entry>
  <entry>
    <title>马尔可夫模型</title>
    <url>/passages/2019-07-26-%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<h1 id="知识背景"><a href="#知识背景" class="headerlink" title="知识背景"></a>知识背景</h1><h2 id="马尔可夫链"><a href="#马尔可夫链" class="headerlink" title="马尔可夫链"></a>马尔可夫链</h2><p>马尔可夫过程是满足无后效性的随机过程。假设一个随机过程中，$t<em>n$时刻的状态$x_n$的条件分布，仅仅与其前一个状态$x</em>{n-1}$有关，即$P(x<em>n|x_1,x_2,…x</em>{n-1})=P(x<em>n|x</em>{n-1})$，则将其称为马尔可夫过程，时间和状态的取值都是离散的马尔可夫过程也称为马尔可夫链。</p>
<h2 id="隐马尔可夫模型（HMM）"><a href="#隐马尔可夫模型（HMM）" class="headerlink" title="隐马尔可夫模型（HMM）"></a>隐马尔可夫模型（HMM）</h2><p>隐马尔可夫模型是对含有未知参数(隐状态)的马尔可夫链进行建模的生成模型，概率图模型如下图所示。</p>
<p><img src="/passages/2019-07-26-马尔可夫模型/Hidden Markov Model.png" alt="Hidden Markov Model"></p>
<p>在简单的马尔可夫模型中，所有状态对于观测者都是可见的，因此在马尔可夫模型中仅仅包括状态间的转移概率。而在隐马尔可夫模型中，隐状态$x_i$对于观测者而言是不可见的，观测者能观测到的只有每个隐状态$x_i$对应的输出$o_i$，而观测状态$o_i$的概率分布仅仅取决于对应的隐状态$x_i$。在隐马尔可夫模型中，参数包含了<strong>隐状态间的转移概率、隐状态到观测状态的输出概率、隐状态$x$的取值空间、观测状态$o$的取值空间以及初始状态的概率分布。</strong></p>
<h3 id="隐马尔可夫模型三个基本问题与相应的算法"><a href="#隐马尔可夫模型三个基本问题与相应的算法" class="headerlink" title="隐马尔可夫模型三个基本问题与相应的算法"></a>隐马尔可夫模型三个基本问题与相应的算法</h3><p>前向、后向算法解决的是评估问题，即给定一个模型，求某特定观测序列的概率，用于评估该序列最匹配的模型。<strong>（概率计算问题）</strong></p>
<p>Baum-Welch算法解决的是模型训练问题，求解使得该观测序列概率最大的模型参数，即参数估计，是一种无监督的训练方法，主要通过EM迭代实现。<strong>（学习问题）</strong></p>
<p>维特比（Viterbi）算法解决的是给定一个模型和某个特定的输出序列，求最可能产生这个输出的状态序列。例如，通过海藻变化（输出序列）来观测天气（状态序列），<strong>是预测问题，通信中的解码问题。</strong></p>
<h1 id="隐马尔可夫对中文分词问题建模与训练"><a href="#隐马尔可夫对中文分词问题建模与训练" class="headerlink" title="隐马尔可夫对中文分词问题建模与训练"></a>隐马尔可夫对中文分词问题建模与训练</h1><p>例如有3个不同的葫芦，每个葫芦里有好药和坏药若干，现在从3个葫芦中按照以下规则倒出药来。</p>
<p>（1）随机挑选一个葫芦。</p>
<p>（2）从葫芦里倒出一颗药，记录是好药还是坏药后将药放回。</p>
<p>（3）从当前葫芦依照一定的概率转移到下一个葫芦。</p>
<p>（4）重复步骤（2）和（3）。</p>
<p>在整个过程中，我们并不知道每次拿到得是哪一个葫芦。用隐马尔可夫模型来描述以上过程，隐状态就是当前是哪一个葫芦，隐状态的取值空间为{葫芦1，葫芦2，葫芦3}，观测状态的取值空间为{好药，坏药}，初始状态的概率分布就是第（1）步随机挑选葫芦的概率分布，隐状态间的转移概率就是从当前葫芦转移到下一个葫芦的概率，而隐状态到观测状态的输出概率就是每个葫芦里好药和坏药的概率。记录下来药的顺序就是观测状态的序列，而每次拿到的葫芦的顺序就是隐状态的序列。</p>
<p>隐马尔可夫模型通常用来解决序列标注问题，因此也可以将分词问题转化为一个序列标注问题来进行建模。例如可以对中文句子中每个字做以下标注：B表示一个词开头的第一个字，E表示一个词结尾的最后一个字，M表示一个词中间的字，S表示一个单字词，则隐状态的取值空间为{B,E,M,S}。同时对隐状态的转移概率可以给出一些先验知识，B和M后面只能是M或者E，S和E后面只能是B或者S。而每个字就是模型中观测状态，取值空间为语料中的所有中文字。完成建模之后，使用语料进行训练可以分有监督训练和无监督训练。有监督训练即对语料进行标注，相当于根据经验得到了语料的所有隐状态信息，然后就可以用简单的计数法来对模型中的概率分布进行极大似然估计。无监督训练可以用Baum-Welch算法，同时优化隐状态序列和模型对应的概率分布。</p>
<h1 id="因子图与马尔可夫逻辑网"><a href="#因子图与马尔可夫逻辑网" class="headerlink" title="因子图与马尔可夫逻辑网"></a>因子图与马尔可夫逻辑网</h1><h2 id="马尔可夫逻辑网"><a href="#马尔可夫逻辑网" class="headerlink" title="马尔可夫逻辑网"></a>马尔可夫逻辑网</h2><p>一个马尔可夫逻辑网就是一个每个准则都有权重的一阶逻辑知识库，可看成是构建马尔可夫逻辑网络的模板。从概率的视角看，马尔可夫逻辑网提供一种简洁的语言来定义大型马尔可夫网，能灵活地、模块化地与大量知识合并；从一阶逻辑的视角看，马尔可夫逻辑网能健全地处理不确定性、容许有瑕疵甚至矛盾的知识库，降低脆弱性。有许多统计关系学习领域的重要任务，如集合分类、链接预测、链接聚合、社会网络建模和对象识别，都自然而然地成为运用马尔科夫逻辑网推理和学习的实例。</p>
<p>马尔可夫网（也叫马尔可夫随机场）是随机变量集$x=x_1,x_2,…,x_n$的联合分布模型，它由一个无向图G和一个势函数$\Psi_k$集合组成，每个随机变量是图上的节点，<strong>图的每个团在模型中都有一个势函数，势函数是一个非负实函数，它代表了相应的团的状态。</strong>马尔可夫网的联合分布如下：</p>
<script type="math/tex; mode=display">
P(X= x) =\frac{1}{Z}\prod_k\Psi_k(x_{\{k\}})</script><p>其中$x<em>$是团中随机变量的状态，Z也叫配分函数（态和），定义为$\sum</em>{x\in X}\prod<em>k\Psi_k(x</em>)$。将马尔可夫网络中每个团的势状态的所有特征值加权后求和再取幂，就可方便地表示成对数线性模式</p>
<script type="math/tex; mode=display">
P(X=x) = \frac{1}{Z}\exp(\sum_jw_jf_j(x))</script><p>特征函数可以是表示状态的任何实函数。公式是势最直接的表示，其中每个团每个可能的状态都有一个对应的特征值 $f_j(x)$，它的权重是$w_j$，这种表示方法与团数量的幂相关。可是，我们可以自由地运用一些方法比如状态的逻辑函数等减少特征值数量，特别在团数量很大时能相比势函数方式提供一种更简洁的表示形式。马尔可夫逻辑网络就是利用了这一方式。</p>
<h2 id="因子图"><a href="#因子图" class="headerlink" title="因子图"></a>因子图</h2><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>概率图模型</tag>
        <tag>无向图</tag>
      </tags>
  </entry>
  <entry>
    <title>决策树专题</title>
    <url>/passages/2019-07-27-%E5%86%B3%E7%AD%96%E6%A0%91%E4%B8%93%E9%A2%98/</url>
    <content><![CDATA[<h1 id="决策树的构建过程"><a href="#决策树的构建过程" class="headerlink" title="决策树的构建过程"></a>决策树的构建过程</h1><p>构建步骤如下：</p>
<ol>
<li>将所有的特征看成一个一个的节点</li>
<li>遍历每个特征的每一种分割方式，找到最好的分割点；将数据划分为不同的子节点，eg:N1，N2…；计算划分之后所有子节点的“纯度”信息；</li>
<li>对第二步产生的分割，选择出最优的特征以及最优的划分方式；得出最终的子节点：N1，N2…Nm；</li>
<li>对子节点N1、N2…Nm分别继续执行2-3步，直到每个最终的子节点都足够‘纯’。</li>
</ol>
<h1 id="决策树的原理"><a href="#决策树的原理" class="headerlink" title="决策树的原理"></a>决策树的原理</h1><p>决策树是一类常见的机器学习方法，它是基于树的结构进行决策的，决策过程通常会进行一系列的判断或者子决策。</p>
<p>每次做决策时根据哪一个属性呢，即如何选择最优划分属性，一般而言，随着划分过程不断进行，我们希望决策树的分支节点所包含的样本尽可能属于同一个类别，即节点的“纯度（purity）”越来越高。</p>
<p>决策树学习算法包含特征选择、决策树的生成与剪枝过程。决策树的学习算法通常是递归地选择最优特征，并用最优特征对数据集进行分割。开始时，构建根节点，选择最优特征，该特征有几种值就分割为几个子集，每个子集分别调用此方法，返回结点，返回的结点就是上一层的子结点。直到所有特征都已经用完，或者数据集只有一维特征为止。</p>
<h2 id="信息熵"><a href="#信息熵" class="headerlink" title="信息熵"></a>信息熵</h2><p>假设当前样本集合D中有n类样本${x_1,x_2,……,x_n}$，第i类样本在样本集合D中所占的比例为$p(x_i)$，则熵定义为信息的期望值，$x_i$的信息定义为：</p>
<script type="math/tex; mode=display">
l(x_i)= -\log_2p(x_i)</script><p>而样本集合D的信息熵定义为：</p>
<script type="math/tex; mode=display">
Ent(D) = -\sum_{i=1}^np(x_i)\log_2p(x_i)</script><p>$Ent(D)$的值越小，则D的纯度越高。</p>
<h2 id="信息增益"><a href="#信息增益" class="headerlink" title="信息增益"></a>信息增益</h2><p>假定离散属性a有k个可能的取值{a1,a2,……,ak}，若使用a来对样本集D进行划分，则会产生k个分支节点，其中第i个分支节点包含了D中所有在属性a上取值ai的样本，记为$D_i$，我们可根据公式求得第i个分支节点的信息熵记为$Ent(D_i)$，第i个分支节点样本集$D_i$占样本集合D总的样本比例记为$p(D_i) = D_i/D$，父节点的信息熵记为$Ent(D)$，则用属性a对样本D进行划分所获得的“信息增益”为：</p>
<script type="math/tex; mode=display">
Gain(D,a)= Ent(D)-\sum_{i=1}^kp(D_i)Ent(D_i)</script><p>一般而言，信息增益越大，表现使用属性a来进行划分所获得的“纯度提升”越大。</p>
<h2 id="信息增益率"><a href="#信息增益率" class="headerlink" title="信息增益率"></a>信息增益率</h2><p>如果使用信息增益去对决策树进行划分，可能出现每个分支节点只包含一个样本，这些分支节点的纯度已经达到最大，但是，这样的决策树显然不具备泛化能力，无法对新样本进行有效的预测。</p>
<p>实际上，信息增益准则对可取值数目较多的属性有所偏好，为减少这种偏好可能带来的不利影响，因此提出了信息增益率的概念：</p>
<script type="math/tex; mode=display">
Gain\_ration(D,a) = Gain(D,a)/IV(a)\\
IV(a) = -\sum_{i =1}^kp(D_i)\log_2(D_i)</script><p>属性$a$的可能取值数目越多，则IV(a)的值通常会越大。</p>
<h2 id="基尼指数"><a href="#基尼指数" class="headerlink" title="基尼指数"></a>基尼指数</h2><p>基尼指数定义：</p>
<script type="math/tex; mode=display">
Gini(D) = \sum_{k=1}^Kp_k(1-p_k)</script><p>基尼指数反映了从数据集D中随机抽取两个样本，其类别标记不一致的概率，因此Gini(D)越小，则数据集D的纯度越高，属性a的基尼指数定义为：</p>
<script type="math/tex; mode=display">
Gini_index(D,a) = \sum_{i=1}^kp(D_i)Gini(D_i)</script><p>于是在候选集合中，选择那个使得划分后基尼指数最小的属性作为最优划分属性。</p>
<h1 id="常用的决策树算法"><a href="#常用的决策树算法" class="headerlink" title="常用的决策树算法"></a>常用的决策树算法</h1><p>常用的决策树算法有ID3，C4.5和CART。</p>
<p><strong>ID3：</strong>以信息增益为准则来选择划分属性，<strong>多叉树</strong>。</p>
<p><strong>C4.5：</strong>使用信息增益率来进行属性的选择，<strong>多叉树</strong>。</p>
<p><strong>CART：</strong>使用基尼指数来选择划分属性，<strong>二叉树</strong>。</p>
<h2 id="C4-5对ID3做了哪些改进"><a href="#C4-5对ID3做了哪些改进" class="headerlink" title="C4.5对ID3做了哪些改进"></a>C4.5对ID3做了哪些改进</h2><p>ID3算法是采用信息增益作为评价标准进行分支的决策树算法。</p>
<p><strong>ID3的缺点：</strong></p>
<ol>
<li>对于具有很多值的属性它是非常敏感的，例如，如果我们数据集中的某个属性值对不同的样本基本上是不相同的，甚至更极端点，对于每个样本都是唯一的，如果我们用这个属性来划分数据集，它会得到很大的信息增益，但是，这样的结果并不是我们想要的。</li>
<li><strong>ID3算法不能处理具有连续值的属性。</strong></li>
<li><strong>ID3算法不能处理属性具有缺失值的样本。</strong></li>
<li>由于按照该算法会生成很深的树，所以容易产生过拟合现象。</li>
</ol>
<p>C4.5算法主要对ID3做出了以下方面的改进。</p>
<ol>
<li>用信息增益率来选择属性，克服了用信息增益来选择属性时偏向选择值多的属性的不足。</li>
<li><strong>可以处理连续数值型属性。</strong></li>
<li><strong>缺失值处理：</strong>对于某些采样数据，可能会缺少属性值。在这种情况下，处理缺少属性值的通常做法是赋予该属性的常见值，或者属性均值。另外一种比较好的方法是为该属性的每个可能值赋予一个概率，即将该属性以概率形式赋值。这样处理的目的是计算信息增益，使得这种属性值缺失的样本也能处理。</li>
</ol>
<p><strong>C4.5的缺点：</strong></p>
<ol>
<li>算法低效，在构造树的过程中，需要对数据集进行多次的顺序扫描和排序，因而导致算法的低效。</li>
<li>内存受限，适合于能够驻留于内存的数据集，当训练集大得无法在内存容纳时程序无法运行。</li>
</ol>
<h2 id="C4-5算法处理连续数值型属性"><a href="#C4-5算法处理连续数值型属性" class="headerlink" title="C4.5算法处理连续数值型属性"></a>C4.5算法处理连续数值型属性</h2><p>对于连续分布的特征，其处理方法是：</p>
<p>先把连续属性转换为离散属性再进行处理。虽然本质上属性的取值是连续的，但对于有限的采样数据它是离散的，如果有N条样本，那么我们有N-1种离散化的方法：$&lt;=v_j$的分到左子树，$&gt;v_j$的分到右子树。计算这N-1种情况下最大的信息增益率。另外，对于连续属性先进行排序（升序），只有在决策属性发生改变的地方（即分类发生了变化）才需要切开，这可以显著减少运算量。<strong>经证明，在决定连续特征的分界点时采用增益这个指标，而选择属性的时候才使用增益率这个指标能选择出最佳分类特征。</strong></p>
<p>对连续属性的处理如下：</p>
<ol>
<li>对特征的取值进行升序排序；</li>
<li>两个特征取值之间的中点作为可能的分裂点，将数据集分为两部分，计算每个可能的分裂点的信息增益。优化算法就是只计算分类属性发生改变的那些特征取值；</li>
<li>选择修正后信息增益最大的分裂点作为该特征的最佳分裂点；</li>
<li>计算最佳分裂点的信息增益率作为特征的信息增益率。注意，此处需对最佳分裂点的信息增益进行修正：减去$\log_2(N-1)/|D|$（N是连续特征的取值个数，D是训练数据数目，此修正的原因在于：当离散属性和连续属性并存时，C4.5算法倾向于选择连续特征做最佳树分裂点）</li>
</ol>
<h2 id="C4-5与CART的区别"><a href="#C4-5与CART的区别" class="headerlink" title="C4.5与CART的区别"></a>C4.5与CART的区别</h2><p>两者都是决策树，但CART既可以做分类，又可以做回归，而C4.5只能用于分类。</p>
<p>C4.5是构造决策树来发现数据中蕴涵的分类规则，是一种通过划分特征空间逼近离散函数值的方法。C4.5是基于ID3的改进算法，使用信息增益率作为划分依据。分类规则是互斥且完备的，所谓互斥即每一条样本记录不会同时匹配上两条分类规则，所谓完备即每条样本记录都在决策树中都能匹配上一条规则。</p>
<p>CART本质是对特征空间进行二元划分（即CART生成的决策树是一棵二叉树），并能够对标量属性与连续属性进行分裂。在对标量进行划分时，分为等于该属性和不等于该属性；对连续进行划分时，分为大于和小于。<strong>并且在分类的时候是采用GINI作为衡量标准，而不是信息增益了；而在回归时，是使用均方误差作为评价。</strong></p>
<p><strong>CART对于特征的利用是可以重复的，而作为分类的C4.5则是不能重复利用特征的。</strong></p>
<h2 id="CART树对离散特征取值数目-gt-3的特征如何处理"><a href="#CART树对离散特征取值数目-gt-3的特征如何处理" class="headerlink" title="CART树对离散特征取值数目&gt;=3的特征如何处理"></a>CART树对离散特征取值数目&gt;=3的特征如何处理</h2><p>因为CART树是二叉树，所以对于样本的有N&gt;=3个取值的离散特征的处理时也只能有两个分支，这就要通过组合人为的创建二取值序列并取GiniGain最小者作为树分叉决策点。</p>
<p>如某特征值具有[“young”,”middle”,”old”]三个取值，那么二分序列会有如下3种可能性（空集和满集在CART分类中没有意义）:</p>
<p>[((‘young’,),(‘middle’,’old’)),((‘middle’,),(‘young’,’old’)),((‘old’,),(‘young’,’middle’))]</p>
<p>采用CART算法，就需要分别计算按照上述List中的二分序列做分叉时的Gini指数，然后选取产生最小的GiniGain的二分序列做该特征的分叉二值序列参与树构建的递归。</p>
<p>因此CART不适用于离散特征有过多个取值可能的场景。此时，若定要使用CART，则最好预先人为的将离散特征的取值缩减。</p>
<p>那么对于二分后的左右分支，如果特征取值tuple中的元素多于2个，该特征还可以继续参与当前子数据集的二分。</p>
<h1 id="决策树的剪枝"><a href="#决策树的剪枝" class="headerlink" title="决策树的剪枝"></a>决策树的剪枝</h1><h2 id="决策树剪枝方法"><a href="#决策树剪枝方法" class="headerlink" title="决策树剪枝方法"></a>决策树剪枝方法</h2><h3 id="预剪枝"><a href="#预剪枝" class="headerlink" title="预剪枝"></a>预剪枝</h3><p>通过提前停止树的构建而对树剪枝，一旦停止，节点就是树叶，该树叶表示子集包含最频繁的类。</p>
<p><strong>常用剪枝条件：</strong></p>
<ol>
<li>定义一个高度，当决策树达到给高度时就停止决策树的生长；</li>
<li>定义一个阈值，当达到某个节点的实例个数小于阈值时就可以停止决策树的生长；</li>
<li>定义一个阈值，通过计算每次扩张对系统性能的增益，并比较增益值与该阈值大小来决定是否停止决策树的生长。</li>
</ol>
<p><strong>缺点：</strong>这样做决策树无法到最优，也无法得到比较好的效果。</p>
<h3 id="后剪枝"><a href="#后剪枝" class="headerlink" title="后剪枝"></a>后剪枝</h3><p>它首先构造完整的决策树，允许树过度拟合训练数据，然后对那些置信度不够的结点子树用叶子结点来代替，该叶子的类标号用该结点子树中最频繁的类标记。</p>
<ol>
<li>错误率降低剪枝</li>
<li>悲观错误剪枝</li>
<li>代价复杂度剪枝</li>
</ol>
<p><strong>缺点：</strong>这种方法比较浪费前面的建立过程（计算上）</p>
<h2 id="决策树需要剪枝的原因"><a href="#决策树需要剪枝的原因" class="headerlink" title="决策树需要剪枝的原因"></a>决策树需要剪枝的原因</h2><p>决策树是充分考虑了所有的数据点而生成的复杂树，有可能出现过拟合的情况，决策树越复杂，过拟合的程度会越来越高。</p>
<p>考虑极端的情况，如果我们令所有的叶子节点都只含有一个数据点，那么我们能够保证所有的训练数据都能准确分类，但是很有可能得到高的预测误差，原因是将训练数据中所有的噪声数据都“准确划分”了，<strong>强化了噪声数据的作用。（形成决策树的目的是作出合理的预测，尽可能有效的排除噪声数据干扰，影响正确预测的判断）</strong></p>
<p>剪枝修剪分裂前后分类误差相差不大的子树，能够降低决策树的复杂度，降低过拟合出现的概率。</p>
<h1 id="决策树特征"><a href="#决策树特征" class="headerlink" title="决策树特征"></a>决策树特征</h1><h2 id="分类树和回归树"><a href="#分类树和回归树" class="headerlink" title="分类树和回归树"></a>分类树和回归树</h2><h3 id="分类树"><a href="#分类树" class="headerlink" title="分类树"></a>分类树</h3><p>以C4.5分类树为例，C4.5分类树在每次分枝时，是穷举每一个feature的每一个阈值，找到使得按照feature&lt;=阈值，和feature&gt;阈值分成的两个分枝的熵最大的阈值，按照该标准分枝得到两个新节点，用同样方法继续分枝得到两个新节点，用同样方法继续分枝直到得到种类唯一的叶子节点，或达到预设的终止条件，若最终叶子节点的种类不唯一，则以占有最多数的种类作为该叶子节点的标识。</p>
<h3 id="回归树"><a href="#回归树" class="headerlink" title="回归树"></a>回归树</h3><p>回归树总体流程也是类似，区别在于，回归树的每个节点（不一定是叶子节点）都会得一个预测值，以年龄为例，该预测值等于属于这个节点的所有人年龄的平均值。分枝时穷举每一个feature的每个阈值找最好的分割点，但衡量最好的标准不再是最大熵，而是最小化均方差即（每个人的年龄-预测年龄）^ 2的总和/N。也就是被预测出错的人数越多，错的越离谱，均方差就越大，通过最小化均方差能够找到最可靠的分枝依据。分枝直到每个叶子节点上人的年龄不唯一，则以该节点上所有人的平均年龄做为该叶子节点的预测年龄。</p>
<h2 id="决策树在选择特征进行分类时一个特征被选择过后，之后还会选择到这个特征吗？"><a href="#决策树在选择特征进行分类时一个特征被选择过后，之后还会选择到这个特征吗？" class="headerlink" title="决策树在选择特征进行分类时一个特征被选择过后，之后还会选择到这个特征吗？"></a>决策树在选择特征进行分类时一个特征被选择过后，之后还会选择到这个特征吗？</h2><p>决策树中一个特征被选择过后依然是有可能被选择为分裂特征的。</p>
<p><strong>若特征为离散特征，如果决策树为二叉树，则可以在分类的子区间继续划分，如果决策树为多叉树，通常进行一次划分。</strong></p>
<p><strong>若特征为连续特征，则可能在决策树中多次被选择。</strong></p>
<h2 id="常用的决策树一定是二叉树？二叉决策树与多分支决策树相比有什么特点？"><a href="#常用的决策树一定是二叉树？二叉决策树与多分支决策树相比有什么特点？" class="headerlink" title="常用的决策树一定是二叉树？二叉决策树与多分支决策树相比有什么特点？"></a>常用的决策树一定是二叉树？二叉决策树与多分支决策树相比有什么特点？</h2><p>决策树并非均为二叉树，CART算法要求其所生成的决策树为二叉树，而ID3和C4.5则允许决策树为多分支的。</p>
<p>二叉决策树不像多叉树那样会形成过多的数据碎片，而二叉决策树可能会得到更深的最终决策树。</p>
<h2 id="决策树需要进行归一化处理吗？"><a href="#决策树需要进行归一化处理吗？" class="headerlink" title="决策树需要进行归一化处理吗？"></a>决策树需要进行归一化处理吗？</h2><p>概率模型不需要归一化，因为它们不关心变量的值，而是关心变量的分布和变量之间的条件概率，决策树是一种概率模型，数值缩放，不影响分裂点位置。所以一般可以不对其进行归一化处理。</p>
<h2 id="一棵决策树构建过程耗时的步骤是？"><a href="#一棵决策树构建过程耗时的步骤是？" class="headerlink" title="一棵决策树构建过程耗时的步骤是？"></a>一棵决策树构建过程耗时的步骤是？</h2><p>决策树的构建最耗时的步骤是确定最佳分割点，在该步骤中需要对特征的值进行排序，这个过程时间损耗较多。</p>
<h2 id="如果决策树属性用完了仍未对决策树完成划分应该怎么办？"><a href="#如果决策树属性用完了仍未对决策树完成划分应该怎么办？" class="headerlink" title="如果决策树属性用完了仍未对决策树完成划分应该怎么办？"></a>如果决策树属性用完了仍未对决策树完成划分应该怎么办？</h2><p>在决策树构造过程中可能会出现这种情况：所有属性都作为分裂属性用光了，但有的子集还不是纯净集，即集合内的元素不属于同一类别。在这种情况下，由于没有更多信息可以使用了，一般对这些子集进行“多数表决”，即使用此子集中出现次数最多的类别作为此节点类别，然后将此节点作为叶子节点。</p>
<h2 id="存在时间序列回归模型效果比决策树模型有更高的精度的原因"><a href="#存在时间序列回归模型效果比决策树模型有更高的精度的原因" class="headerlink" title="存在时间序列回归模型效果比决策树模型有更高的精度的原因"></a>存在时间序列回归模型效果比决策树模型有更高的精度的原因</h2><p>时间序列数据有线性关系，而决策树算法是已知的检测非线性交互最好的算法。<strong>为什么决策树没能提供好的预测的原因是它不能像回归模型一样做到对线性关系那么好的映射。</strong>因此，我们知道了如果我们有一个满足线性回归模型能提供强大的预测。</p>
<h2 id="决策树的优缺点"><a href="#决策树的优缺点" class="headerlink" title="决策树的优缺点"></a>决策树的优缺点</h2><p><strong>优点：</strong></p>
<ol>
<li>易于理解，决策树易于理解和实现。人们在通过解释后都有能力去理解决策树所表达的意义。</li>
<li>数据处理简单，对于决策树，数据的准备往往是简单或者是不必要的。其他的技术往往要求先把数据一般化，比如去掉多余的或者空白的属性。</li>
<li>能够同时处理数据型和常规型属性。其他的技术往往要求数据属性的单一。</li>
<li>是一个白盒模型如果给定一个观察的模型，那么根据所产生的决策树很容易推出相应的逻辑表达式。</li>
<li>易于通过静态测试来对模型进行评测。表示有可能测量该模型的可信度。</li>
<li>在相对短的时间内能够对大型数据源做出可行且效果良好的结果。</li>
</ol>
<p><strong>缺点：</strong></p>
<ol>
<li>很容易在训练数据中生成复杂的树结构，造成过拟合(overfitting)。剪枝可以缓解过拟合的负作用，常用方法是限制树的高度、叶子节点中的最少样本数量。</li>
<li>不适合处理高维数据，当属性数量过大的时候，部分决策树就不太适用了。</li>
<li><strong>对异常值(Outlier)过于敏感，很容易导致树的结构的巨大的变换。</strong></li>
<li>泛化(Generalization)能力太差，对于没有出现过的值几乎没有办法。</li>
</ol>
<h2 id="决策树对缺失值的处理"><a href="#决策树对缺失值的处理" class="headerlink" title="决策树对缺失值的处理"></a>决策树对缺失值的处理</h2><p>决策树缺失值需要考虑3个问题：</p>
<ol>
<li>当开始决定选择哪个属性用来进行分支时，如果有些训练样本缺失了某些属性值时该怎么办？</li>
</ol>
<ul>
<li><strong>忽略</strong>这些缺失属性a的样本。</li>
<li><strong>填充缺失值</strong>，例如给缺失属性a的样本赋予属性a一个均值或者最常用的值或者根据其他未知的属性想办法把这些样本缺失的属性补全。</li>
<li><strong>计算信息增益或者信息增益率时根据缺失属性样本个数所占的比率对增益/增益率进行相应的“打折”</strong>，例如我们对10个样本进行分类，一个样本数据在a属性具有缺失值，我们使用其中九个完全样本计算a属性的信息增益，并将其乘以0.9作为最终信息增益。</li>
</ul>
<ol>
<li>一个属性已被选择，那么在决定分支的时候如果有些样本缺失了该属性如何处理？</li>
</ol>
<ul>
<li>忽略这些样本</li>
<li>填充缺失值再进行分类，例如给缺失属性a的样本赋予属性a一个均值或者最常用的值者根据其他未知的属性想办法把这些样本缺失的属性补全。</li>
<li>把这些属性缺失样本，按照具有属性a的样本被划分成的子集样本个数的相对比率，分配到各个子集中去。至于哪些缺失的样本被划分到子集1，哪些被划分到子集2，这个没有一定的准则，可以随机而动。</li>
<li>把属性缺失样本分配给所有的子集，也就是说每个子集都有这些属性缺失样本。</li>
<li>单独为属性缺失的样本划分一个分支子集。</li>
</ul>
<ol>
<li>当决策树已经生成，但待分类的样本缺失了某些属性，这些属性该如何处理？</li>
</ol>
<ul>
<li>如果有单独的缺失值分支，依据此分支预测。</li>
<li>把待分类的样本的属性a值分配一个最常出现的a的属性值，然后进行分支预测。</li>
<li>根据其他属性为该待分类样本填充一个属性a值，然后进行分支处理。</li>
<li>待分类样本在到达属性a节点时就终止分类，然后根据此时a节点所覆盖的叶子节点类别状况为其分配一个发生概率最高的类。</li>
</ul>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>决策树</tag>
        <tag>ID3</tag>
        <tag>C4.5</tag>
        <tag>CART</tag>
      </tags>
  </entry>
  <entry>
    <title>K邻近（KNN）专题</title>
    <url>/passages/2019-07-29-K%E9%82%BB%E8%BF%91%EF%BC%88KNN%EF%BC%89%E4%B8%93%E9%A2%98/</url>
    <content><![CDATA[<h1 id="KNN算法原理"><a href="#KNN算法原理" class="headerlink" title="KNN算法原理"></a>KNN算法原理</h1><p>KNN算法又称为k最近邻分类算法。所谓的k最近邻，就是指最接近的k个邻居（数据），即每个样本都可以由它的k个邻居来表达。</p>
<p>KNN算法的核心思想是，在一个含未知样本的空间，可以根据离这个样本最邻近的k个样本的数据类型来确定样本的数据类型。</p>
<p><strong>该算法涉及3个主要因素：分类决策规则、距离与相似的衡量、k的大小。</strong></p>
<p>KNN做分类预测时，一般是选择多数表决法，即训练集里和预测的样本特征最近的k个样本，预测为里面有最多类别数的类别。而KNN做回归时，一般是选择平均法，即最近的K个样本的样本输出的平均值作为回归预测值。</p>
<p>对于距离的度量，我们有很多的距离度量方式，但是最常用的是欧式距离。</p>
<p>k值的选择，过小则容易过拟合，过大则容易欠拟合，可以使用交叉验证法选取k值。</p>
<h1 id="KNN算法优缺点"><a href="#KNN算法优缺点" class="headerlink" title="KNN算法优缺点"></a>KNN算法优缺点</h1><p><strong>优点：</strong></p>
<ol>
<li>思想简单，理论成熟，既可以用来做分类也可以用来做回归；</li>
<li>可用于非线性分类；</li>
<li>训练时间复杂度为O(n)；</li>
<li>准确度高，对数据没有假设，<strong>对离群值不敏感</strong>。</li>
</ol>
<p><strong>缺点：</strong></p>
<ol>
<li>计算量大；</li>
<li>样本不平衡问题（即有些类别的样本数量很多，而其他样本的数量很少）；</li>
<li>需要大量的内存。</li>
</ol>
<h1 id="KNN中不平衡样本问题的解决方案"><a href="#KNN中不平衡样本问题的解决方案" class="headerlink" title="KNN中不平衡样本问题的解决方案"></a>KNN中不平衡样本问题的解决方案</h1><p>KNN在分类时重要的不足在于当样本不平衡时（即一个类的样本容量很大，而其他类样本数量很小），很可能导致当输入一个未知样本时，该样本的k个邻居中大数量类的样本占多数。但是这类样本并不接近目标样本，而数量小的这类样本很靠近目标样本。这个时候，我们有理由认为该位置样本属于数量小的样本所属的一类，但是，KNN却不关心这个问题，它<strong>只关心哪类样本的数量最多，而不去把距离远近考虑在内，因此，会导致预测结果的不准确。</strong></p>
<p>我们可以采用<strong>权值</strong>的方法来改进。和样本距离小的邻居权值大，和样本距离大的邻居权值则相对较小，由此，将距离远近的因素也考虑在内，避免因一个样本过大导致误判的情况。</p>
<h1 id="KNN算法计算量过大的解决方案"><a href="#KNN算法计算量过大的解决方案" class="headerlink" title="KNN算法计算量过大的解决方案"></a>KNN算法计算量过大的解决方案</h1><p>KNN算法计算量较大，因为对每一个待分类的样本都要计算它到全体已知样本的距离，才能求得它的K个最近邻点。KNN算法的改进方法之一是分组快速搜素近邻法。其基本思想是：将样本集按近邻关系分解成组，给出每组质心的位置，以质心作为代表点，和未知样本计算距离，选出距离最近的一个或若干个组，再在组的范围内应用一般的KNN算法。由于并不是将未知样本与所有样本计算距离，故该改进算法可以减少计算量，但不能不减少存储量。</p>
<h1 id="KD树的概念"><a href="#KD树的概念" class="headerlink" title="KD树的概念"></a>KD树的概念</h1><p>kd树（k-dimension tree）是一种对k维空间中的实例点进行存储以便对其进行快速检索的树形数据结构。kd树是一种二叉树，表示对k维空间的一个划分，构造kd树相当于不断地用垂直于坐标轴的超平面将k维空间切分，构成一系列的k维超矩形区域。这种空间划分就是对数据点进行分类，“挨得近”的数据点就在一个空间里面。利用kd树可以省去对大部分数据点的搜索，从而减少搜素的计算量。</p>
<p><img src="/passages/2019-07-29-K邻近（KNN）专题/KD_Tree.jpeg" alt="KD_Tree"></p>
<h2 id="kd树的构造"><a href="#kd树的构造" class="headerlink" title="kd树的构造"></a>kd树的构造</h2><p>构造根结点，使得根结点对应于k维空间中包含所有实例点的超矩形区域；通过下面的递归的方法，不断地对k维空间进行切分，生成子结点。在超矩形区域选择一个坐标轴和在此坐标轴上的一个切分点，确定一个超平面，这个超平面通过选定的切分点并垂直于选定的坐标轴，将当前超矩形区域切分成左右两个子区域（子结点）；这时，实例被分到两个子区域（子结点）；这时，实例被分到两个子区域，这个过程直到子区域内没有实例时终止（终止时的结点为叶结点）。在此过程中，将实例保存在相应的结点上。通常，循环的选择坐标轴对空间切分，选择训练实例点在坐标轴上的中位数为切分点，这样得到的kd树是平衡的。</p>
<h2 id="构造平衡kd树算法"><a href="#构造平衡kd树算法" class="headerlink" title="构造平衡kd树算法"></a>构造平衡kd树算法</h2><p><strong>输入：</strong>k维空间数据集$T={x_1,x_2,…,x_N}$，其中$x_i ={x_i(1),x_i(2),…,x_i(k)}，i=1,2,…,N$；</p>
<p><strong>输出：</strong>kd树</p>
<p>（1）<strong>开始：</strong>构造根结点，根结点对应于包含T的k维空间的超矩形区域。选择x(1)为坐标轴，以T中所有实例的x(1)坐标中位数为切分点，将根结点对应的超矩形区域切分为两个子区域。切分由通过切分点并与坐标轴x(1)垂直的超平面实现。由根结点生成深度为1的左、右子结点：左子结点对应坐标x(1)小于切分点的子区域，右子结点对应于坐标x(1)大于切分点的子区域。将落在切分超平面上的实例点保存在根结点。</p>
<p>（2）<strong>重复：</strong>对深度为j的结点，选择x(I)为切分的坐标轴，I =j%k+1，以该结点的区域中所有实例的x(I)坐标的中位数为切分点，将该结点对应的超矩形区域切分为两个子区域。切分由通过切分点并与坐标轴x(I)垂直的超平面实现。由该结点生成深度为j+1的左、右子结点：左子结点对应坐标x(I)小于切分点的子区域，右子结点对应坐标x(I)大于切分点的子区域。将落在切分超平面上的实例点保存在该结点。</p>
<h2 id="搜索kd树"><a href="#搜索kd树" class="headerlink" title="搜索kd树"></a>搜索kd树</h2><p>利用kd树可以省去对大部分数据点的搜素，从而减少搜索的计算量。</p>
<p><strong>用kd树的最近邻搜索：</strong></p>
<p><strong>输入：</strong>已构造的kd树；目标点x；</p>
<p><strong>输出：</strong>x的最近邻</p>
<p>（1）在kd树中找出包含目标点x的叶结点：从根结点出发，递归的向下访问kd树。若目标点当前维的坐标值小于切分点的坐标值，则移动到左子结点，否则移动到右子结点。直到子结点为叶结点为止；</p>
<p>（2）以此叶结点为“当前最近点”；</p>
<p>（3）递归的向上回退，在每个结点进行以下操作：</p>
<ul>
<li>如果该结点保存的实例点比当前最近点距目标点更近，则以该实例点为“当前最近点”；</li>
<li>当前最近点一定存在于该结点一个子结点对应的区域是否有更近的点。具体的，检查另一个子结点对应的区域是否与以目标点为球心、以目标点与“当前最近点”间的距离为半径的超球体相交。如果相交，可能在另一个子结点对应的区域内存在距离目标更近的点，移动到另一个子结点。接着，递归的进行最近邻搜索。如果不相交，向上回退。</li>
</ul>
<p>（4） 当回退到根结点时，搜索结束。最后的“当前最近点”即为x的最近邻点。该方法可以修改后用于k近邻搜索，即通过维护一个包含k个最近邻结点的队列来实现。</p>
<h2 id="优化kd树建立过程中切分维度的顺序"><a href="#优化kd树建立过程中切分维度的顺序" class="headerlink" title="优化kd树建立过程中切分维度的顺序"></a>优化kd树建立过程中切分维度的顺序</h2><p>构建开始前，对比数据点在各维度的分布情况，数据点在某一维度坐标值的方差越大分布越分散，方差越小分布越集中。<strong>从方差大的维度开始切分可以取得很好的切分效果及平衡性。</strong></p>
<h2 id="kd树每一次继续切分都要计算该子区间在需切分维度上的中值，计算量很大，如何优化？"><a href="#kd树每一次继续切分都要计算该子区间在需切分维度上的中值，计算量很大，如何优化？" class="headerlink" title="kd树每一次继续切分都要计算该子区间在需切分维度上的中值，计算量很大，如何优化？"></a>kd树每一次继续切分都要计算该子区间在需切分维度上的中值，计算量很大，如何优化？</h2><ol>
<li>算法开始前，对原始数据点在所有维度进行一次排序，存储下来，然后在后续的中值选择中，无须每次都对其子集进行排序，提升了性能。</li>
<li>从原始数据点中随机选择固定数目的点，然后对其进行排序，每次从这些样本点中取中值，来作为分割超平面。</li>
</ol>
<h1 id="k-Means与KNN的区别"><a href="#k-Means与KNN的区别" class="headerlink" title="k-Means与KNN的区别"></a>k-Means与KNN的区别</h1><ol>
<li>KNN是分类算法，k-Means是聚类算法；</li>
<li>KNN是监督学习，k-Means是非监督学习；</li>
<li>KNN给它的数据集是带label的数据，已经是完全正确的数据，k-Means给它的数据集是无label的数据，是杂乱无章的，经过聚类后才变得有点顺序，先无序，后有序；</li>
<li>KNN没有明显的前期训练过程，k-Means有明显的前期训练过程；</li>
<li>k的含义</li>
</ol>
<ul>
<li>KNN是对一个样本x给它分类，即求出它的y。就是从数据集中，在x附近找离它最近的k个数据点，这k个数据点，类别c占的个数最多，就把x的label设为c。</li>
<li>k-Means中k是人工固定好的数字，假设数据集合可以分为k个簇，由于是依靠人工定好，需要一点先验知识。</li>
</ul>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>有监督学习</tag>
        <tag>kNN</tag>
        <tag>分类回归算法</tag>
      </tags>
  </entry>
  <entry>
    <title>集成学习专题（一）</title>
    <url>/passages/2019-07-30-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E4%B8%93%E9%A2%98%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    <content><![CDATA[<h1 id="集成学习算法"><a href="#集成学习算法" class="headerlink" title="集成学习算法"></a>集成学习算法</h1><p>严格意义上来说，集成学习算法不算是一种机器学习算法，而更像是一种优化手段或者策略，它通常是结合多个简单的弱机器学习算法，去做更可靠的决策。</p>
<p>集成方法是由多个较弱的模型集成模型组，一般的弱分类器可以是决策树，SVM，KNN等构成。其中的模型可以单独进行训练，并且它们的预测能以某种方式结合起来去做出一个总体预测。该算法主要的问题是要找出哪些较弱的模型可以结合起来，以及如何结合的方法。</p>
<h1 id="集成学习主要三种框架"><a href="#集成学习主要三种框架" class="headerlink" title="集成学习主要三种框架"></a>集成学习主要三种框架</h1><p>集成学习从集成思想的架构分为Bagging，Boosting，Stacking三种。</p>
<p><strong>Bagging：</strong>基于数据随机重抽样的分类器构建方法。从训练集中进行子抽样组成每个基模型所需要的子训练集，对所有基模型预测的结果进行综合产生最终的预测结果。</p>
<p><strong>Boosting：</strong>训练过程为阶梯状，基模型按次序一一进行训练（实际上可以做到并行），基模型的训练集按照某种策略每次都进行一定的转化，每次都是提高前一次分错了的数据集的权值，最后对所有基模型预测的结果进行线性组合产生最终的预测结果。</p>
<p><strong>Stacking：</strong>将训练好的所有基模型对训练集进行预测，第j个基模型对第i个训练样本的预测值将作为新的训练集中第i个样本的第j个特征值，最后基于新的训练集进行训练。同理，预测的过程也要先经过所有基模型的预测形成新的测试集，最后再对测试集进行预测。</p>
<h2 id="Bagging算法流程"><a href="#Bagging算法流程" class="headerlink" title="Bagging算法流程"></a>Bagging算法流程</h2><p>输入为样本集D={(x1,y1),(x2,x2),…,(xm,ym)}，弱学习器算法，弱分类器迭代次数T</p>
<p>输出为最终的强分类器f(x)</p>
<p>（1）对于t = 1,2,…,T：</p>
<ul>
<li>对训练集进行第t次随机采样，共采集T次，得到包含T个样本的采样集$D_t$</li>
<li>用采样集$D_t$训练第t个弱学习器$G_t(x)$</li>
</ul>
<p>（2）如果是分类算法预测，则T个弱学习器投出最多票数的类别或者类别之一为最终类别。如果是回归算法，T个弱学习器得到的回归结果进行算术平均得到的值为最终的模型输出。</p>
<p><strong>常用bagging算法：</strong>随机森林算法</p>
<h2 id="Boosting算法流程"><a href="#Boosting算法流程" class="headerlink" title="Boosting算法流程"></a>Boosting算法流程</h2><ol>
<li>给定初始训练数据，由此训练出第一个基学习器；</li>
<li>根据基学习器的表现对样本进行调整，在之前学习器做错的样本上投入更多关注；</li>
<li>用调整后的样本，训练下一个基学习器；</li>
<li>重复上述过程T次，将T个学习器加权结合。</li>
</ol>
<script type="math/tex; mode=display">
f(x) = w_0 + \sum_{m = 1}^Mw_m\Psi_m(x)</script><p>其中w是权重，$\Psi$是弱分类器的集合，可以看出最终就是基函数的线形组合。</p>
<p><strong>常用boosting算法：</strong>Adaboost，GBDT，XGBoost</p>
<h2 id="stacking的使用"><a href="#stacking的使用" class="headerlink" title="stacking的使用"></a>stacking的使用</h2><p>stacking常见的使用方式：由KNN、随机森林和朴素贝叶斯基础分类器组成，它的预测结果由作为元分类器的Logistic回归组合。</p>
<h1 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h1><p>随机森林是Bagging算法的代表，它的核心思想就是将多个不同的决策树进行组合，利用这种组合降低单一决策树有可能带来的片面性和判断不准确性。</p>
<p>随机森林使用了CART决策树作为弱学习器，并对决策树的建立做了改进，对于普通的决策树，会在节点上所有的n个样本特征中选择一个最优的特征来做决策树的左右子树划分，但是随机森林通过随机选择节点上的一部分样本特征，这个数字小于n，假设为nsub，然后在这些随机选择的nsub个样本特征中，选择一个最优的特征来做决策树的左右子树划分。这样进一步增强模型的泛化能力。</p>
<p>如果nsub=n，则此时随机森林的CART决策树和普通的CART决策树没有区别。nsub越小，则模型越健壮，当然此时对于训练集的拟合程度会变差。也就是说nsub越小，模型的方差会减小，但偏差会增大。在实际案例中，一般会通过交叉验证调参获取一个合适的nsub的值。</p>
<h2 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h2><p>输入为样本集D ={(x1,y1),(x2,y2),…,(xm,ym)}，弱分类器迭代次数T。</p>
<p>输出为最终的强分类器f(x)</p>
<p>(1) 对于t=1,2,…,T：</p>
<ul>
<li>对训练集进行第t次随机采样，共采集m次，得到包含m个样本的采样集$D_t$</li>
<li>用采样集$D_t$训练第t个决策树模型$G_t(x)$，在训练决策树模型的节点的时候，在节点上所有的样本特征中选择一部分样本特征，在这些随机选择的部分样本特征中选择一个最优的特征来做决策树的左右子树划分</li>
</ul>
<p>(2) 如果是分类算法预测，则T个弱学习器投出最多票数的类别或者类别之一为最终类别。如果是回归算法，T个弱学习器得到的回归结果进行算术平均得到的值为最终的模型输出。</p>
<h2 id="随机森林的随机性"><a href="#随机森林的随机性" class="headerlink" title="随机森林的随机性"></a>随机森林的随机性</h2><ol>
<li>随机森林的随机性体现在每棵树的训练样本是随机的。</li>
<li>随机森林的树中每个节点的分裂属性集合也是随机选择确定的。</li>
</ol>
<h2 id="随机森林不易过拟合原因"><a href="#随机森林不易过拟合原因" class="headerlink" title="随机森林不易过拟合原因"></a>随机森林不易过拟合原因</h2><p>随机森林由很多棵树组合在一起，单看每一颗树都可以是过拟合的，但是，既然是过拟合，就会拟合到非常小的细节上，因此随机森林通过引入随机性，让每一颗树拟合的细节不同，这时再把这些树组合在一起，过拟合的部分就会自动被消除掉。</p>
<p>所以随机森林不容易过拟合，但这不是绝对的，随机森林也是有可能出现过拟合的现象，只是出现的概率相对低。</p>
<h2 id="如何使用随机森林去弥补特征向量中的缺失值"><a href="#如何使用随机森林去弥补特征向量中的缺失值" class="headerlink" title="如何使用随机森林去弥补特征向量中的缺失值"></a>如何使用随机森林去弥补特征向量中的缺失值</h2><p>对于训练集中的缺失值，可以使用均值，0等方式进行预填充，然后使用随机森林分类，同一个分类下的数据，更新缺失值，<strong>如果是分类变量缺失，用众数补上，如果是连续型变量缺失，用中位数补，</strong>然后再次使用随机森林分类更新缺失值，4-6轮后可以达到一个比较好的效果。</p>
<h2 id="随机森林对特征重要性的评估"><a href="#随机森林对特征重要性的评估" class="headerlink" title="随机森林对特征重要性的评估"></a>随机森林对特征重要性的评估</h2><p>首先要了解随机森林的袋外数据（oob）误差的计算方法。</p>
<p>随机森林的袋外数据指每次随机抽取未被抽到的数据。</p>
<p><strong>袋外数据（oob）误差的计算方式如下：</strong></p>
<p>对于已经生成的随机森林，用袋外数据测试其性能，假设袋外数据总数为O，用这O个袋外数据作为输入，带进之前已经生成的随机森林分类器，分类器会给出O个数据相应的分类，因为这O条数据的类型是已知的，则用正确的分类与随机森林分类器的结果进行比较，统计随机森林分类器分类错误的数目，设为X，则袋外数据误差大小 = X/O；<strong>这已经经过证明是无偏估计的，所以在随机森林算法中不需要再进行交叉验证或者单独的测试集来获取测试集误差的无偏估计。</strong></p>
<p><strong>在随机森林中某个特征X的重要性的计算方法如下：</strong></p>
<ol>
<li>对于随机森林中的每一颗决策树，使用相应的OOB（袋外数据）来计算它的袋外数据误差，记为$errOOB_1$。</li>
<li>随机地对袋外数据OOB所有样本的特征X加入噪声干扰（可以随机的改变样本在特征X处的值），再次计算它的袋外数据误差，记为$errOOB_2$。</li>
<li>假设随机森林中有Ntree棵树，那么对于特征X的重要性=$\sum(errOOB_2-errOOB_1)/Ntree$，之所以可以用这个表达式来作为相应特征的重要性的度量是因为：若给某个特征随机加入噪声后，袋外的准确率大幅度降低，则说明这个特征对于样本的分类结果影响很大，也就是说它的重要程度比较高。</li>
</ol>
<h2 id="随机森林训练需要调整的参数"><a href="#随机森林训练需要调整的参数" class="headerlink" title="随机森林训练需要调整的参数"></a>随机森林训练需要调整的参数</h2><p>随机森林中主要需要调整参数：</p>
<ol>
<li>n_estimators 随机森林建立子树的数量。</li>
</ol>
<p>较多的子树一般可以让模型有更好的性能，但同时让你的代码变慢。需要选择最佳的随机森林子树数量。</p>
<ol>
<li>max_feature随机森林允许单个决策树使用特征的最大数量。</li>
</ol>
<p>增加max_features一般能提高模型的性能，因为在每个节点上，我们有更多的选择可以考虑。然而，这未必完全是对的，因为它降低了单个树的多样性，而这正是随机森林独特的优点。但是，可以肯定，<strong>通过增加max_features会降低算法的速度。</strong>因此，你需要适当的平衡和选择最佳max_features。</p>
<ol>
<li>max_depth 决策树最大深度</li>
</ol>
<p>默认决策树在建立子树的时候不会限制子树的深度。</p>
<ol>
<li>min_samples_split 内部节点再划分所需最小样本数</li>
</ol>
<p>内部节点再划分所需最小样本数，如果某节点的样本数少于min_samples_split，则不会继续再尝试选择最优特征来进行划分。</p>
<ol>
<li>min_samples_leaf 叶子节点最少样本数</li>
</ol>
<p>这个值限制了叶子节点最少的样本数，如果某叶子节点数目小于样本数，则会和兄弟节点一起被剪枝。</p>
<ol>
<li>max_leaf_nodes 最大叶子节点数</li>
</ol>
<p>通过限制最大叶子节点数，可以防止过拟合，默认是“None”，即不限制最大的叶子节点数。如果加了限制，算法会建立在最大叶子节点数内最优的决策树。</p>
<ol>
<li>min_impurity_split 节点划分最小不纯度</li>
</ol>
<p>这个值限制了决策树的增长，如果某节点的不纯度（基于基尼系数，均方差）小于这个阈值，则该节点不再生成子节点。即为叶子节点。一般不推荐改动默认值1e-7。</p>
<h2 id="随机森林不用全样本训练m棵决策树"><a href="#随机森林不用全样本训练m棵决策树" class="headerlink" title="随机森林不用全样本训练m棵决策树"></a>随机森林不用全样本训练m棵决策树</h2><p>全样本训练忽视了局部样本的规律（各个决策树趋于相同），对于模型的泛化能力是有害的，使随机森林算法在样本层面失去了随机性。</p>
<h2 id="随机森林算法优缺点"><a href="#随机森林算法优缺点" class="headerlink" title="随机森林算法优缺点"></a>随机森林算法优缺点</h2><p><strong>优点：</strong></p>
<p>（1）训练可以高度并行化，对于大数据时代的大样本训练速度有优势。</p>
<p>（2）随机森林对于高维数据集的处理能力令人兴奋，<strong>它可以处理成千上万的输入变量，并确定最重要的变量</strong>，因此被认为是一个不错的降维方法。此外，该模型能够输出变量的重要性程度，这是一个非常便利的功能。</p>
<p>（3） 在对缺失数据进行评估时，随机森林是一个十分有效的方法。就算存在大量的数据缺失，随机森林也能较好地保持精确性，一方面因为随机森林随机选取样本和特征，另一方面因为它可以继承决策树对缺失数据的处理方式。</p>
<p>（4）由于采用了随机采样，<strong>训练出的模型的方差小，</strong>泛化能力强。</p>
<p>（5）当存在分类不平衡时，随机森林是能够提供平衡数据集误差的有效方法。</p>
<p><strong>缺点：</strong></p>
<p>（1）随机森林对回归问题的解决并没有像它在分类中表现那么好。它并不能给出一个连续的输出，而且不能够做出超出训练集数据范围的预测，当进行回归时，随机森林不能够做出超越训练集数据范围的预测，这可能导致某些特定噪声的数据进行建模时出现过度拟合，随机森林已经被证明在某些噪音较大的分类或者回归问题上会过拟合。</p>
<p>（2） 对于很多统计建模者来说，随机森林给人的感觉就像一个黑盒子，你无法控制模型内部的运行，只能在不同的参数和随机种子之间进行尝试，可能有很多相似的决策树，掩盖了真实的结果。</p>
<p>（3） 对于小数据或者低维数据（特征较少的数据），可能不能产生很好的分类。</p>
<h1 id="AdaBoost"><a href="#AdaBoost" class="headerlink" title="AdaBoost"></a>AdaBoost</h1><p>AdaBoost分类器就是一种元算法分类器，Adaboost分类器利用同一种基分类器（弱分类器），基于分类器的错误率分配不同的权重参数，最后累加加权的预测结果作为输出。</p>
<h2 id="AdaBoost算法流程"><a href="#AdaBoost算法流程" class="headerlink" title="AdaBoost算法流程"></a>AdaBoost算法流程</h2><p>Adaboost算法流程如下：</p>
<p>（1） 给数据中的每一个样本一个权重，权重的起始值是相同的，若有n个训练样本，其权重均为1/n；</p>
<p>（2）训练数据中的每一个样本，得到第一个分类器；</p>
<p>（3）计算该分类器的错误率，根据错误率计算要给分类器分配的权重<strong>（这里是分类器的权重，不是样本的权重）</strong></p>
<script type="math/tex; mode=display">
错误率\varepsilon = \sum_{i \in 错分类样本}W_i, W_i为样本权重</script><script type="math/tex; mode=display">
分类器权重\alpha = \frac{1}{2}In(\frac{1-\varepsilon}{\varepsilon})</script><p>（4）将第一个分类器分错误的样本权重增加，分对的样本权重减小<strong>（这里是样本的权重，不是分类器的权重）</strong></p>
<script type="math/tex; mode=display">
错误样本权重更新公式D_i^{t+1} = \frac{D_i^te^{\alpha}}{sum(D_i^t)}</script><script type="math/tex; mode=display">
正确样本权重更新公式D_i^{t+1} = \frac{D_i^te^{-\alpha}}{sum(D_i^t)}</script><p>t指当前分类器，i指第i个样本</p>
<p>（5）然后再用新的样本权重训练数据，得到新的分类器，到步骤3</p>
<p>（6）直到步骤3中分类器错误率为0或者整体弱分类器为0，或者到达迭代次数</p>
<p>（7）将所有弱分类器加权求和，得到分类结果（注意是分类器权重），错误率低的分类器获得更高的决定系数，从而在对数据进行预测时起关键作用。</p>
<script type="math/tex; mode=display">
f(x) = \sum\alpha h_i(x),h_i(x)为各个弱分类器</script><h2 id="AdaBoost优缺点"><a href="#AdaBoost优缺点" class="headerlink" title="AdaBoost优缺点"></a>AdaBoost优缺点</h2><p><strong>优点：</strong></p>
<ol>
<li><p>Adaboost提供一种框架，在框架内可以使用各种方法构建子分类器。可以使用简单的弱分类器，不用对特征进行筛选，也不存在过拟合的现象。</p>
</li>
<li><p>Adaboost算法不需要弱分类器的先验知识，最后得到的强分类器的分类精度依赖于所有弱分类器。无论是应用于人造数据还是真实数据，Adaboost都能显著的提高学习精度。</p>
</li>
<li><p>Adaboost算法不需要预先知道弱分类器的错误率上限，且最后得到的强分类器的分类精度依赖于所有弱分类器的分类精度，可以深挖分类器的能力。</p>
<p>Adaboost可以根据弱分类器的反馈，自适应地调整假定的错误率，执行的效率高。</p>
</li>
<li><p>Adaboost对同一个训练样本集训练不同的弱分类器，按照一定的方法把这些弱分类器集合起来，构造一个分类能力很强的强分类器。</p>
</li>
</ol>
<p><strong>缺点：</strong></p>
<p>在Adaboost训练过程中，Adaboost会使得难于分类样本的权值呈指数增长，训练将会过于偏向这类困难的样本，导致Adaboost算法易受噪声干扰。</p>
<p>Adaboost依赖于弱分类器，而弱分类器的训练时间往往很长。</p>
<h2 id="AdaBoost对噪声敏感的原因"><a href="#AdaBoost对噪声敏感的原因" class="headerlink" title="AdaBoost对噪声敏感的原因"></a>AdaBoost对噪声敏感的原因</h2><p>在Adaboost训练过程中，Adaboost会使得难于分类样本权值呈指数增长，训练将会过于偏向这类困难的样本，导致Adaboost算法易受噪声干扰。</p>
<h2 id="AdaBoost与随机森林的异同"><a href="#AdaBoost与随机森林的异同" class="headerlink" title="AdaBoost与随机森林的异同"></a>AdaBoost与随机森林的异同</h2><p>随机森林和Adaboost算法都可以用来分类，它们都是优秀的基于决策树的组合算法。</p>
<p><strong>这两种分类方法的相同之处：</strong></p>
<ol>
<li>二者都是bootstrap自助法选取样本。</li>
<li>二者都要训练很多棵决策树。</li>
</ol>
<p><strong>两种分类方法的不同之处：</strong></p>
<ol>
<li>Adaboost是基于boosting的算法，随机森林是基于bagging的算法。</li>
<li>Adaboost后面树的训练，其在变量抽样选取的时候，对于上一棵树分错的样本，抽中的概率会加大。</li>
<li>随机森林在训练每一棵树的时候，随机挑选了部分特征作为拆分特征，而不是所有的特征都去作为拆分特征。</li>
<li>在观测新数据时，adaboost中所有的树加权投票来决定因变量的预测值，每棵树的权重和错误率有关；随机森林按照所有树中少数服从多数树的分类值来决定因变量的预测值（或者求取树预测的平均值）。</li>
</ol>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>集成学习</tag>
        <tag>随机森林</tag>
        <tag>AdaBoost</tag>
      </tags>
  </entry>
  <entry>
    <title>集成学习专题（二）</title>
    <url>/passages/2019-07-30-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E4%B8%93%E9%A2%98%EF%BC%88%E4%BA%8C%EF%BC%89/</url>
    <content><![CDATA[<h1 id="GBDT"><a href="#GBDT" class="headerlink" title="GBDT"></a>GBDT</h1><p>GBDT是集成学习Boosting的一种。Gradient Boosting的主要的思想是，每一次建立单个学习器时，是在之前建立的模型的损失函数的梯度下降方向。损失函数越大，说明模型越容易出错，如果我们的模型能够让损失函数持续下降，则说明我们的模型在不停的改进，而<strong>最好的方式就是让损失函数在其梯度的方向上下降</strong>。</p>
<p>GBDT的核心就在于，每一棵树学的是之前所有树结论和的残差，这个残差就是一个加预测值后能得真实值的累加量。所以为了得到残差，<strong>GBDT中的树都是回归树，不是分类树。</strong></p>
<h2 id="GBDT的算法流程"><a href="#GBDT的算法流程" class="headerlink" title="GBDT的算法流程"></a>GBDT的算法流程</h2><p>输入是训练集样本，最大迭代次数T，每轮迭代输入数据是训练集<strong>无放回采样样本</strong>，损失函数L。</p>
<ol>
<li>初始化弱学习器。</li>
</ol>
<script type="math/tex; mode=display">
T(x;\theta_m)</script><p>T表示决策树，x为输入样本，$\theta_m$为树分裂参数。</p>
<ol>
<li>对迭代轮数m = 1,2,…,T有：</li>
</ol>
<p>（a）计算各个叶子区域损失函数L的负梯度值，将它作为残差的估计</p>
<script type="math/tex; mode=display">
r_{mi} = -[\frac{\partial L(y,f(x_i))}{\partial f(x_i)}]_{f(x)=f_{m-1}(x)}</script><p>（b）对$r_{mi}$拟合为一颗新的回归树，根据新的回归树得到m轮产生的叶子节点区域</p>
<p>（c）遍历回归树所有叶子节点区域，在各个区域使损失函数极小化找到残差</p>
<p>（d）更新强学习器</p>
<ol>
<li>得到输出的最终模型</li>
</ol>
<script type="math/tex; mode=display">
f_M(x) = \sum_{m =1}^M T(x;\theta_m)</script><h2 id="GBDT常用的损失函数"><a href="#GBDT常用的损失函数" class="headerlink" title="GBDT常用的损失函数"></a>GBDT常用的损失函数</h2><p>对于分类算法，其损失函数一般有两种：</p>
<p>（1） 指数损失函数：$L(y,h(x)) = \exp(-yh(x))$</p>
<p>（2） 对数损失函数：分为二元分类和多元分类两种。</p>
<ul>
<li>对于二元分类：$L(y,h(x)) = \log(1+\exp(-yh(x)))$</li>
<li>对于多元分类：设类别数为k， $L(y<em>k,h(x)) = -\sum</em>{k=1}^Ky_k\log(p_k(x))$，$y_k$为样本数据估计值，当一个样本x属于k时，$y_k=1$，否则$y_k=0$</li>
</ul>
<p>对于回归算法，常用损失函数有4种：</p>
<ol>
<li><p>均方差：$L(y,h(x)) =(y-h(x))^2$</p>
</li>
<li><p>绝对损失：$L(y,h(x)) = |y-h(x)|$</p>
</li>
<li><p>Huber损失：它是均方差和绝对损失的折衷产物，对于远离中心的异常点，采用绝对损失，而中心附近的点采用均方差。这个界限一般用分位数点度量</p>
<script type="math/tex; mode=display">
L(y,f(x))= \begin{cases}
 \frac{1}{2}(y-f(x))^2&|y-f(x)|\le \delta\\
 \delta(|y-f(x)|-\frac{\delta}{2})&|y-f(x)|\gt \delta
\end{cases}</script></li>
<li><p>分位树损失：它对应的是分位数回归的损失函数。</p>
</li>
</ol>
<script type="math/tex; mode=display">
L(y,f(x)) = \sum_{y\ge f(x)}\theta|y-f(x)|+\sum_{y\lt f(x)}(1-\theta)|y-f(x)|</script><h2 id="GBDT中为什么用负梯度来拟合残差计算"><a href="#GBDT中为什么用负梯度来拟合残差计算" class="headerlink" title="GBDT中为什么用负梯度来拟合残差计算"></a>GBDT中为什么用负梯度来拟合残差计算</h2><p>其实除了均方误差的情况一阶导是残差外，其他的情况没有残差的概念，GBDT每一轮拟合的都是损失函数负梯度。</p>
<p><strong>使用梯度计算代替的主要原因是为了将GBDT扩展到更复杂的损失函数中。</strong></p>
<p>当损失函数形式简单，可以认为$y^{‘}（模型输出值）= y（实际值）$时损失函数最小，但当损失函数加入了正则项后，并非$y^{‘}=y$时损失函数取得最小值，所以我们需要计算损失函数的梯度，而不能直接使用模型来计算残差。</p>
<h2 id="GBDT不适合使用高维稀疏特征的原因"><a href="#GBDT不适合使用高维稀疏特征的原因" class="headerlink" title="GBDT不适合使用高维稀疏特征的原因"></a>GBDT不适合使用高维稀疏特征的原因</h2><ol>
<li>特征太多，GBDT不一定跑的动，即使可以跑也会耗费时间，因为在每一次分割时需要比较大量的特征。</li>
<li>树的分割往往只考虑了少量特征，大部分特征用不到，少量的特征在多次分裂时被重复用到，剩余的长尾基本用不到，所有高维稀疏特征会造成大量特征的浪费。</li>
</ol>
<h2 id="GBDT减少误差的方式"><a href="#GBDT减少误差的方式" class="headerlink" title="GBDT减少误差的方式"></a>GBDT减少误差的方式</h2><p>机器学习算法的误差分为偏差和方差两个部分。</p>
<p>GBDT迭代每一步都在拟合当前模型预测值和真实值之间的偏差，通过不断的迭代使偏差减小，所以只要选取方差较小的模型作为基分类器，GBDT就可以很好的减小预测误差。</p>
<h2 id="GBDT的优缺点"><a href="#GBDT的优缺点" class="headerlink" title="GBDT的优缺点"></a>GBDT的优缺点</h2><p><strong>GBDT主要的优点有：</strong></p>
<p>（1）可以灵活处理各种类型的数据，包括连续值和离散值。</p>
<p>（2）在相对少的调参时间情况下，预测的准确率也可以比较高</p>
<p>（3）使用一些健壮的损失函数，对异常值的鲁棒性非常强，比如Huber损失函数和Quantile损失函数</p>
<p><strong>GBDT的主要缺点有：</strong></p>
<p>（1）由于弱学习器之间存在依赖关系，难以并行训练数据。</p>
<h2 id="GBDT如何进行正则化"><a href="#GBDT如何进行正则化" class="headerlink" title="GBDT如何进行正则化"></a>GBDT如何进行正则化</h2><p>第一种正则化方式为步长（learning rate）。定义为v，对于前面的弱学习器的迭代</p>
<script type="math/tex; mode=display">
f_k{x} = f_{k-1}(x)+h_k(x)</script><p>如果我们加上了正则化项，则有</p>
<script type="math/tex; mode=display">
f_k(x) = f_{k-1}(x)+ vh_k(x)</script><p>v的取值范围为$0\lt v \le 1$。对于同样的训练集学习效果，较小的v意味着我们需要更多的弱学习器的迭代次数，通常我们用步长和迭代最大次数一起来决定算法的拟合效果。</p>
<p>第二种正则化的方式是通过子采样比例（subsample）。取值为(0,1]。<strong>注意这里的子采样和随机森林不一样，随机森林使用的是放回抽样，而这里是不放回抽样。</strong>如果取值为1，则全部样本都使用，等于没有使用子采样。如果取值小于1，则只有一部分样本会去做GBDT的决策树拟合。选择小于1的比例可以减少方差，即防止过拟合，但是会增加样本拟合的偏差，因此取值不能太低。推荐在[0.5,0.8]之间。</p>
<p>第三种是对于弱学习器即CART回归树进行正则化剪枝。</p>
<h2 id="GBDT如何构建特征"><a href="#GBDT如何构建特征" class="headerlink" title="GBDT如何构建特征"></a>GBDT如何构建特征</h2><p>GBDT本身是不能产生特征的，但是我们可以利用GBDT去产生特征的组合，其主要思想是<strong>GBDT每棵树的路径直接作为其他模型的输入特征使用</strong>，例如输入逻辑回归模型。</p>
<p>用已有特征训练GBDT模型，然后利用GBDT模型学习到的树来构造新特征，最后把这些新特征加入原有特征一起训练模型。构造的新特征向量是取值0/1的，向量的每个元素对应于GBDT模型中树的叶子结点。<strong>当一个样本点通过某棵树最终落在这棵树的一个叶子结点上，那么在新特征向量中这个叶子结点对应的元素值为1</strong>，而这棵树的其他叶子结点对应的元素值为0。新特征向量的长度等于GBDT模型里所有树包含的叶子结点数之和。</p>
<p><img src="/passages/2019-07-30-集成学习专题（二）/GBDT-Feature.jpg" alt="GBDT-Feature"></p>
<p>上图的两棵树是GBDT学习到的，第一棵树有3个叶子结点，而第二棵树有2个叶子结点。对于一个输入样本点x，如果它在第一棵树最后落在其中第二个叶子结点，而在第二棵树里最后落在其中的第一个叶子结点。那么通过GBDT获得的新特征向量为[0,1,0,1,0]，其中向量中的前三位对应第一棵树的3个叶子结点，后两位对应第二棵树的2个叶子结点，原来的特征一起组合成为新的组合特征进行训练。实验证明这样会得到比较显著的提升模型效果。</p>
<p>经验证，树的数量最多500棵（500以上就没有提升了），每棵树的节点不多于12。</p>
<h2 id="GBDT如何用于分类"><a href="#GBDT如何用于分类" class="headerlink" title="GBDT如何用于分类"></a>GBDT如何用于分类</h2><p>GBDT无论用于分类还是回归一直都是使用的CART回归树。不会因为我们所选择的任务是分类任务就选用分类树。由于GBDT每轮的训练是在上一轮的训练的残差基础之上进行训练的。这里的残差就是当前模型的负梯度值。这个要求每轮迭代的时候，弱分类器的输出结果相减是有意义的，即残差相减是有意义的。</p>
<p>如果选用的弱分类器是分类树，类别相减是没有意义的。上一轮输出的是样本x属于A类，本一轮训练输出的是样本x属于B类。A和B很多时候甚至都没有比较的意义，A类-B类是没有意义的。</p>
<p>首先，我们在训练的时候，是针对样本X每个可能的类都训练一个分类回归树。举例说明，目前样本有三类，也就是K = 3。样本x属于第二类。那么针对该样本x的分类结果，其实我们可以用一个三维向量[0,1,0]来表示。0表示样本不属于该类，1表示样本属于该类。由于样本已经属于第二类了，所以第二类对应的向量维度为1，其他位置为0。</p>
<p><strong>针对样本有三类的情况，我们实质上是在每轮的训练的时候是同时训练三棵树。</strong>第一棵树针对样本x的第一类，输入为(x,0)。第二棵树输入针对样本x的第二类，输入为(x,1)。第三棵树针对样本x的第三类，输入为(x,0)。</p>
<p>在这里每棵树的训练过程其实就是CART TREE的生成过程。按照生成树的流程可以解出三棵树，以及三棵树对x类别的预测$f_1(x),f_2(x),f_3(x)$。那么在此类训练中，我们仿照多分类的逻辑回归，使用softmax来产生概率，则属于类别1的概率：</p>
<script type="math/tex; mode=display">
p_1 = exp(f_1(x))/\sum_{k=1}^3\exp(f_k(x))</script><p>并且我们可以针对类别1求出残差$y<em>{11}(x) =0-p_1(x)$;类别2求出残差$y</em>{22} =1-p<em>2(x)$;类别3求出残差$y</em>{33}(x) = 0-p_3(x)$。</p>
<p>然后开始第二轮训练 针对第一类输入为$(x,y<em>{11}(x))$，针对第二类输入为$(x,y</em>{22}(x))$，针对第三类输入为$(x,y_{33}(x))$，继续训练出三棵树。一直迭代M轮。每轮构建3棵树，进行T轮迭代后，生成3*T棵树，样本属于某个类别的概率为：</p>
<script type="math/tex; mode=display">
p_c = \exp(f_c(x))/\sum_{k=1}^3exp(f_k(x))</script><h2 id="GBDT需要调试的参数"><a href="#GBDT需要调试的参数" class="headerlink" title="GBDT需要调试的参数"></a>GBDT需要调试的参数</h2><p>GBDT训练中需要调试的参数如下：</p>
<ol>
<li>n_estimators：也就是弱学习器的最大迭代次数，或者说<strong>最大弱学习器的个数</strong>。一般来说n_estimators太小，容易欠拟合，n_estimators太大，容易过拟合，一般选择一个适中的数值。</li>
<li>learning_rate：即每个弱学习器的权重缩减系数v，也称步长。</li>
<li>subsample：不放回抽样。如果取值为1，则全部样本都使用，等于没有使用子采样。如果取值小于1，则只有一部分样本会去做GBDT的决策树拟合。</li>
<li>max_features允许单个决策树使用特征的最大数量。</li>
<li>max_depth决策树最大深度</li>
</ol>
<p>默认决策树在建立子树的时候不会限制子树的深度</p>
<ol>
<li>min_sample_split 内部节点再划分所需最小样本数</li>
</ol>
<p>内部节点再划分所需最小样本数，如果某节点的样本数少于min_samples_split，则不会继续再尝试选择最优特征来进行划分。</p>
<ol>
<li>min_samples_leaf 叶子节点最少样本数</li>
</ol>
<p>这个值限制了叶子节点最少的样本数，如果某叶子节点数目小于样本数，则会和兄弟节点一起被剪枝。</p>
<ol>
<li>max_leaf_nodes 最大叶子节点数</li>
</ol>
<p>通过限制最大叶子节点数，可以防止过拟合，默认是“None”，即不限制最大的叶子节点数。如果加了限制，算法会建立在最大叶子节点数内的最优的决策树。</p>
<ol>
<li>min_impurity_split 节点划分最小不纯度</li>
</ol>
<p>这个值限制了决策树的增长，如果某节点的不纯度（基于基尼系数，均方差）小于这个阈值，则该节点不再生成子节点。即为叶子节点。一般不推荐改动默认值1e-7。</p>
<h1 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h1><h2 id="Xgboost算法思想"><a href="#Xgboost算法思想" class="headerlink" title="Xgboost算法思想"></a>Xgboost算法思想</h2><p><strong>该算法就是不断地添加树，不断地进行特征分裂来生长一棵树，每次添加一个树，其实是学习一个新函数，去拟合上次预测的残差。</strong>当我们训练完成得到k棵树，我们要预测一个样本的分数，其实就是根据这个样本的特征，在每棵树中会落到对应的一个叶子节点，每个叶子节点就对应一个分数，最后只需要将每棵树对应的分数加起来就是该样本的预测值。</p>
<p>如下图例子，训练出了2棵决策树，小孩的预测分数就是两棵树中小孩所落到的结点的分数相加。爷爷的预测分数同理。</p>
<p><img src="/passages/2019-07-30-集成学习专题（二）/XGBoost.png" alt="XGBoost"></p>
<p><strong>分裂结点问题上，XGBoost使用了和CART回归树一样的想法，利用贪婪算法，遍历所有特征的所有特征划分点，不同的是评价函数（分裂后的目标函数值比单子叶子节点的目标函数的增益，CART是MSE），同时限制树生长过深，还加了阈值，当增益大于阈值才能进行分裂。</strong></p>
<h2 id="Xgboost使用泰勒展开的优势"><a href="#Xgboost使用泰勒展开的优势" class="headerlink" title="Xgboost使用泰勒展开的优势"></a>Xgboost使用泰勒展开的优势</h2><p>Xgboost使用了一阶和二阶偏导，二阶导数有利于梯度下降的更快更准，使用泰勒展开取得函数做自变量的二阶导数形式，可以在不选定损失函数具体形式的情况下，仅仅依靠输入数据的值就可以进行叶子节点分裂优化计算，<strong>本质上也就把损失函数的选取和模型算法优化/参数选择分开了。</strong>这种去耦合增加了xgboost的适用性，使得它按需选取损失函数，可以用于分类，也可以用于回归。</p>
<h2 id="Xgboost如何寻找最优特征"><a href="#Xgboost如何寻找最优特征" class="headerlink" title="Xgboost如何寻找最优特征"></a>Xgboost如何寻找最优特征</h2><p>Xgboost在训练的过程中给出各个特征的增益评分，最大增益的特征会被选出来作为分裂依据，从而记忆了每个特征对在模型训练时的重要性，从根到叶子中间节点涉及某特征的次数作为该特征重要性排序。</p>
<h2 id="Xgboost的采样"><a href="#Xgboost的采样" class="headerlink" title="Xgboost的采样"></a>Xgboost的采样</h2><p>Xgboost属于boosting集成学习方法，样本是不放回的，因而每轮计算样本不重复。另一方面，Xgboost支持子采样，也就是每轮计算可以不使用全部样本，以减少过拟合，进一步地，Xgboost还有列采样，每轮计算按百分比随机采样一部分特征，既提高计算速度又减少过拟合。</p>
<h2 id="Xgboost中树的剪枝"><a href="#Xgboost中树的剪枝" class="headerlink" title="Xgboost中树的剪枝"></a>Xgboost中树的剪枝</h2><p>首先看Xgboost分裂的决策函数：</p>
<script type="math/tex; mode=display">
Gain =\frac{1}{2}[\frac{G_L^2}{H_L+\lambda}+\frac{G_R^2}{H_R+\lambda}-\frac{(G_L+G_R)^2}{H_L+H_R+\lambda}]-\gamma</script><p>其中第一项为树的左孩子的分数，第二项为树的右孩子的分数，第三项为没有分裂的分数，$\gamma$在这里实际上是一个临界值，它的值越大，表示我们对切分后损失函数下降幅度要求越严。这个值也是可以在xgboost中设定的。Gain是正的，并且值越大，就越值得切分。</p>
<p>每一次分类选择Gain值最大的分裂方式，可以通过调节$\gamma$值的大小来改变树的分裂倾向，实现预剪枝。</p>
<p>其次Xgboost会在完整生成一棵决策树后回溯剪枝。</p>
<p><strong>注意：</strong>xgboost的切分操作和普通的决策树切分过程是不一样的。普通的决策树在切分的时候并不考虑树的复杂度，而依赖后续的剪枝操作来控制。xgboost在切分的时候就已经考虑了树的复杂度，就是那个γ参数。所以，它不需要进行单独的剪枝操作。</p>
<h2 id="Xgboost对缺失值的处理"><a href="#Xgboost对缺失值的处理" class="headerlink" title="Xgboost对缺失值的处理"></a>Xgboost对缺失值的处理</h2><p>当数据中含有缺失值的时候，我们可以不再填充缺失值。利用Xgboost的机制自动处理缺失值。</p>
<p><img src="/passages/2019-07-30-集成学习专题（二）/XGBoost缺失值处理.png" alt="XGBoost缺失值处理"></p>
<p>Xgboost的处理方式是，<strong>缺失值数据会被分到左子树和右子树分别计算损失，选择较优的那个。如果训练中没有数据缺失，预测时出现了数据缺失，默认分类到右子树。</strong></p>
<h2 id="Xgboost训练通常调整的参数"><a href="#Xgboost训练通常调整的参数" class="headerlink" title="Xgboost训练通常调整的参数"></a>Xgboost训练通常调整的参数</h2><p>Xgboost训练需要调整的参数：</p>
<ol>
<li>booster：选择每次迭代的模型，有两种选择：</li>
</ol>
<ul>
<li><p>gbtree：基于树的模型</p>
</li>
<li><p>gbliner：线性模型</p>
</li>
</ul>
<ol>
<li>n_estimatores：总共迭代的次数，即决策树的个数</li>
<li>eta：学习率，通过减少每一步的权重，可以提高模型的鲁棒性。</li>
<li>max_depth：树的深度</li>
<li>min_child_weight：决定最小叶子节点样本权重和</li>
<li>max_leaf_nodes：树上最大的节点或者叶子的数量</li>
<li>gamma：</li>
</ol>
<p><strong>在节点分裂时，只有分裂后损失函数的值下降了，才会分裂这个节点。</strong></p>
<p>Gamma指定了节点分裂所需的最小损失函数下降值。</p>
<p>这个参数的值越大，算法越保守。这个参数的值和损失函数息息相关，所以是需要调整的。</p>
<ol>
<li>lambda：权重的L2正则化项</li>
<li>alpha：权重的L1正则化项</li>
<li>objective：这个参数定义需要被最小化的损失函数</li>
<li>eval_metric：对于有效数据的度量方法</li>
</ol>
<h1 id="XGBoost和GBDT的异同"><a href="#XGBoost和GBDT的异同" class="headerlink" title="XGBoost和GBDT的异同"></a>XGBoost和GBDT的异同</h1><h2 id="Xgboost-GBDT在调参数时为什么树的深度很少就能达到很高的精度，而随机森林需要的深度相对较高？"><a href="#Xgboost-GBDT在调参数时为什么树的深度很少就能达到很高的精度，而随机森林需要的深度相对较高？" class="headerlink" title="Xgboost/GBDT在调参数时为什么树的深度很少就能达到很高的精度，而随机森林需要的深度相对较高？"></a>Xgboost/GBDT在调参数时为什么树的深度很少就能达到很高的精度，而随机森林需要的深度相对较高？</h2><p>Xgboost/GBDT是基于Boosting思想的集成学习方法，随机森林是基于Bagging思想的集成学习方法。<strong>Boosting主要关注降低偏差，Bagging主要关注降低方差。</strong></p>
<p>Bagging算法是这样做的：每个分类器都随机从原样本中做有放回的采样，然后分别在这些采样后的样本上训练分类器，然后再把这些分类器组合起来，简单的多数投票一般就可以。代表算法是随机森林。Boosting的意思是这样，他通过迭代地训练一系列的分类器，每个分类器采用的样本分布都和上一轮的学习结果有关。其代表算法是Adaboost，GBDT。</p>
<p>机器学习算法来说，其泛化误差可以分解为两部分，偏差和方差。</p>
<p>偏差指的是算法的期望预测与真实预测之间的偏差程度，反应了模型本身的拟合能力；方差度量了同等大小的训练集的变动导致学习性能的变化，刻画了数据扰动所导致的影响。</p>
<p>当模型越复杂时，拟合的程度就越高，模型的训练偏差就越小。但此时如果换一组数据可能模型的变化就会很大，即模型的方差很大。所以模型过于复杂的时候会导致过拟合。</p>
<p>当模型越简单时，即使我们再换一组数据，最后得出的学习器和之前的学习器的差别就不那么大，模型的方差很小。还是因为模型简单，所以偏差会很大。</p>
<p>对于Bagging算法来说，由于我们会并行地训练很多不同的分类器的目的就是降低这个方差，<strong>因为采用了相互独立的基分类器多了以后，方差的值会减小</strong>，所以对于每个基分类器来说，目标就是如何降低这个偏差，所以我们会采用深度很深甚至不剪枝的决策树。</p>
<p>对于Boosting来说，<strong>每一步我们都会在上一轮的基础上更加拟合原数据，所以可以保证偏差，</strong>所以可以保证偏差，对于每个基分类器来说，问题就在于如何选择方差更小的分类器，即更简单的分类器，所以我们选择深度很浅的决策树。</p>
<h2 id="Xgboost和GBDT的区别"><a href="#Xgboost和GBDT的区别" class="headerlink" title="Xgboost和GBDT的区别"></a>Xgboost和GBDT的区别</h2><ol>
<li><p>传统GBDT以CART作为基分类器，Xgboost还支持线性分类器，这个时候Xgboost相当于带L1和L2正则化项的逻辑斯蒂回归（分类问题）或者线性回归（回归问题）。</p>
</li>
<li><p>传统GBDT在优化时只用到一阶导数信息，Xgboost则对代价函数进行二阶泰勒展开，同时用到了一阶和二阶导数。</p>
</li>
<li><p>Xgboost在代价函数里加入了正则项，用于控制模型的复杂度，损失函数如下：</p>
<script type="math/tex; mode=display">
Obj = \sum_{i=1}^n l(y_i,\hat{y_i})+\sum_{k=1}^K\Omega(f_k)</script><p>正则项里包含了树的叶子节点个数、每个叶子节点上输出的score的L2模的平方和。</p>
<script type="math/tex; mode=display">
\Omega(f_t) = \gamma T+\frac{1}{2}\lambda \sum_{j=1}^T w_j^2</script></li>
<li><p>Xgboost支持列抽样</p>
</li>
</ol>
<p>Xgboost借鉴了随机森林的做法，支持列抽样，不仅能降低过拟合，还能减少计算。</p>
<p>传统的GBDT在每轮迭代时使用全部的数据。</p>
<ol>
<li><p>传统的GBDT没有设计对缺失值进行处理，Xgboost能够自动学习出缺失值的处理策略。</p>
</li>
<li><p>Xgboost工具支持并行</p>
</li>
</ol>
<p>Xgboost的并行不是tree粒度的并行，Xgboost也是一次迭代完才能进行下一次迭代的（第t次迭代的代价函数里包含了前面t-1次迭代的预测值）。<strong>Xgboost的并行是在特征粒度上的。</strong>决策树的学习最耗时的一个步骤就是对特征的值进行排序（因为要确定最佳分割点），Xgboost在训练之前，预先对数据进行了排序，然后保存为block结构，后面的迭代中重复地使用这个结构，大大减小计算量。这个block结构也使得并行成为了可能，在进行节点的分裂时，需要计算每个特征的增益，最终选增益最大的那个特征去做分裂，那么各个特征的增益计算就可以开多线程进行。</p>
<p>可并行的近似直方图算法：</p>
<p>树节点在进行分裂时，我们需要计算每个特征的每个分割点对应的增益，即用贪心法枚举所有可能的分割点。当数据无法一次载入内存或者在分布式情况下，贪心算法效率就会变得很低，所以Xgboost提出了一种可并行的近似直方图算法，用于高效地生成候选的分割点。</p>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>集成学习</tag>
        <tag>监督学习</tag>
        <tag>GBDT</tag>
        <tag>XGBoost</tag>
      </tags>
  </entry>
  <entry>
    <title>RESIDE:Improving Distantly-Supervised Neural Relation Extraction using Side Information</title>
    <url>/passages/2019-10-21-RESIDE/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>考虑到Knowledge Base（KB）包含其他side information（边界信息），例如关系别名（founded/co-founded -&gt; founderOfCompany）。RESIDE模型的提出为了充分利用来自知识库的边界信息提高关系抽取效果。模型使用实体类型与关系别名信息在预测关系过程施加软约束。RESIDE采用图卷积网络编码句法信息即使在有限的边界信息也可以取得不错的效果。<strong>代码开源</strong></p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>大规模知识库：Freebase  and Wikidata 应用于很多NLP任务中像问答、web搜索等。知识库本身是不全面的，关系抽取任务目标是抽取文本中实体对的语义关系填充知识库。关系对明确的条件下该任务可以被简单的建模为分类任务。</p>
<p>multi-instance learning目的在于松弛远程监督的假设，以前的假设两个实体在知识库中，之后所有提到所有句子均表达同样的关系。</p>
<p>在神经网络模型中，attention机制是用于缓解远程监督数据集的噪声。来自依赖文法的句法信息用于获取tokens之间的长期依赖。GCN方法编码文法依赖信息在2017年被提出。但是上述方法均依赖远程监督的有噪音示例。</p>
<p>Relevant side information例如实体类型信息有助于纠正关系预测，这是因为每个关系约束了对应的目标实体类型。同理关系别名也是有价值的。RESIDE充分使用知识库中实体类型与关系别名规则信息，在预测关系时增加软约束。</p>
<p>文章贡献：</p>
<ol>
<li><p>一个全新的神经网络方法，利用知识库中的附加信息采用规则方法提高远程监督关系抽取效果。</p>
</li>
<li><p>RESIDE使用图卷积对句法信息进行建模，并被证明即使在有限的边信息情况下也具有竞争力。</p>
</li>
<li>通过实验证实了RESIDE效果好于baseline，且代码开源链接如下：<a href="http://github.com/malllabiisc/RESIDE" target="_blank" rel="noopener">http://github.com/malllabiisc/RESIDE</a></li>
</ol>
<h1 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h1><p><strong>远程监督：</strong> 句子会被错误标注，为了缓解这个问题，2010年Riedel等人采用multi-instance single-label learning 缓解远程监督问题，随后为了处理实体间关系重叠问题，学者们提出了multi-instance multi-label learning.</p>
<p><strong>神经网络关系抽取：</strong>传统方法强烈依赖手工工程特征的质量。2014年Zeng提出一个端到端CNN方法获取相关词汇与句子级特征。后通过picewise max-pooling以及attention机制从多个有效句子中学习。另一方面，依赖树特征对关系抽取任务有着影响。2018年He等人使用依赖树输入到一个recursive tree-GRU模型中来提升结果。本文之所以选用图卷积神经网络在于GCN在句法信息建模上有着不错的效果。</p>
<p><strong>关系抽取边界信息：</strong>实体描述信息被充分利用（Ji et al., 2017），但是这样的信息并非对所有实体均可利用。实体类型信息被利用主要是通过联合学习实体类型与关系抽取模型来降低远程监督带来的噪声。像Freebase这种知识库可以直接得到可靠的实体类型信息。本文中使用了实体类型信息与关系别名来源于KBs，同时还使用无监督的开放信息提取方法（Open IE），发现无需预定义本体的可能关系事实作为side information。</p>
<h1 id="图卷积神经网络（GCN）"><a href="#图卷积神经网络（GCN）" class="headerlink" title="图卷积神经网络（GCN）"></a>图卷积神经网络（GCN）</h1><h2 id="GCN-on-labeled-Directed-Graph"><a href="#GCN-on-labeled-Directed-Graph" class="headerlink" title="GCN on labeled Directed Graph"></a>GCN on labeled Directed Graph</h2><p>对于有向图而言，$G =(V,\varepsilon)$，$V$和$\varepsilon$分别表示顶点的集合与边的集合，一条边从点$u$到点$v$带有标签$l<em>{uv}$被表示为$(u,v,l</em>{uv})$，然而在有向边信息并非一定沿着其方向传播，这里定义了一个更新边的集合$\varepsilon^{‘}$包含转置边$(v,u,l_{uv}^{-1})$与自环$(u,u,T)$，其中$T$是一个特殊符号标记自环。定义每个节点$v$的一个初始向量表示$x_v$，使用GCN，计算得到一个更新的d维度隐层表示$h_v$，这里仅仅考虑它的近邻，公式如下：</p>
<script type="math/tex; mode=display">
h_v= f(\sum_{u \in N(v)}(W_{l_{uv}}x_{u}+b_{l_{uv}}))</script><p>其中$N(v)$反映$v$近邻的集合基于$\varepsilon^{‘}$，$f$为任意非线性激活函数。为了捕获多跳邻域，可以叠加多个GCN层。故第k层GCN可表示为:</p>
<script type="math/tex; mode=display">
h_v^{k+1} = f(\sum_{u \in N(u)}(W_{l_{uv}}^kh_u^k+b_{l_{uv}}^k))</script><h2 id="Integrating-Edge-Importance"><a href="#Integrating-Edge-Importance" class="headerlink" title="Integrating Edge Importance"></a>Integrating Edge Importance</h2><p>在自动构造的图中，有些边可能是错误的因此需要丢弃。GCN中的edgewise gating有助于抑制噪声边。实现方法即为图中的每条边分配一个相关分数。在第k层边$(u,v,l_{uv})$的重要性(edgewise gating)计算公式如下：</p>
<script type="math/tex; mode=display">
g_{uv}^{k} = \sigma ( h_{u}^{k} \cdot \hat w_{l_{uv}}^{k}+\hat b_{l_{uv}}^{k})</script><p>使用edgewise gating，最终的GCN对节点$v$的编码公式为：(文章中非线性函数使用Relu)</p>
<script type="math/tex; mode=display">
h_v^{k+1} = f(\sum_{u \in N(v)}g_{uv}^{k}*(W_{l_{uv}}^kh_{u}^k+b_{l_{uv}}^k))</script><h1 id="RESIDE"><a href="#RESIDE" class="headerlink" title="RESIDE"></a>RESIDE</h1><p>由三个组件组成：</p>
<ol>
<li><strong>句法句子编码：</strong>使用Bi-GRU编码连续的位置与词嵌入，为了捕获长范围依赖，输入依赖树到GCN将编码结果附加到每个token表示中。最终，attention在token级别应用抑制不相关的tokens，得到一个全句的编码结果。</li>
<li><strong>边界信息采集：</strong>使用额外的监督来自KB、利用Open IE方法得到相关边界信息。</li>
<li><strong>示例集整合：</strong>句法句子编码器的句子表示与前一步得到的关系embeding相连接。之后，使用句子级attention，这样整个包可以得到一个表示。在输入softmax分类器之前将表示与实体类型表示连接。</li>
</ol>
<p><img src="/passages/2019-10-21-RESIDE/GCN.png" alt="GCN"></p>
<h2 id="句法句子编码"><a href="#句法句子编码" class="headerlink" title="句法句子编码"></a>句法句子编码</h2><p>采用k-dimensional Glove embedding表示每个token。使用的是相对于目标实体的相对位置。使用Bi-GRU的原因在于在许多任务中编码上下文token十分有效。Bi-GRU虽然可以捕获long context，但是通过依赖边才有助于获得long-range依赖。文法依赖树的生成采用Stanford CoreNLP。因为依赖关系图有55个不同的边标签，将所有标签合并在一起可以显著地将模型参数化。因此使用了三种边标签基于边的方向：[forward($\longrightarrow$)，backward($\longleftarrow $)，self-loop($T$)]。所以边标签定义如下：</p>
<p><img src="/passages/2019-10-21-RESIDE/edge-label.png" alt="edge-label"></p>
<p>将GCN中的语法图编码连接到Bi-GRU输出即$h<em>i^{concat}=[h_i^{gru};h</em>{i^{k+1}}^{gcn}]$，得到最终的token表示。由于tokens在RE任务中并非等同相关的，所以采用注意力机制计算每个token的相关度，公式如下：</p>
<script type="math/tex; mode=display">
\alpha_i = \frac{exp(u_i)}{\sum_{j=1}^mexp(u_j)}</script><script type="math/tex; mode=display">
u_i = h_i^{concat}\cdot r</script><p>$r$是一个随机查询向量。</p>
<p><img src="/passages/2019-10-21-RESIDE/side-information.png" alt="side-information"></p>
<p>RESIDE使用Open IE提取实体间的关系短语，用$P$表示。P可以扩展通过文法依赖路径包含token的一跳距离。从P中提取的短语与关系别名$R$之间的匹配程度可以提供有关该关系与句子相关性的重要线索。相似度计算采用余弦相似度，找到与句子最为匹配的关系别名，使用余弦相似度阈值过滤掉噪声别名。模型RESIDE定义一个匹配关系编码$h^{rel}$与句子表示输入$s$相连。对于句子满足条件$|P| \gt 1$，这种情况下我们可能会得到多个匹配关系，在这种情况下，我们取它们嵌入的平均值</p>
<p><strong>Note：</strong>仅提供关系名称作为别名也有助于取得较好效果。</p>
<p>对于实体类型边界信息，文章定义了一个$k_t$维编码叫做entity type embedding（$h^{type}$）。当一个实体在不同语境下有多个类型时，文章取每个类型的编码均值。这个结果是用于连接目标实体与输入到关系分类器的最终包级别表示，来实现效果提升。为了避免参数过多，没有使用细粒度的112个实体类型，使用了38粗粒度类型。</p>
<p><strong>Note：</strong>关系别名连接句子，实体类型（主语与宾语，即两个实体）连接包结构，最后输入到softmax分类器中求解。</p>
<h1 id="实验设置与结果"><a href="#实验设置与结果" class="headerlink" title="实验设置与结果"></a>实验设置与结果</h1><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><ol>
<li><strong>NYT10：</strong>Riedel 在2010年对齐Freebase relations与NYT corpus，标准数据集最为常用，53分类，在此不做介绍。</li>
<li><strong>GIDS：</strong>Jat等人创建Google Distant Supervision (GIDS)数据集通过扩展谷歌关系抽取数据集，即为每一个关系对添加额外的示例。该数据集保证至少一个假设在多示例学习中成立，这使得自动自动评估更可靠，无需人工验证，5个分类。</li>
</ol>
<h2 id="Baselines"><a href="#Baselines" class="headerlink" title="Baselines"></a>Baselines</h2><p><strong>传统方法：</strong>Mintz：多类逻辑回归模型； MultiR：多示例概率图模型； MIMLRE：联合多示例与多标签概率图模型；</p>
<p><strong>神经网络方法：</strong>PCNN：基于卷积神经网络使用picewise最大池化处理句子表示；PCNN+ATT：就是在上个模型基础上加入句子级attention；BGWA：使用word-level与sentence-level的Bi-GRU关系抽取模型；</p>
<h2 id="评估标准"><a href="#评估标准" class="headerlink" title="评估标准"></a>评估标准</h2><p>与以前的工作相同，采用held-out evaluation，模型性能评估采用Precision-Recall curve和top-N precision度量。</p>
<h2 id="结果分析"><a href="#结果分析" class="headerlink" title="结果分析"></a>结果分析</h2><ol>
<li>所有的非神经网络的baseline表现效果相对较差，因为它们使用的特征大多来自于NLP工具，特征可能是有错误的。</li>
<li>合并辅助信息（side information）有助于提高模型效果。（在组件移除效果也能体现）</li>
<li>Attention 在远程监督关系抽取任务有着不错的效果。</li>
<li>GCN有效编码句法信息（RESIDE组件移除后P-R 曲线下面积）</li>
</ol>
<p><strong>关于Relation Alias这一边界信息</strong>：文章实验采用四种不同的设置：</p>
<p><strong>None：</strong>关系别名没有提供；</p>
<p><strong>One：</strong>关系名作为别名；</p>
<p><strong>One+PPDB：</strong>关系名使用Paraphrase Database（PPDB）扩展；</p>
<p><strong>All：</strong>手动映射到相应的wikidata属性获取关系别名，补充关系别名少有的信息；</p>
<p>实验结果反映有限的关系别名也会提升性能，使用更多的别名信息有助于性能进一步提高。</p>
<h1 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h1><p>没有未来展望，就是GCN+side information在此不做总结了。</p>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      <categories>
        <category>文献阅读</category>
      </categories>
      <tags>
        <tag>Relation Extraction</tag>
        <tag>EMNLP</tag>
        <tag>GCN</tag>
      </tags>
  </entry>
  <entry>
    <title>Fine-tuning Pre-Trained Transformer Language Models to Distantly Supervised Relation Extraction</title>
    <url>/passages/2019-10-17-Fine-tuning-Pre-Trained-Transformer-Language-Models-to-Distantly-Supervised-Relation-Extraction/</url>
    <content><![CDATA[<h1 id="论文摘要"><a href="#论文摘要" class="headerlink" title="论文摘要"></a>论文摘要</h1><p>现阶段关系抽取方法采用多示例学习与提供的语义与语境信息有效的确定关系类别。这样模型会识别偏向于高精确率的关系，忽略那些关系长尾句子中（in the long tail），为了解决这个问题，利用预训练语言模型Open AI Generative Pre-trained Transformer（GPT），除了从词法句法的角度解决问题外，也更注重大量的常识知识（一些重要的特征识别更多元的关系），在高召回率情况下在NYT10数据集下实现较好的效果。</p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>关系抽取是许多自然语言处理应用的关键组件，例如知识库普及与问答系统。远程监督是一种流行方法启发式生成标签数据用于训练关系抽取系统，方法是通过对齐文本中的实体元组与已知关系示例来自于知识库中，但是存在噪声标签与知识库信息不完全。</p>
<p>现阶段关系抽取方法解决问题是通过多示例学习与显式提供语义和句法知识指导模型，例如：词性与文法依赖信息。最近的方法利用附加信息，例如：意译、关系别名与实体类型。但是依旧会出现摘要中提到的问题。</p>
<p>深度语言表示，例如那些由Transformer通过语言建模学到的，已经被证实通过无监督的预训练就可以隐式地捕获文本的有价值的语义与句法属性，并在广泛的自然语言处理任务中取得不错的效果。文章假设预训练语言模型为远程监督提供一个强烈的信号，更好的基于知识获取指导关系抽取任务。使用隐形特征代替显性语言知识与附加信息提高领域和语言的独立性，并且能够增加识别出关系的多样性。</p>
<p>在文章中，引入一个远程监督关系抽取Transformer模型。文章扩展标准的Transformer模型通过一个有选择性的注意力机制处理多示例学习与预测，整个过程直接微调模型在远程监督关系抽取。文章提及该处理最小化显式特征提取并降低错误累积的风险。<strong>此外，文章引入自注意结构允许模型有效地长期依赖关系。</strong></p>
<p>论文贡献：</p>
<ol>
<li><p>将GPT应用于远程监督数据集包级、多示例训练与预测，对句子级信息采用注意力机制进行选择聚合产生包级预测。</p>
</li>
<li><p>在NTY数据集上实现较好的（Area of Under Curve）AUC效果，相比于RESIDE，PCNN+ATT in held-out evaluation.</p>
</li>
<li><p>手动评估跟踪结果，证明模型预测了一组更加多样化的关系，并在高召回率下表现良好。</p>
</li>
<li>开源贡献：<a href="https://github.com/DFKI-NLP/DISTRE" target="_blank" rel="noopener">https://github.com/DFKI-NLP/DISTRE</a></li>
</ol>
<h1 id="模型方法"><a href="#模型方法" class="headerlink" title="模型方法"></a>模型方法</h1><h2 id="Transformer-Decoder模型"><a href="#Transformer-Decoder模型" class="headerlink" title="Transformer-Decoder模型"></a>Transformer-Decoder模型</h2><p>Transformer-Decoder在多个层上重复编码给定的输入表示（Transformer 块），包含掩码多头注意力机制接一个position-wise feedforward operation.，不同于原始的Transformer，鉴于没有编码器，模型不同于原始模型，不含任何形式的无掩码自注意力机制。</p>
<script type="math/tex; mode=display">
h_0 = TW_e+W_p</script><script type="math/tex; mode=display">
h_l =tf_block(h_{l-1}), l \in [1,L]</script><p>$T$ 是一个句子中词索引的one-hot 行向量矩阵 ，$W_e$是词向量矩阵，$W_p$是位置向量矩阵，$L$是Transformer块数，$h_t$表示$l$层的state。之所以加入词位置向量在于Transformer模型本身不含隐性的位置信息，自注意结构有效的解决长距离依赖。</p>
<p><img src="/passages/2019-10-17-Fine-tuning-Pre-Trained-Transformer-Language-Models-to-Distantly-Supervised-Relation-Extraction/Transformer-Block_architecture.png" alt="Transformer-Block_architecture"></p>
<h2 id="contextualized-representations语言模型学习方法"><a href="#contextualized-representations语言模型学习方法" class="headerlink" title="contextualized representations语言模型学习方法"></a>contextualized representations语言模型学习方法</h2><script type="math/tex; mode=display">
L_1(C) = \sum_i \log P(c_i|c_{i-1},...,c_{i-k};\theta)</script><p>无监督预训练语言表示模型采用最大似然估计作为损失函数，其中$k$表示上下文窗口数，通过条件概率$P$预测下一个词$c_i$ （貌似只是单向的），Transformer模型目标函数：</p>
<script type="math/tex; mode=display">
P(c) = softmax(h_LW_e^T)</script><p>整个优化过程采用随机梯度下降，该结果是对于每一个词的概率分布用于下游任务的输入序列。</p>
<h2 id="Transformer多示例学习"><a href="#Transformer多示例学习" class="headerlink" title="Transformer多示例学习"></a>Transformer多示例学习</h2><p>实现包级别多示例学习在Transformer结构基础上，文章假设一个标记的数据可以表示为$D =\lbrace(x<em>i,head_i,tail_i,r_i)\rbrace</em>{i=1}^N$，其中$head_i$与$tail_i$是相对于头尾实体的相对位置，$x_i$是每个例子包含的输入词序列（句子表示）$x_i = [x^1,…x^m]$。对于包中句子$S=\lbrace x_1,x_2,…,x_n\rbrace$每一个词序列（句子）通过预训练模型使用最后一个状态表示$h_L$的最后一个状态$h_L^m$对应于$x_i$的每一个表示$s_i$，使用$s$用于分类，公式如下：</p>
<script type="math/tex; mode=display">
s=\sum_i \alpha_is_i</script><p>选择注意力可以学习认清那些带有明显特征表示某个关系的句子同时不重视那些包含噪音的句子，权重计算公式如下：</p>
<script type="math/tex; mode=display">
\alpha_i = \frac{exp(s_ir)}{\sum_{j=1}^n exp(s_jr)}</script><p>最终优化目标如下：</p>
<script type="math/tex; mode=display">
p(l|S,\theta) = softmax(W_{r}s+b)</script><script type="math/tex; mode=display">
L_2(D) = \sum_{i=1}^{|S|}logP(l_i|S_i,\theta)</script><p>由于引入语言模型在微调过程中有助于改善泛化能力实现快速收敛，故：</p>
<script type="math/tex; mode=display">
L(D) = \lambda*L_1(D)+L_2(D)</script><p>标量$\lambda$反映微调期间语言模型的权重值。</p>
<h3 id="模型输入的特殊性-BPE编码算法"><a href="#模型输入的特殊性-BPE编码算法" class="headerlink" title="模型输入的特殊性-BPE编码算法"></a>模型输入的特殊性-BPE编码算法</h3><p>充分利用分词信息，使用byte pair encoding（BPE）对输入文本分词。BPE是用来解决未登录词问题的一种方法。在做NLP的时候，我们通常会对语料做一个预处理，生成语料的一个字典。为了不让字典太大，我们通常只会把出现频次大于某个阈值的词丢到字典里边，剩下所有的词都统一编码成#UNK。这是很经典很朴素的做法，这种方法不能解决未登录词的问题。<strong>未登录词是指在验证集或测试集出现了但训练集从来没见到过的单词。</strong>这种未登录词对分词、NLP其他任务性能有很大影响。常见的解决方法有：给低频词设置一个back-off表，当出现低频词的时候就去查表；或者不做word-level的东西，转做char-level的东西，因为不管什么词肯定是由若干个字母组成的。</p>
<p>两种方法各有优劣。第一种方法，简单直接，若干back-off做的很好会对低频词处理有很大提升（机器翻译）；但这种方法依赖于back-off表的质量，而且也没法处理非登录词问题。第二种方法，从源头解决未登录词的问题，但是模型粒度太细，一般出来的效果不是特别好。我认为可能非串级别导致词信息损失过多。</p>
<p>2016年《Neural Machine Translation of Rare Words with Subword Units》提出了基于subword来生成词典的方法。他的核心思想是综合word-level and char-level的优势，从语料中学习到所有词里边频次高的字符串子串。然后把这些频次高的字符串子串收集起来形成一个字典。这个字典里边，既存在char-level级别字符也存在word-level级别的子串。然后把这个字典用于模型的训练。论文在寻找频次高的子串时，使用了BPE算法，就是把子串encoding：每次合并在语料中同一个词里面的、相邻的、出现频率最高的两个子串。decoding的时候，根据生成的voc.txt做相应的替换。</p>
<p>关系抽取输入为头尾实体有分隔符分割，后面跟着包含句子的token序列，以一个特殊的分类token作为结尾。由于模型处理输入是从左到右的，故论文在最开始添加关系论据，使得注意力机制在处理句子token序列过程中偏向于对应的token表征。</p>
<p><img src="/passages/2019-10-17-Fine-tuning-Pre-Trained-Transformer-Language-Models-to-Distantly-Supervised-Relation-Extraction/input_for_fine-tuning.png" alt="input_for_fine-tuning"></p>
<h2 id="实验设置"><a href="#实验设置" class="headerlink" title="实验设置"></a>实验设置</h2><p>文章在远程监督数据集NYT10上使用PCNN+ATT与RESIDE作为基准进行比较。</p>
<p>PCNN（The piecewise convolutional neural network）: 将每个句子分割成实体对信息的左中右三个部分，后面接卷积神经网络编码与选择注意力机制得到一个bag-level的表示用于关系分类器。</p>
<p>RESIDE：使用双向循环门控单元（Bi-GRU）去编码句子，后面接一个图卷积神经网络编码显性提供的文法依赖树信息。然后将其与命名实体识别信息相结合，获得一个句子表示，句子表示通过选择注意力整合并输入到关系分类器中。</p>
<h3 id="NYT10-Dataset"><a href="#NYT10-Dataset" class="headerlink" title="NYT10 Dataset"></a>NYT10 Dataset</h3><p>2010年Riedel等人提出，对齐Freebase与New York Times corpus，采用2005-2006年信息用于训练，2007年的信息用于测试，目前一般使用2016年Lin等人预处理后的版本数据集，该数据集开源。其测试集也是通过远程监督生成，所以仅仅能提供性能大概度量的方法，P@N是基于manual evaluation。</p>
<h3 id="语言模型预训练"><a href="#语言模型预训练" class="headerlink" title="语言模型预训练"></a>语言模型预训练</h3><p>目标是反映微调在远程监督关系抽取任务的效率，所以直接重用2018年Radford等人发布的语言模型，扩展了模型的词库添加了task-specific tokens（开始，结束，分隔符）。</p>
<h2 id="实验结果与结论"><a href="#实验结果与结论" class="headerlink" title="实验结果与结论"></a>实验结果与结论</h2><p><img src="/passages/2019-10-17-Fine-tuning-Pre-Trained-Transformer-Language-Models-to-Distantly-Supervised-Relation-Extraction/P-R_curves.png" alt="P-R_curves"></p>
<p>文章在结果上强调P-R曲线的balance问题，即整体表现良好（AUC面积最好），这在现实世界中可能具备很高的应用价值，baselines方法都体现出高召回率下drop early现象。</p>
<p><img src="/passages/2019-10-17-Fine-tuning-Pre-Trained-Transformer-Language-Models-to-Distantly-Supervised-Relation-Extraction/variety_relations.png" alt="variety_relations"></p>
<p>之所以使用手动评估原因在于hold-out dataset不能反映模型存在false positive标签于知识库信息不完整下的真实性能，故使用手工估计评估。文章模型DISTRE的手动评估结果显示大部分错误容易在高精确率错误标签中出现，例如/location/country/capital。高精确率的Top 300 相比于baselines种类更多。PCNN+ATT模型更关注提取实体类型信号和基本句法模式（包含关系与国籍关系占比91%），例如“LOC in LOC”，适合处理简单模式下的内容，后两种模型（RESIDE与DISTRE）可以处理更复杂的模式，比如实体距离更远。此外文章提出的模型也列出了一些句子级的预测结果。<strong>文章的TOP N（N=300）不是最高的，但是balance好。相比之下利用预训练模型获得隐性特征不同于RESIDE需要显性特征信息，增加domain与language的独立性，预处理可以省略。</strong></p>
<p>文章扩展点在于通用结构引入额外的背景知识或者进行深度语言模型表示处理。</p>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p><strong>关系抽取方向：</strong>最初RE任务基于统计分类器与核方法结合使用具体的句法特征实现，句法特征可以是词性、命名实体识别、形态特征（morphological features）、词网上下位（WordNet hypernyms）。后来被基于序列的方法所取代，具体的特征被替换为分布式（离散）的词与句法特征在神经网络中训练。最短文法依赖信息关注句子中的名词与动作，2015年Xu等人将其输入到基于LSTM的关系分类模型。2018年张等人在TACRED数据集上取得不错的效果，应用了a combination of pruning and graph convolutions to the dependency tree.</p>
<p><strong>远程监督关系抽取方向：</strong></p>
<ol>
<li>multi-instance learning and multi-instance multi-label learning (at least one)</li>
<li>PCNN</li>
<li>selective attention</li>
<li>adversarial training</li>
<li>noise model (Luo et al 2017)</li>
<li>soft labeling</li>
<li>graph convolutions and capsule networks（胶囊网络）</li>
<li>previously methods</li>
</ol>
<p><strong>语言表示与Transfer Learning：</strong></p>
<p>2018年Peters等人提出embeddings from language models（ELMo），在各种自然语言处理任务使用语境化词表征代替静态预训练词向量提高性能。通过无监督语言建模学习语言表示，显著提高文本分类性能，防止过度拟合，提高了样本效率。通用域的预训练与具体任务的微调有助于实现state-of-the-art的结果。2019年Radford等人发现增加语言模型的大小能更好的归纳下游任务，但是仍然欠拟合大规模文本集。</p>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      <categories>
        <category>文献阅读</category>
      </categories>
      <tags>
        <tag>Relation Extraction</tag>
        <tag>ACL</tag>
      </tags>
  </entry>
  <entry>
    <title>EM算法专题</title>
    <url>/passages/2019-08-02-EM%E7%AE%97%E6%B3%95%E4%B8%93%E9%A2%98/</url>
    <content><![CDATA[<h1 id="最大似然概率"><a href="#最大似然概率" class="headerlink" title="最大似然概率"></a>最大似然概率</h1><p>以测量校园里学生身高分布为例，分为男生和女生，分别抽取100个人。假设他们的身高是服从高斯分布的，但是这个分布的均值$\mu$和方差$\sigma^2$是未知的，我们要估计这两个参数，记作$\theta=[\mu,\sigma]^T$。</p>
<p>我们独立地按照概率密度$p(x|\theta)$抽取100个身高，组成样本集X，我们想通过样本集X来估计出未知参数$\theta$。其中的未知参数是$\theta = [\mu,\sigma]^T$。抽到的样本集是$X={x_1,x_2,…,x_N}$，其中$x_i$表示抽到第i个人的身高，N为抽到样本个数。</p>
<p>在$\theta$参数的情况下抽取得到样本集的概率，就是从分布是$p(x| \theta)$的总体样本中抽取到这100个样本的概率，也就是样本集X中各个样本的联合概率，用下式表示：</p>
<script type="math/tex; mode=display">
L(\theta) = L(x_1,..,x_n;\theta) = \prod_{i=1}^np(x_i;\theta),\theta \in \Theta</script><p>这里$L(\theta)$就是参数$\theta$相对于样本集的似然函数（likehood function）</p>
<p>那么$\theta$的最大似然估计量，记为：$\hat\theta = argmaxl(\theta)$</p>
<p>有时为了我便于分析与计算，定义对数似然函数，将连乘变成连加：</p>
<script type="math/tex; mode=display">
H(\theta) = \ln L(\theta) = \ln\prod_{i=1}^{n}p(x_i;\theta) =\sum_{i=1}^n\ln p(x_i;\theta)</script><p>之后为求一个函数的最值，需要求导使得导数为0，那么解这个方程得到的$ \theta$就是了（前提是函数$L(\theta)$连续可微）；如果$\theta$包含多个参数的向量，则求$L(\theta)$对所有参数的偏导数，n个未知的参数，就有n个方程，方程组的解就是似然函数的极值点。</p>
<h2 id="求解最大似然函数估计值的一般步骤"><a href="#求解最大似然函数估计值的一般步骤" class="headerlink" title="求解最大似然函数估计值的一般步骤"></a>求解最大似然函数估计值的一般步骤</h2><p>（1）写出似然函数；</p>
<p>（2）对似然函数取对数，并整理；</p>
<p>（3）求导数，令导数为0，得到似然方程；</p>
<p>（4）解似然方程，得到的参数即为所求。</p>
<p><strong>注意</strong>：参数只是对应了一个类别，也就是说男生，女生身高的问题，就是在已知这一群人都是男生的情况下，获得这个类别的参数，或者都是女生的情况下获得。如果两个类别混在一起，那么就是下面的EM估计了。</p>
<h1 id="EM算法"><a href="#EM算法" class="headerlink" title="EM算法"></a>EM算法</h1><p><strong>EM出现的原因就是抽取的样本不知道是哪个分布抽取的</strong>。例如上例的最大似然，两种高斯分布的人（男生、女生）混在一块了，我们又不知道哪些人属于第一个高斯分布，哪些属于第二个，所以就没法估计这两个分布的参数。反过来，只有当我们对这两个分布的参数作出了准确的估计的时候，才能知道到底哪些人属于第一个分布，那些人属于第二个分布。所以这里就是说EM估计就是因为多了一个<strong>隐含变量（抽取得到的每个样本都不知道是从哪个分布抽取的）使得本来简单的可以求解的问题变复杂了。</strong></p>
<p>简单的处理办法是先初始化隐含变量，然后估计出每个类别对应的分布参数。然后再根据这个分布参数去调整每个样本的隐含参数，依次迭代。其能迭代成功的原因在于<strong>我们可以证明似然函数是一个单调函数。</strong></p>
<h2 id="EM算法的推导"><a href="#EM算法的推导" class="headerlink" title="EM算法的推导"></a>EM算法的推导</h2><p>给定的训练样本是${x^{(1)},…,x^{(m)}}$，样例间独立，我们想找到每个样例隐含的类别z，能使得$p(x,z)$最大。$p(x,z)$的最大似然估计如下：</p>
<script type="math/tex; mode=display">
l(\theta) = \sum_{i=1}^m \log p(x;\theta) = \sum_{i=1}^m\log\sum_zp(x,z;\theta)</script><p>第一步是对极大似然取对数，第二步是对每个样例的每个可能类别z求联合分布概率和。但是直接求$\theta$一般比较困难，因为有隐藏变量z存在，但是一般确定了z后，求解就容易了，也就是说我们的目标是找到合适的$\theta$和z让$L(\theta)$最大。</p>
<p><strong>EM是一种解决存在隐含变量优化问题的有效方法。竟然不能直接最大化$l(\theta)$，我们可以不断地建立$l$的下界（E步），然后优化下界（M步）。</strong></p>
<p>对于每一个样例i，让$Q_i$表示该样例隐含变量z的某种分布，$Q_i$满足的条件是$\sum_xQ_i(z) = 1, Q_i(z) \ge 0$。（如果z是连续性的，那么$Q_t$是概率密度函数，需要将求和符号换做积分符号）。比如要将班上学生聚类，假设隐藏变量z是身高，那么就是连续的高斯分布。如果按照隐藏变量是男女，那么就是伯努利分布了。</p>
<p>则似然公式如下：</p>
<script type="math/tex; mode=display">
\sum_i \log p(x^{(i)};\theta) = \sum_i\log p(x^{(i)},z^{(i)};\theta) ,(1)式\\
= \sum_i \log \sum_{z^{(i)}}Q_i(z^{(i)})\frac{p(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})},(2)式\\
\ge \sum_i\sum_{z^{(i)}}Q_i(z^{(i)})\log \frac{p(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})},(3)式</script><p>看似最后只多了一个未知变量$Q_i(z^{(i)})$而已，实际上变到（3）式的时候公式由“和的对数”变为“对数的和”，这样求导就容易了。值得注意的是，（3）式变为了不等号，<strong>这就是Jensen不等式（就是对凹函数的公式: f(E[X]&gt;=E[f(X)])）的大显神威的地方。</strong></p>
<p>（1）到（2）比较直接，就是分子分母同乘以一个相等的函数。（2）到（3）利用了Jensen不等式，考虑到$\log(x)$是凹函数（二阶导数小于0），而且$\sum_{z^{(i)}}Q_i(z^{(i)})[\frac{p(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})}]$就是$[p(x^{(i)},z^{(i)};\theta)/Q_i(z^{(i)})]$的期望。（依期望公式中的Lazy Statistician规则）</p>
<h3 id="Lazy-Statistician规则"><a href="#Lazy-Statistician规则" class="headerlink" title="Lazy Statistician规则"></a>Lazy Statistician规则</h3><p>设Y是随机变量X的函数，$Y=g(X)$（g是连续函数），那么：</p>
<p>（1） X是离散型随机变量，它的分布律为$P(X=x<em>k) = p_k,k=1,2,…$。若$\sum</em>{k=1}^{\infty}g(x<em>k)p_k$绝对收敛，则有$E(Y) =E[g(X)] = \sum</em>{k=1}^{\infty}g(x_k)p_k$</p>
<p>（2） X是连续型随机变量，它的概率密度为$f(x)$，若$\displaystyle\int^{\infty}<em>{-\infty}{g(x)f(x)dx}$绝对收敛，则有$E(Y)= E[g(X)] =\displaystyle\int^{\infty}</em>{-\infty}{g(x)f(x)dx}$</p>
<p>依据上述规则，上面的（2）式到（3）式的不等式可以写成：似然函数$L(\theta)&gt;=J(z,Q)$，那么我们可以通过不断的最大化这个下界J，来使得$L(\theta)$不断提高，最终达到它的最大值。</p>
<p><img src="/passages/2019-08-02-EM算法专题/EM_iter.jpg" alt="EM_iter"></p>
<p>见上图，我们固定$\theta$，调整Q(z)使得下界$J(z,Q)$上升至与$L(\theta)$在此点$\theta$处相等（绿色曲线到蓝色曲线），然后固定$Q(z)$，调整$\theta$使下界$J(z,Q)$达到最大值（$\theta^t$到$\theta^{t+1}$），然后再固定$\theta$，调整Q(z)…直到收敛到似然函数$L(\theta)$的最大值处的$\theta^{*}$。这里有两个问题：什么时候下界$J(z,Q)$与$L(\theta)$在此点$\theta$处相等？为什么一定会收敛？</p>
<p>这个过程可以看作是对$l(\theta)$求了下界。对于$Q_i$的选择，有多种可能，<strong>哪种更好？</strong>假设$\theta$已经给定，那么$l(\theta)$的值就决定于$Q_i(z^{(i)})$和$p(x^{(i)},z^{(i)})$了。我们可以通过调整这两个概率使下界不断上升，以逼近$l(\theta)$的真实值，那么什么时候算是调整好了呢？当不等式变成等式时，说明我们调整后的概率能够等价于$l(\theta)$了。按照这个思路，我们要找到等式成立的条件。根据Jensen不等式，要想让等式成立，需要让随机变量变成常数值，这里得到：</p>
<script type="math/tex; mode=display">
\frac{p(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})} = c</script><p>c为常数，不依赖于$z^{(i)}$。对此式子做进一步推导，我们知道$\sum_zQ_i(z^{(i)})=1$，那么也就有$\sum_z p(x^{(i)},z^{(i)};\theta) =c$（多个等式分子分母相加不变，这个认为每个样例的两个概率比值都是c），那么有下式：</p>
<script type="math/tex; mode=display">
Q_i(z^{(i)}) = \frac{p(x^{(i)},z^{(i)};\theta)}{\sum_zp(x^{(i)},z;\theta)}\\
= \frac{p(x^{(i)},z^{(i)};\theta)}{\sum_zp(x^{(i)};\theta)}\\
= p(z^{(i)}|x^{(i)};\theta)</script><p>至此，我们推出了在固定其他参数$\theta$后，$Q_i(z^{(i)})$的计算公式就是后验概率，解决了$Q_i(z^{(i)})$如何选择的问题。这一步就是E步，建立$l(\theta)$的下界。接下来的M步，就是给定$Q_i(z^{(i)})$后，调整$\theta$，去极大化$l(\theta)$的下界（在固定$Q_i(z^{(i)})$后，下界还可以调整的更大）。那么一般的EM算法步骤如下：</p>
<p>循环重复直到收敛{<br>            (E步)，对于每一个i，计算</p>
<script type="math/tex; mode=display">
Q_i(z^{(i)}) := p(z^{(i)}|x^{(i)};\theta)</script><p>​            (M步)，计算</p>
<script type="math/tex; mode=display">
\theta:= \arg\max_{\theta}\sum_i\sum_{z^{(i)}}Q_i(z^{(i)})\log \frac{p(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})}</script><p>}</p>
<p>究竟怎么确保EM收敛？假定$\theta^{(t)}$和$\theta^{(t+1)}$是EM第t次和t+1次迭代后的结果。如果我们证明了$l(\theta^{(t)})\le l(\theta^{(t+1)})$，也就是说极大似然估计单调增加，那么最终我们会到达最大似然估计的最大值。</p>
<p>感性的说，因为下界不断提高，所以极大似然估计单调增加，那么最终我们会到达最大似然估计的最大值。理性分析的话，就会得到下面的式子：</p>
<script type="math/tex; mode=display">
l(\theta^{(t+1)}) \ge \sum_i\sum_{z^{(i)}}Q_i^{(t)}(z^{(i)})\log \frac{p(x^{(i)},z^{(i)};\theta^{(t+1)})}{Q_i^{(t)}(z^{(i)})}\\
\ge \sum_i\sum_{z^{(i)}}Q_i^{(t)}(z^{(i)})\log \frac{p(x^{(i)},z^{(i)};\theta^{(t)})}{Q_i^{(t)}(z^{(i)})}\\
= l(\theta^{(t)})</script><h2 id="EM算法另一种理解"><a href="#EM算法另一种理解" class="headerlink" title="EM算法另一种理解"></a>EM算法另一种理解</h2><p>坐标上升法（Coordinate ascent）：</p>
<p><img src="/passages/2019-08-02-EM算法专题/EM.jpg" alt="EM"></p>
<p>图中的直线式迭代优化的路径，可以看到每一步都会向最优值前进一步，而且前进路线是平行于坐标轴的，因为<strong>每一步只优化一个变量</strong>。</p>
<p>这类似在x-y坐标系中找一个曲线的极值，然而曲线函数不能直接求导，因此梯度下降的方法就不适用了。但固定一个变量后，另外一个可以通过求导得到，因此可以使用坐标上升法，一次固定一个变量，对另外的求极值，最后逐步逼近极值。对应到EM上，<strong>E步：</strong>固定$\theta$，优化Q；<strong>M步：</strong>固定Q，优化$\theta$；交替将极值推向最大。</p>
<h2 id="EM的应用"><a href="#EM的应用" class="headerlink" title="EM的应用"></a>EM的应用</h2><p>EM算法有很多的应用，最广泛的就是GMM混合高斯模型、聚类、HMM等等。</p>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul>
<li><a href="https://blog.csdn.net/fuqiuai/article/details/79484421" target="_blank" rel="noopener">数据挖掘领域十大经典算法之一EM算法</a></li>
</ul>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>聚类</tag>
      </tags>
  </entry>
  <entry>
    <title>Cross-Relation Cross-Bag Attention for Distantly-Supervised Relation Extraction</title>
    <url>/passages/2019-10-24-Cross-Relation-Cross-Bag-Attention-for-Distantly-Supervised-Relation-Extraction/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>问题：生成的训练数据通常包含大量噪音，可能导致在常规的监督学习中表现不佳。</p>
<p>文本提出一种先进的Cross-relation Cross-bag Selective Attention ($C^2SA$）使得远程监督关系抽取器能够实现噪声鲁棒训练。具体而言，文章采用句子级选择注意力机制减少噪声以及不匹配句子的影响，同时利用关系间的相关性来提高注意权重的质量。此外，代替将所有实体对看作是等价的，文章采用注意力机制关注更高质量的关系对。两种类型关系抽取器证实了本文提出方法的优越性，同时进一步的消融实验也证实了推理与技术的有效性。</p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>为了探索与分类在给定句子中一个实体对的关系，关系抽取（RE）在自然语言理解中扮演着一个至关重要的角色。一般的方法采用完全监督的模式、需要大量的人工标注，这些是高成本且费时的。为了缓解这样的依赖，学者们企图构建远程监督关系提取器，例如使用知识库（KB）自动生成训练数据。</p>
<p>尽管远程监督节省了成本与时间，但是远程监督方法是上下文无关的，因此对于句子级的RE其包含大量噪声。</p>
<p>噪声鲁棒训练模式：多示例学习方法有助于减少噪声增强模型鲁棒性。多示例学习把句子包视为基础的训练示例，每个包中的一组句子被标记为相同的知识库事实。通过包内选择，模型可以更加关注高质量的句子减少对噪音句子关注。Selective Attention企图为句子分配注意力权重之后结合包内所有句子用于训练。</p>
<p><strong>然而，句子级可选择注意力（ATT）独立的生成每种关系类型的权重而忽略了关系类型间的关联。</strong>举例说明一句话反映低质量的die_in关系同时也可能表达了高质量的live_in关系。基于这个问题，文章提出Cross-relation Attention，在考察所有关系类型之间的关系后产生注意力权重。</p>
<p>本文放宽了一个训练实例只包含一个实体对的约束。具体来说，本文提出Cross-bag Attention结合不同的句子包，将这种组合结构称为superbag，并将其作为训练示例代替句子包，这使得我们更加关注高质量的句子包，减少知识库中过时或未表示的信息带来的噪声。</p>
<p>结合两种机制：Cross-relation与Cross-bag两个选择注意力机制是本文的核心部分。</p>
<h1 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h1><p>关系抽取任务，特别是有监督关系抽取任务已经有很多工作，但是大多基于额外的NLP系统获得词法特征。</p>
<p>深度神经网络能够自动学习潜在特征，循环神经网络在2012年被Socher等人使用，2014年起Zeng等人采用端到端卷积神经网络处理关系抽取任务。2016年起Zhou等人使用基于注意力机制的LSTM缓解CNN网络处理大跨度信息效果差的弱点。无论CNN还是RNN，甚至是强化学习都在关系抽取任务中有过应用。</p>
<p>远程监督的出现是为了节约大量标注的成本，而相同实体对的所有句子在同一个包内的多示例学习方法是为了抑制远程监督带来的噪音。选择性注意力机制的提出是为了筛选出包中高质量的句子特征。2017年Luo等人提出了一种基于过渡矩阵的噪音动态表征方法。2018年Feng等人使用强化学习在远程监督数据集上选择一个更可靠的子集并使用它训练分类器。为解决包级别噪音标注问题，Liu等人在2017年采用后验概率约束更正可能不正确的包标签。</p>
<p>本文提出的方法与选择注意力机制的不同主要有两方面：（1）是本文的方法考虑了多重关系之间的相互影响；（2）本文的方法评估了bag feature的质量，并减少袋级噪声标签问题的影响，而现有的选择性注意力当处理一个完全不正确的bag时是没有效果的。</p>
<h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><p>本文模型（$C^{2}SA$）的提出通过考虑关系间的相关性提高句子级注意力的效果，并在另一个注意力层级筛选包级别特征。</p>
<p>如图一所示，关系抽取器包含两个组件：一个神经网络特征抽取器和一个输出层。对于神经网络特征抽取器，它可以抽取有用的特征进行关系分类，并可以使用任何的神经网络结构包括CNN与RNN。基于抽取特征，输出层对关系类型做出预测。模型训练过程整个分为四个步骤：首先为每个句子构建表示。之后，cross-relation选择性注意结合句子表征并生成句子包的表征。相似地，cross-bag选择注意力结合句子包表示生成超级包表示。最终loss基于superbag特征指导关系抽取器学习。</p>
<p><img src="/passages/2019-10-24-Cross-Relation-Cross-Bag-Attention-for-Distantly-Supervised-Relation-Extraction/C2SA.png" alt="C2SA"></p>
<p>通常，神经网络特征抽取器可以被看作是一个神经网络句子编码器，它可以将句子编码成低维、固定长度的向量。本文在介绍方法默认采用CNN网络结构。</p>
<h2 id="输入表示"><a href="#输入表示" class="headerlink" title="输入表示"></a>输入表示</h2><p>encode in an entity-aware manner.预训练词向量，计算到两实体相对位置，位置有对应的位置编码表。位置编码表是随机初始化的并且在整个模型训练过程中进行更新。句子最大长度$m$有限，对于短句子，我们pad其他部分是0。</p>
<h2 id="神经网络特征抽取器"><a href="#神经网络特征抽取器" class="headerlink" title="神经网络特征抽取器"></a>神经网络特征抽取器</h2><p>文章采用piecewise-CNN，由卷积层和分段最大池化层。卷积层，输出结果$c$计算方法如下：</p>
<script type="math/tex; mode=display">
c_{i,j} = P_i \circ C_{j,j+l-1}</script><p>其中$P<em>i$是第i层的卷积核，$l$是核宽，$C</em>{i,j}$是从词$w_i$到$w_j$的滑动窗口来自句子$C$，分段最大池化的使用是考虑了考虑了关系抽取任务具体的情境的，句子根据实体对分割成三部分，分别对每一部分采用最大池化处理，将三部分特征输出并连接，得到特征向量$x_i$，最后应用双曲正切函数处理输出的特征向量$x_i$。</p>
<p><img src="/passages/2019-10-24-Cross-Relation-Cross-Bag-Attention-for-Distantly-Supervised-Relation-Extraction/PCNN.png" alt="PCNN"></p>
<h2 id="输出层"><a href="#输出层" class="headerlink" title="输出层"></a>输出层</h2><p>为计算每个关系的置信度，本文采用线性投影与softmax函数计算条件概率，另外本文采用droput策略防止过拟合。Dropout prevents co-adaptation of hidden units by randomly setting them to zero for a proportion $p$，故输出公式计算如下：</p>
<script type="math/tex; mode=display">
o = W \cdot(f \bigodot h)</script><p>其中，h是随机Bernoulli变量向量使得概率$p$为1。</p>
<h2 id="Cross-relation-Selective-Attention"><a href="#Cross-relation-Selective-Attention" class="headerlink" title="Cross-relation Selective Attention"></a>Cross-relation Selective Attention</h2><p><img src="/passages/2019-10-24-Cross-Relation-Cross-Bag-Attention-for-Distantly-Supervised-Relation-Extraction/cross-relation-attention.png" alt="cross-relation-attention"></p>
<p>其目的旨在减少噪声或错误匹配句子的影响，计算选择注意力基于句子与关系间的相似性：</p>
<script type="math/tex; mode=display">
S_{i,j,k} = \frac{x_{i,j}\cdot r_k}{||x_{i,j}||||r_k||}</script><p>其中$r_k$是注意力参数对应于第k个关系。</p>
<p><img src="/passages/2019-10-24-Cross-Relation-Cross-Bag-Attention-for-Distantly-Supervised-Relation-Extraction/similarity-correlation-matrix.png" alt="similarity-correlation-matrix"></p>
<p>为了捕获关系之间的相关性，我们使用bayes规则计算期望注意权重：</p>
<script type="math/tex; mode=display">
P(j_{th}sentence|k_{th}relation) = \frac{P(k_{th}relation|j_{th}sentence)}{\sum_{\hat j=1}^{n_b}P(k_{th}relation|\hat j_{th}sentence)P(\hat j_{th}sentence)}</script><p>本文假设$P(j<em>{th}sentence)$是均匀分布，采用softmax函数计算$P(k</em>{th}relation|j_{th}sentence)$</p>
<script type="math/tex; mode=display">
P(k_{th}relation|j_{th}sentence) = \frac{e^{S_{i,j,k}}}{\sum_{\hat k=1}^{n_r}e^{S_{i,j,k}}}</script><p>简化概念，定义计算变量$P(k<em>{th}relation|j</em>{th}sentence)$简化为$\alpha<em>{j,k}$，变量$P(j</em>{th}sentence|k<em>{th}relation)$简化为$\beta</em>{j,k}$，因此属于第k个关系的包特征$B_i$可以计算为：</p>
<script type="math/tex; mode=display">
b_{i,k} = \sum_{\hat j=1}^{n_b}\beta_{\hat j,k}x_{i,\hat j}</script><p>cross-relation selective attention不仅仅依赖于目标关系句子的相似性，也依赖于其他关系。例如在下图中$x_2$和$x_4$与$r_1$有相似的相似度，但是$x_4$更倾向于表示$r_3$关系。因此模型倾向于使用$x_2$特征生成bag特征并用此预测$r_1$关系。</p>
<h2 id="Cross-bag-Selective-Attention"><a href="#Cross-bag-Selective-Attention" class="headerlink" title="Cross-bag Selective Attention"></a>Cross-bag Selective Attention</h2><p>句子级注意力机制假设在包中至少一句话表达实体对的某种关系，远程监督在句子包级别存在噪音。可能大量关系对不能发现知识库中给定的表达。这种实体对会导致句子级关系抽取存在不匹配或噪声训练示例。</p>
<p><img src="/passages/2019-10-24-Cross-Relation-Cross-Bag-Attention-for-Distantly-Supervised-Relation-Extraction/cross-bag-attention.png" alt="cross-bag-attention"></p>
<p>处理办法：本文结合几个包含相同关系类型的句子包，将注意力集中到更高质量的部分，定义superbag为$B=\lbrace B<em>1,B_2,…,B</em>{n_s}\rbrace$，其中$n_s$是超级包的大小，所有的$B_i$都由第k个关系类型表示。采用attention layer结合包，公式如下：</p>
<script type="math/tex; mode=display">
f = \sum_{i=1}^{n_s}\gamma_i \cdot b_{i,k}</script><script type="math/tex; mode=display">
\gamma_i = \frac{e^{S(r_k,b_{i,k})}}{\sum_{j=1}^{n_s}e^{S(r_k,b_{j,k})}}</script><p>$S(r<em>k,b</em>{i,k})$即上文提到的余弦相似度计算，$r<em>k$表示注意力参数对应于第j个关系，$b</em>{i,k}$是包的表示对应于$B_i$的第k种关系。</p>
<p>最终模型目标函数训练采用负对数似然实现。</p>
<h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><p>因为$C^2SA$与模型有关，只用于学习阶段，因此本文使用两种类型的神经关系提取器进行实验。使用人工标注的测试库在句子级关系抽取任务上进行实验取得了state-of-the-art结果。进一步采用case study与ablation实验，验证cross-sentence 与cross-bag选择注意力机制的有效性。</p>
<h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>训练集于之前一致使用NYT10作为训练集，53个分类，数据集包含522611个句子，281270实体对与18252知识库事实。</p>
<p>一个实体对表达关系的概率就是最大化这个关系所有包含实体对的句子提及的概率。</p>
<h2 id="baselines"><a href="#baselines" class="headerlink" title="baselines"></a>baselines</h2><ol>
<li><strong>PCNN+ATT：</strong>使用普通的句子级选择注意力结合每个包的句子特征，基于每个包的表示在PCNN模型下训练。</li>
<li><strong>BLSTM+2ATT：</strong>也是使用普通的句子级选择注意力机制，不同于PCNN采用的是BLSTM模型附加一个额外的word-level attention单元。</li>
<li><strong>PCNN+ATT+RL：</strong>整合强化学习改善PCNN+ATT，它采用学习策略选择训练集子集PCNN+ATT模型。</li>
<li><strong>PCNN+ATT+softlabel：</strong>增强PCNN+ATT模型的效果通过使用后验概率约束修正潜在错误包标签。</li>
</ol>
<h3 id="corpus-level-Task"><a href="#corpus-level-Task" class="headerlink" title="corpus-level Task"></a>corpus-level Task</h3><p>本文P-R曲线评估方法采用语料库级关系抽取。</p>
<p>测试集是2007年freebase标注构建的，包含172448句子，96678实体对与1950 知识库事实。</p>
<p><img src="/passages/2019-10-24-Cross-Relation-Cross-Bag-Attention-for-Distantly-Supervised-Relation-Extraction/baselines.png" alt="baselines"></p>
<p>性能比较方面从P-R曲线来看，基于PCNN的方法与基于BLSTM的方法没有明确的区别，尽管baseline方法PCNN效果比BLSTM差但是本文提出的$PCNN+C^2SA$与$BLSTM+C^2SA$相比PCNN更好。</p>
<h3 id="sentence-level-Task"><a href="#sentence-level-Task" class="headerlink" title="sentence-level Task"></a>sentence-level Task</h3><p>与语料库级任务不同，该任务旨在识别特定句子中实体对的关系类型。本质上是将句子表示输入到输出层中并观察预测结果。</p>
<p>在该任务中采用Hoffmann2011年发表文章的数据集，包含395个人工标注结果，相比于corpus-level任务该数据集比较小，但是考虑到人工标注的价值，这项分析是有意义的。</p>
<p>在模型比较方面除了Base的PCNN+ATT与BLSTM+2ATT外还考虑了$C^2SA$的两种变体：$CRSA$和$C^2SA-dot$。其中$CRSA$仅使用cross-relation选择注意机制；$C^2SA-dot$将公式中余弦相似度部分均改为点乘（dot product）。</p>
<p><img src="/passages/2019-10-24-Cross-Relation-Cross-Bag-Attention-for-Distantly-Supervised-Relation-Extraction/sentence-level-performance.png" alt="sentence-level-performance"></p>
<p>实验结果反映了两个重要信息：（1）本文提出的cross-relation与cross-bag对模型效果的提升都有效；（2）余弦相似度代替点乘作为评分函数的一部分是非常有效的。</p>
<h2 id="模块切除研究（Ablation-Study）"><a href="#模块切除研究（Ablation-Study）" class="headerlink" title="模块切除研究（Ablation Study）"></a>模块切除研究（Ablation Study）</h2><p>为证明cross-relation机制的有效性，比较$CRSA$与$ATT$，因为二者均在句子包级别上进行训练。而cross-bag是基于句子包表示的，因此通过比较$CRSA$与$C^2SA$来证明cross-bag的有效性。为保证公平的比较，本文分别对PCNN与BLSTM based方法都进行了Precision-Recall curve评估。</p>
<p><img src="/passages/2019-10-24-Cross-Relation-Cross-Bag-Attention-for-Distantly-Supervised-Relation-Extraction/P-R-curves.png" alt="P-R-curves"></p>
<p>文章说明了PCNNs-based的方法比BLSTMs-based方法效果好很可能是由于不同神经网络特征提取器的特征差异造成的。CNNs模型能够很好地提取句子中反映在特征向量维度上的局部信息（如触发词），这一点导致基于余弦相似度的注意机制具有更好的性能。</p>
<p>另一方面，$C^2SA$与$CRSA$之间的表现差距证实了一些句子包相比其他的有更高的质量。主要说明了模型在superbag level上训练会有更好的鲁棒性，case study实验也是支持这一观点。</p>
<h2 id="Case-Study"><a href="#Case-Study" class="headerlink" title="Case Study"></a>Case Study</h2><h3 id="Noise-of-Distant-Supervision-at-Bag-level"><a href="#Noise-of-Distant-Supervision-at-Bag-level" class="headerlink" title="Noise of Distant Supervision at Bag-level"></a>Noise of Distant Supervision at Bag-level</h3><p>本文随机采样20种不同的NYT数据集中关系类型，随机选择100个实体对构建100个句子包。手工检验它们的质量，这些句子包包含483个句子，句子包的质量效果一般（一般句子级是用于考虑句子内的关系），如下图。</p>
<p><img src="/passages/2019-10-24-Cross-Relation-Cross-Bag-Attention-for-Distantly-Supervised-Relation-Extraction/manually-check.png" alt="manually-check"></p>
<p>从结果上来看，大约31%的句子包甚至没有包含一个正确标注的句子。因此，得出结论如下：应对远程监督的噪声，采用superbag-level进行训练是有价值的。</p>
<h3 id="Effectiveness-of-Cross-bag-Selective-Attention"><a href="#Effectiveness-of-Cross-bag-Selective-Attention" class="headerlink" title="Effectiveness of Cross-bag Selective Attention"></a>Effectiveness of Cross-bag Selective Attention</h3><p>下图显示一个表示关系类型lived_in的superbag，它两个句子包。经过观察发现仅有一个句子正确的标注在第一个句子包中，二第二个句子包所有句子均不匹配知识库反应的关系事实。cross-bag选择注意力允许模型关注更多句子包从而获得更高的质量。</p>
<p><img src="/passages/2019-10-24-Cross-Relation-Cross-Bag-Attention-for-Distantly-Supervised-Relation-Extraction/case-study.png" alt="case-study"></p>
<h1 id="结论与展望"><a href="#结论与展望" class="headerlink" title="结论与展望"></a>结论与展望</h1><p>本文提出cross-relation cross-bag 选择注意力，建立一个实体关系模型有效地学习真实表达关系的特征从包含噪声的远程监督数据中。实验证明所提出的模型能更好的学习高质量的bag feature对比于现存文献。跨包注意力选择机制有助于进一步提升性能通过使用高质量的bag features。</p>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      <categories>
        <category>文献阅读</category>
      </categories>
      <tags>
        <tag>Relation Extraction</tag>
        <tag>AAAI</tag>
      </tags>
  </entry>
  <entry>
    <title>ARNOR：Attention Regularization based Noise Reduction for Distant Supervision Relation Classification</title>
    <url>/passages/2019-10-28-ARNOR/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>（Distant supervision）远程监督的问题在于引入了大量噪声标签，即句子并不能表达标注关系。本文提出ARNOR，一种先进的基于注意力正则化的远程监督关系分类降噪框架。ARNOR假设一个可信关系标注是可被神经网络注意力模型解释的。本文首先引入注意力正则化强迫关注那些可解释关系标签的模式。之后，如果学到的模型能够清晰地定位到训练集中侯选对示例的关系模式，这样我们选择该示例作为可信示例用于下一步的训练。在NYT10上的实验结果，反映ARNOR这个框架在关系分类与去噪两个方面都有很好的效果。</p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>Relation Classification（RC）属于自然语言处理中的基础任务，对于知识库的构建特别重要。RC的目标是识别给定实体对在句子中的关系类型。通常一个关系应该会被一些线索词表达，例如：“was born in” ，<strong>这样的指示词被称为模式patterns。</strong></p>
<p>远程监督带来大量噪声可能很降低RC模型的效果，这可能是因为没有明确的关系模式来识别关系。在2009年Mintz等人说明了远程监督导致超过30%噪声示例。另一方面，由下图所示基于噪声数据，基于注意力机制的神经网络模型经常关注于实体词而忽略了模式。</p>
<p>目前有三种方法处理噪声问题。（1）multi-instance learning，假设同样实体对提及的包中句子至少有一句表达对应标注的关系，在bag-level上效果不错但是sentence-level表现不佳。（2）为了减少句子级预测的噪音，采用强化学习或者对抗生成训练选择可信数据，这一研究路线通过将学习模型的预测标签与远程监督生成的标签相匹配选择置信关系关系标签。但是模型就是从远程监督数据学习的，当模型预测与远程监督生成标签都是错误的情况下模型失效。（3）relation patterns，这种方式在信息抽取中有着广泛的应用，其中典型代表Data programming融合基于远程监督标签与手工标记模式减少噪音。</p>
<p>ARNOR减少噪声基于假设：模型对实力中关系解释得越清楚，示例就越可信。本文首先采用注意力正则化神经网络模型关注关系模式。如果被学习的模型能够从候选示例中发现patterns，本文挑选这些候选作为正确标注数据用于下一步训练，这样两部分相互作用，即模型可解释性越强，选择的训练数据越好，反之亦然。</p>
<p>以前的方法测试集是从训练集中分出来的，因此也是包含噪音的。而本文使用2017年Ren等人提出的测试集做评估，这个数据集也有对应的问题，故本文提出了一个更大更精准的版本。</p>
<p>本文贡献如下：</p>
<ol>
<li>提出了先进的attention regularization方法减少远程监督噪音。</li>
<li>ARNOR框架在去噪与RC表现上效果不错。</li>
<li>发布了一个更好的手工标注的句子级评估关系分类的测试集，包含1024个句子和4543个关系对。</li>
</ol>
<h1 id="ARNOR-Framework"><a href="#ARNOR-Framework" class="headerlink" title="ARNOR Framework"></a>ARNOR Framework</h1><p>ARNOR框架由两部分组成：注意力正则化训练与示例选择。attention regularization的目的是希望模型有定位关系模式的能力，因此被应用于训练模型，迫使模型关注给出的模式词，之后选择示例检查是否模型能够给出远程监督标注的关系一个合理的解释，这两步不断重复 in a booststrap procedure。方法框架如下图所示。</p>
<p>为了捕获识别关系的关键特征词，本文在BILSTM Encoder基础上应用一个注意力机制。输入embeddings包含三个部分：word embedding，position embedding，entity type embedding。本文引入实体类型信息通过实体类型embedding matrix。</p>
<p>后面接一般的注意力机制帮助捕获分类任务重要特征。然而远程监督生成的噪声数据大多关注实体信息而忽略关系分类任务中更有价值的关系模式。</p>
<h2 id="Attention-Regularization"><a href="#Attention-Regularization" class="headerlink" title="Attention Regularization"></a>Attention Regularization</h2><p>给定一个T个词的句子$s = \lbrace x<em>i \rbrace </em>{i=1}^T$，句子中的实体对$(e_1,e_2)$，relation label $y$，relation patterns $m$用来解释$e_1$和$e_2$的关系$y$。我们可以在输入$m$的情况下根据模式提及显著性函数$q(z|s,e_1,e_2,m)$，计算attention guidance value $a^m$。这里$z$表示句子中的模式词，本文希望分类器能够近似注意力分布$a^s=p(z|s)$为$a^m$，其中$p$表示分类器网络。故直观地，本文应用KL散度作为优化函数，描述分布的不同：</p>
<script type="math/tex; mode=display">
KL（a^m||a^s）= \sum a^m \log \frac{a^m}{a^s}</script><p>由于$a^m$含有固定值，所以注意力正则化损失可以表示为：</p>
<script type="math/tex; mode=display">
loss_a = -\sum a^m \log a^s</script><p>本文最终的损失考虑将注意力正则损失加入分类器损失中学习，最终的损失如下：</p>
<script type="math/tex; mode=display">
loss = loss_c+\beta loss_a</script><p>$\beta$是$loss_a$的权重，通常在实验里被设置为1。在本文中采用了一个简单的函数生成$a^m$</p>
<script type="math/tex; mode=display">
b_i =\begin{cases} 
1 & x_i \in \lbrace e1,e2,m\rbrace \\
0 & else
\end{cases}</script><script type="math/tex; mode=display">
a^m =\lbrace \frac{b_k}{\sum_{i=1}^T b_i} \rbrace_{k=1}^T</script><p>$b$表示$x_i$是否属于实体词以及关系模式词。</p>
<h2 id="Instance-Selection-with-Attention"><a href="#Instance-Selection-with-Attention" class="headerlink" title="Instance Selection with Attention"></a>Instance Selection with Attention</h2><p>对于一个训练示例，如果模式关注的关系模式词不能匹配解释关系类型的模式$m$，那么这个示例可能是错误被标记成了正样本。文章仍使用KL散度去度量示例是否是false positive的概率。给定RC模型的注意力权重$a^s$以及计算的模式$a^m$，一个示例的置信度分数$c$归一化得：</p>
<script type="math/tex; mode=display">
c = \frac{1}{1+KL(a^m||a^s)}</script><p>$c$值越高，示例越可信。本文计算训练集中的所有示例并选择示例超过一个阈值$c^t$，其中$c^t$是一个超参数。</p>
<h2 id="Bootstrap-learning-Procedure"><a href="#Bootstrap-learning-Procedure" class="headerlink" title="Bootstrap learning Procedure"></a>Bootstrap learning Procedure</h2><p>在ARNOR框架中，一个重要的问题是怎么获取训练模型中的关系模式$m$以及示例选择步数。在示例选择步骤中，为了选择更可信的数据以及发现更可信的关系模式，需要给定更多种类模式。在模型训练中，给定一个模式抽取器$e$，它可以从示例中抽取一个关系模式；定义一个初始的可信任模式集$m$（它可以用$e$从原始训练数据集$d$计数或是手工收集），本文重复bootstrap procedure操作直到F1分数在验证集上不再增加。bootstrap procedure详细如下：</p>
<h2 id="Relation-Pattern-Extraction"><a href="#Relation-Pattern-Extraction" class="headerlink" title="Relation Pattern Extraction"></a>Relation Pattern Extraction</h2><p>另外一个问题是怎样构建一个关系模式抽取器$E$抽取一个示例中的一个模式。这并非十分重要。即使使用十分简单的模型也能够得到很大的提升。当然复杂且表现良好的抽取器带来了额外的提升。这是本文未来的工作。这里的模式抽取器$E$抽取两实体之间的词。而初始模式集$M$的构建，本文从原始数据集中的所有实例中提取关系模式并进行统计。$M$最初是通过选择初始出现的模式构建的，本文保留每个关系类型的前10%（最大20）模式。</p>
<p>在模式集$M$构建后，数据集$D$将使用这些模式重新分布。所有正示例不匹配那些模式将被放入负样本集，并将他们的关系标签改为”None”。</p>
<h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><h2 id="数据集与评估"><a href="#数据集与评估" class="headerlink" title="数据集与评估"></a>数据集与评估</h2><p>NYT是一个新闻数据集来自294k 1989-2007年纽约时报新闻文章最早于2010年Riedel等人提出的。通过和Freebase对齐的方法虽然没有人工代价但是只能提供大概的估量由于远程监督存在噪声数据。相比之下，Ren等人在2017年发布一个手工标注测试集包含2011年Hoffmann等人提出的395个句子。这个测试集标记一个实体对一句话。测试集仅包含一半的训练集的关系类型。</p>
<p>为了解决这些问题以及评估ARNOR框架更准确，本文标注并发布一个新的句子级测试集在Ren等人工作基础上，也包含标注的命名实体类型。首先，本文修改了最初395个测试句子中错误标注的实例。然后，从原始训练集中抽取约600个句子并删除。之后仔细检查了它们的标签并将它们合并到测试集中。另外，本文还移除了一些重叠和不明确的关系类型，或是太过噪声而无法获得非噪声测试样本的关系类型。</p>
<p>为了评估，本文在句子级及示例级评估模型，句子级预测有助于理解句子任务，例如问答以及语义分析。与常用的bag level评估不同，句子级别评估直接针对数据集中的所有单个实例计算精度（prec.）、召回（rec.）和f1度量。本文认为这样的评估更直观，更适合实际应用。</p>
<h2 id="Baselines"><a href="#Baselines" class="headerlink" title="Baselines"></a>Baselines</h2><h1 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h1><p>本文提出ARNOR，一个基于注意力正则化的远程监督关系分类的降噪框架。本文发现关系模式是一个重要的特征极少被以往的模型在噪声数据方面考虑进去。因此，本文设计注意力正则化帮助模型学习关系模式的定位。对于一个更易于解释的模型，我们通过评估模型对实例关系的解释程度来进行降噪。bootstrap learning procedure构建用于迭代改善模型，训练数据与可信模式集。使用一个非常简单的模式提取器，本文模型的性能优于几个基于RL-based baselines，在关系分类与噪声抑制方面都取得了显著的改进。此外，本文发布了一个更好的手工标注测试集用于句子级评估。</p>
<p>在未来，本文希望通过使用更好的基于模型的模式抽取器，并借助隐变量模型对实例选择器进行联合建模来改进工作。此外，还希望验证方法在更多任务上的有效性，包括开放信息抽取和事件抽取，以及重叠关系抽取模型。</p>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      <categories>
        <category>文献阅读</category>
      </categories>
      <tags>
        <tag>Relation Extraction</tag>
        <tag>ACL</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo与github搭建个人博客</title>
    <url>/passages/hexo/</url>
    <content><![CDATA[<p> <a href="https://github.com/hexojs/hexo" target="_blank" rel="noopener">GitHub</a>个人博客搭建主要有两种方法：一是基于Ruby的jekyll+github方法，二是基于Nodejs的Hexo+github方法。这是本人的第一篇个人博客，希望能够坚持写下去。下面我将介绍下Hexo+github方法的具体过程：</p>
<h2 id="搭建过程"><a href="#搭建过程" class="headerlink" title="搭建过程"></a>搭建过程</h2><h3 id="Hexo安装"><a href="#Hexo安装" class="headerlink" title="Hexo安装"></a>Hexo安装</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ npm install hexo-cli -g</span><br><span class="line">$ npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure>
<p>第一句是安装<a href="https://hexo.io/zh-cn/docs/" target="_blank" rel="noopener">Hexo</a>，第二句是安装Hexo部署到git page的deployer保证与github关联。</p>
<h3 id="主题建站"><a href="#主题建站" class="headerlink" title="主题建站"></a>主题建站</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> your_blog_dir</span><br><span class="line">$ hexo init blog</span><br><span class="line">$ git <span class="built_in">clone</span> https://github.com/dongyuanxin/theme-ad.git themes/ad</span><br></pre></td></tr></table></figure>
<p>安装完成后，根据自己喜好建立目录。Hexo 将会在指定文件夹中新建所需要的文件。之后我们可以在<a href="https://hexo.io/zh-cn/docs/" target="_blank" rel="noopener">Hexo</a>官网上选取主题从Github上clone到本地的themes文件夹下。</p>
<p>针对于不同的主题，blog下的_config.yml需进行如下操作更换主题、与Github关联：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">theme:</span> <span class="string">主题名</span></span><br><span class="line"><span class="attr">deploy:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">git</span></span><br><span class="line">  <span class="attr">repository:</span> <span class="string">git@github.com:nijunssdut/nijunssdut.github.io.git</span></span><br><span class="line">  <span class="attr">branch:</span> <span class="string">master</span></span><br></pre></td></tr></table></figure>
<p>在这里，我们配置Github的SSH密钥可以让本地git项目与远程的github建立联系，让我们在本地写了代码之后直接通过git操作就可以实现本地代码库与Github代码库同步。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> ~/ .ssh</span><br><span class="line">$ ssh-keygen -t rsa -C <span class="string">"your_email@example.com"</span></span><br><span class="line"><span class="comment"># 这将按照你提供的邮箱地址，创建一对密钥</span></span><br><span class="line">$ pbcopy &lt; ~/.ssh/id_rsa.pub</span><br><span class="line"><span class="comment"># 将公钥的内容复制到系统粘贴板</span></span><br></pre></td></tr></table></figure>
<p>之后在Github的Account Settings-SSH Keys中粘贴添加密钥即可。</p>
<p>更多信息详见: <a href="https://blog.csdn.net/grave2015/article/details/79961843" target="_blank" rel="noopener">参考博客</a></p>
<h3 id="配置与测试"><a href="#配置与测试" class="headerlink" title="配置与测试"></a>配置与测试</h3><p>这部分主要介绍Hexo命令的使用。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo clean</span><br><span class="line">$ hexo generate</span><br><span class="line">$ hexo server</span><br><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>hexo clean与hexo generate一般一起使用清理并生成编写内容，执行完hexo server后可在本地使用<a href="https://localhost:4000" target="_blank" rel="noopener">https://localhost:4000</a> 查看建站情况，hexo deploy会更新Github端个人博客的内容：<a href="https://nijunssdut.github.io">Jun的个人主页</a></p>
<h3 id="Markdown写作"><a href="#Markdown写作" class="headerlink" title="Markdown写作"></a>Markdown写作</h3><p>本人使用Mac OS，推荐Typora软件进行Markdown编写。Typora是一款轻便简洁的Markdown编辑器，支持即时渲染技术。</p>
<p>Typora语法相对简单，可参考<a href="https://www.jianshu.com/p/b7fd16a44508" target="_blank" rel="noopener">简书typora</a>、<a href="https://www.cnblogs.com/xupccc/p/9545687.html" target="_blank" rel="noopener">博客园typora</a>。</p>
<h1 id="Hexo博客内容图片显示问题"><a href="#Hexo博客内容图片显示问题" class="headerlink" title="Hexo博客内容图片显示问题"></a>Hexo博客内容图片显示问题</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ npm install eslint</span><br><span class="line">$ npm install hexo-asset-image --save</span><br></pre></td></tr></table></figure>
<p>由于缺少eslint依赖直接安装Hexo图片插件会有警告。完成安装后用hexo新建文章的时候会发现_posts目录下面会多出一个和文章名字一样的文件夹。图片就可以放在文件夹下面。插入图片的方式采用Markdown语法即可。</p>
<p><strong>Note:</strong>把主页配置文件<code>_config.yml</code> 里的<code>post_asset_folder:</code>这个选项设置为<code>true</code></p>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      <categories>
        <category>环境配置</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Github</tag>
      </tags>
  </entry>
  <entry>
    <title>Distant Supervision Relation Extraction with Intra-Bag and Inter-Bag Attentions</title>
    <url>/passages/2020-03-24-Distant-Supervision-Relation-Extraction-with-Intra-Bag-and-Inter-Bag-Attentions/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>​        本文提出了一种神经网络关系抽取方法，用于处理远程监督产生的噪音训练数据。先前的研究主要通过设计具有包内注意力的神经网络，专注于句子级的降噪。本文同时考虑了包内注意力与包间注意力机制，以便分别处理语句级别和包级别的噪音。首先，通过使用包内注意力对句子嵌入进行加权来计算相关示例包的表示。在此，将每个可能的关系用作关注度计算的查询，而不是仅使用常规方法中的目标关系。此外，通过使用基于相似度的包间注意力模块对示例包表示加权来计算训练集中共享相同关系标签的一组示例包的表示。最后，在构建关系提取器时，将一个示例包组用作训练样本。New York Times数据集上的实验结果证明了提出的包间和包内注意力模块的有效性。与该数据集上最新方法相比，其方法具有更好的关系 抽取精度。</p>
<p>​        其开源代码网址为<a href="https://github.com/ZhixiuYe/Intra-Bag-and-Inter-Bag-Attentions，经本人验证略作改动可在CPU环境下复现使用，运行时长约20小时左右。" target="_blank" rel="noopener">https://github.com/ZhixiuYe/Intra-Bag-and-Inter-Bag-Attentions，经本人验证略作改动可在CPU环境下复现使用，运行时长约20小时左右。</a></p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>​        关系抽取是自然语言处理（NLP）中的一项基本任务，其目的是提取实体之间的语义关系。例如，句子“<strong>[Barack Obama]</strong> was born in <strong>[Hawaii]</strong>表示实体对<strong>Barack Obama</strong>和<strong>Hawaii</strong>之间的<strong>bornin</strong>关系。</p>
<p><img src="/passages/2020-03-24-Distant-Supervision-Relation-Extraction-with-Intra-Bag-and-Inter-Bag-Attentions/examples-table1.png" alt="Table1" style="zoom:75%;"></p>
<p>​        常规的关系抽取方法，例如(Zelenko et al., 2002; Culotta and Sorensen, 2004; Mooney and Bunescu, 2006)，都采用监督训练，并且缺乏大规模的手工标记数据。为了解决这个问题，提出了一种远程监督方法（MIntz等，2009），该方法可以自动生成训练关系抽取模型的数据。远程监督假设，如果两个实体参与关系，则提及这两个实体的所有句子都表示该关系。不可避免地，在远程监督标记的数据中会存在噪音。例如，对齐New York Times与Freebase的关系精度只有大约70%。</p>
<p>​        因此，Riedel等人提出的额关系抽取方法认为，远程监督假设额过于强大，因此将其放宽为at-least-once假设。此假设表明，如果两个实体参与关系，则至少一个提及这两个实体的句子可能表示该关系。表1中句子S1和S2显示了一个示例。此关系抽取方法首先将远程监督提供的训练数据划分为多个包，其中每个包是一组包含相同实体对的句子，然后，通过对每个包中的句子进行加权得出包表示。期望减少带有不正确标签语句的权重，并且主要使用带有正确标签的语句来计算包表示。最后，将示例包用作训练关系抽取模型的样本，而非单个语句。</p>
<p>​        近年来，已经提出了许多使用具有注意力机制的神经网络关系抽取方法，以减轻at-least-once假设下的噪音训练数据的影响。然而，这些方法仍然存在两个缺陷。首先，在训练阶段，仅使用每个示例包的目标关系来计算注意力权重，以从句子嵌入中得出多示例包表示。在这里，本论文认为，应当以一种关系感知的方式来计算包的表示形式。例如，表1中的示例包B1中包含两个句子S1和S2。当此包被分类为BornIn关系时，句子S1的权重应高于S2，但当分类关系为关系PresidentOf时，S2的权重应更高。其次，at-least-once假设忽略了嘈杂的包问题，这意味着一个包内所有语句都被错误地标记，表1中的袋子B2显示了这样的一个示例。</p>
<p>​        为解决现有方法的两个不足，本文提出了一种多层次注意力的神经网络用于远程监督关系抽取。在实例/句子级别，即包内层次，所有可能的关系都被用作查询来计算关系感知的包表示，而不是使用每个包的目标关系。为了解决嘈杂的示例包问题，采用多示例包组作为训练样本，而不是单个包。在这里，一个多示例包组由训练集中共享相同关系标签的包组成。使用基于相似度的包间注意力模块通过对包表示的加权来计算多示例包组的表示。</p>
<p>​        本文的贡献包含三部分。首先，提出了一种改进的包内注意力机制，以导出用于关系抽取的关系感知的包表示。其次，引入包间注意力模块来处理嘈杂的包问题，该问题被at-least-once假设所忽略。第三，本文提出的方法比相同数据集上的最新模型具有更高的抽取精度。</p>
<h1 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h1><p>​        先前的一些工作将关系提取视为一种有监督的学习任务，并设计了手工制作的特征来训练基于内核的模型。由于缺乏大规模的人工标注数据用于监督训练，提出了远程监督方法，该方法将原始文本自动对齐到知识库中，生成实体对的关系标签。然而，这种方法受到了标签噪音问题的困扰。因此，随后的一些研究将远程监督关系抽取看作是一个多示例学习问题，从一个句子集中提取关系，而不是从单个句子中提取关系。</p>
<p>​        随着深度学习技术的额发展，已经开发了许多基于神经网络的远程监督关系抽取模型。Zeng等人提出了分段卷积神经网络来建模句子表示，并选择最可靠的语句作为包表示。Lin等人采用PCNN作为句子编码，提出了一种包内注意力机制，通过包内所有语句表示的加权和计算包表示。Ji等人采用相似的注意力策略，并结合实体描述来计算权重。Liu等人提出一种软标签方法来减少嘈杂实例的影响。所有这些方法都用一个加权的语句嵌入总和表示一个示例包，并在训练阶段使用相同的包表示计算包被分类到每个关系中的概率。在本论文提出的方法中，包内注意是以一种关系感知的方式计算的，这意味着不同的包表示被用来计算不同关系类型的概率。此外，这些现有的方法主要集中在包内注意，忽略了嘈杂的多示例包问题。</p>
<p>​        还有一些鲁棒的远程监督关系抽取数据过滤策略被提出。Feng等人与Qin等人均采用强化学习训练实例选择器，并过滤出标签错误的样本。他们分别根据关系分类器的预测概率和性能变化来计算模型的奖惩。Qin等人设计了一个对抗性学习过程，通过基于策略梯度的强化学习来构建句子级生成器。这些方法都是在句子级过滤掉有噪声的数据，也不能很好地处理有噪声的多示例包问题。</p>
<h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><p>​        在本小节中，本论文介绍了一个带有包内和包间注意力机制的神经网络用于远程监督关系抽取。让$g=\lbrace b^1,b^2,…,b^n\rbrace$代表一组具有远程监督给出的额相同关系标签的包，以及$n$组内包的个数。让$b^i=\lbrace x^i<em>1,x^i_2,…,x^i</em>{m<em>i}\rbrace$代表示例包$b^i$内所有句子，并且$m_i$表示$b^i$包内句子数。让$x^i_j=\lbrace w^i</em>{j1},w^i<em>{j2},…w^i</em>{jl<em>{ij}}\rbrace$表示在第$i$个包内第$j$个句子，并且$l</em>{ij}$是它的长度（即，词的数量）。模型框架如图1中所示，共有三个主要模块。</p>
<ul>
<li>句子编码器：给定一个句子$x^i_j$和在这个句子中两个实体的位置，采用CNN或PCNN推导句子表征$s^i_j$。</li>
<li>包内注意力机制：给定在$b^i$包内所有句子的句子表示和一个关系嵌入矩阵$R$，注意力权重向量$\alpha^i_k$与包表示$b^i_k$由所有关系计算得到，其中$k$是关系索引。</li>
<li>包间注意力机制：在给定g组的所有包的表示的情况下，通过基于相似度的注意机制进一步计算权重矩阵$\beta$，得到包组的表示。</li>
</ul>
<p><img src="/passages/2020-03-24-Distant-Supervision-Relation-Extraction-with-Intra-Bag-and-Inter-Bag-Attentions/Fig1.jpg" alt="Fig1" style="zoom:75%;"></p>
<h2 id="句子编码器"><a href="#句子编码器" class="headerlink" title="句子编码器"></a>句子编码器</h2><h3 id="单词表示"><a href="#单词表示" class="headerlink" title="单词表示"></a>单词表示</h3><p>​        在句子$x^i<em>j$中每个单词$w^i</em>{jk}$首先映射到一个$d<em>w$维度的单词嵌入。为了描述两个实体的位置信息，本文还采用了Zeng等人提出的位置特征（PFs）。对于每个单词，PFs描述当前词和两个实体之间的相对距离，并进一步映射到两个$d_p$维度向量$p^i</em>{jk}$和$q^i<em>{jk}$。最终，这些三个向量被连接得到$d_w+2d_p$维度的词向量$w</em>{jk}^i=[e<em>{jk}^i;p</em>{jk}^i;q_{jk}^i]$。</p>
<h3 id="分段卷积"><a href="#分段卷积" class="headerlink" title="分段卷积"></a>分段卷积</h3><p>​        对于句子$x^i<em>j$，单词表示矩阵$W^i_j \in R^{l</em>{ij}\times(d_w+2d_p)}$首先使用$d_c$维度的过滤器输入到CNN中。之后，使用分段最大池化从CNN输出的三个部分中提取特征，并且分段边界由两个实体的位置信息决定。最终句子表示$s^i_j \in R^{3d_c}$可获得。</p>
<h2 id="包内注意力机制"><a href="#包内注意力机制" class="headerlink" title="包内注意力机制"></a>包内注意力机制</h2><p>让$S^i \in R^{m_i\times 3d_c}$表示$b^i$包内所有的句子表示，并且$R \in R^{h \times 3d_c}$代表一个关系嵌入矩阵，其中$h$是关系的数量。</p>
<p>与传统方法不同的是，本论文的方法为关系分类导出了统一的包表示，本论文的方法计算包表示$b^i_k$为包$b^i$在所有可能关系的条件下为：</p>
<script type="math/tex; mode=display">
b^k_i=\sum_{j=1}^{m_i}\alpha^i_{kj}s^i_j</script><p>其中$k\in \lbrace 1,2,…,h \rbrace$是关系索引并且$a^i<em>{kj}$是$b^i$包内第$k$个关系与第$j$个句子之间的注意力权重。$\alpha^i</em>{kj}$能够进一步定义为：</p>
<script type="math/tex; mode=display">
\alpha^i_{kj} = \frac {exp(e^i_{kj})}{ \sum^{m_i}_{ j^{'}=1 } exp(e^i_{ kj^{'} })}</script><p>​        </p>
<p>其中$e^i_{kj}$是包$b^i$中第$k$个关系查询和第$j$个句子之间的匹配度。在本论文的实现中，采用向量之间的简单点积来计算匹配度为：</p>
<script type="math/tex; mode=display">
e^i_{kj}=r_ks^{i^T}_j</script><p>其中$r_k$是关系嵌入矩阵$R^2$的第k行。</p>
<p>​        最终，包$b^i$的表示组成图1中的矩阵$B^i \in R^{h\times 3d_c}$，其中每一行对应这个多示例包的一个可能的关系类型。</p>
<h2 id="包间注意力机制"><a href="#包间注意力机制" class="headerlink" title="包间注意力机制"></a>包间注意力机制</h2><p>​        为了解决含噪示例包问题，设计了一个基于相似度的包内注意力模块，动态降低带有噪音包的权重。直观上，如果两个包$b^{i1}$和$b^{i2}$都标记为关系k，他们的表示$b^{i_1}_k$与$b^{i_2}_k$应当相互接近。给定一组具有相同关系标签的包，论文将更高的权重分配给与该组中其他示例包相近的包，因此，包组$g$的表示形式可以公式化为：</p>
<script type="math/tex; mode=display">
g_k= \sum_{i=1}^n \beta_{ik}b^i_{k}</script><p>​        其中$g<em>k$是图1中矩阵$G \in R^{h \times3d_c}$的第k行，$k$是关系索引，并且$\beta</em>{ik}$组成了注意力权重矩阵$\beta \in R^{n\times h}$，每一个$B_{ik}$被定义为：</p>
<script type="math/tex; mode=display">
\beta_{ik}=\frac{exp(\gamma_{ik})}{\sum^{n}_{i=1}exp(\gamma_{ik})}</script><p>其中，$\gamma_{ik}$描述了标注示例包$b^i$带有第$k$个关系的置信度。</p>
<p>​        受自注意力算法的启发，该算法使用向量本身计算一组向量的注意权重，本论文根据它们自身的表示来计算行李的权重。数学上，$\gamma_{ik}$被定义为</p>
<script type="math/tex; mode=display">
\gamma_{ik} = \sum_{i^{'}=1,..,n,i^{'} \not=i}similarity(b^i_k,b^{i^{'}}_k)</script><p>在他们的实现中，函数相似性是一个简单的点积。</p>
<script type="math/tex; mode=display">
similarity(b^i_k,b^{i^{'}}_k)=b^i_k,b^{i^{'}T}_k</script><p>而且，为了防止向量长度的影响，所有包表示$b^i_k$标准化为单位长度$\overline{b^i_k}=b^i_k/||b^i_k||_2$在计算包间注意力前。</p>
<p>​        之后，将包组$g$分类为关系$k$的得分$o<em>{k}$通过$g</em>{k}$和关系嵌入$r_{k}$计算为</p>
<script type="math/tex; mode=display">
o_{k}=r_{k}g_{k}^T+d_k</script><p>其中$d_k$是一个偏倚项。最后，使用softmax函数来获得包组$g$被归类为第$k$个关系：</p>
<script type="math/tex; mode=display">
p(k|g) =\frac{exp(o_{k})}{\sum^{h}_{k^{'}=1}exp(o_{k^{'}})}</script><p>需要注意的是，公式的计算使用了相同的关系嵌入矩阵$R$。类似于Lin等人，dropout策略被应用于包表示$B^{i}$以防止过拟合。</p>
<h2 id="实现详情"><a href="#实现详情" class="headerlink" title="实现详情"></a>实现详情</h2><h3 id="数据打包"><a href="#数据打包" class="headerlink" title="数据打包"></a>数据打包</h3><p>首先，训练集中包含相同两个实体的所有句子都被累积到一个包中。然后，将共享相同关系标签的每$n$个包捆绑在一起。应当注意的是，在该论文的方法中，包组是一个训练样本。因此，也可以通过将多个包打包成一个批量，以小批量的方式训练模型。</p>
<h3 id="目标函数与优化"><a href="#目标函数与优化" class="headerlink" title="目标函数与优化"></a>目标函数与优化</h3><p>在论文的实现中，目标函数被定义为：</p>
<script type="math/tex; mode=display">
J(\theta) = -\sum_{(g,k)\in T}logp(k|g;\theta)</script><p>其中，$T$是所有训练样本的集合，$\theta$是模型参数的集合，包括词嵌入矩阵，位置特征嵌入矩阵，CNN权重矩阵和关系嵌入矩阵。通过小批量随机梯度下降（SGD）最小化目标函数$J(\theta)$来估算模型参数。</p>
<h3 id="训练与测试"><a href="#训练与测试" class="headerlink" title="训练与测试"></a>训练与测试</h3><p>如上所述，在本文提出的方法的训练阶段，将具有相同关系标签的n个包累积到一个包组中，并计算包表示的加权总和已获得包组的表示$G$。由于每个包的标签在测试阶段都是未知的，因此在处理测试集时将每个单个包视为一个包组（即，$n=1$）</p>
<p>而且，类似于Qin等人的方法，该论文仅将包间注意应用于阳性样本，即关系标签不是NA的包。原因是么没有关系的示例包的表示总是多种多样的，很难为它们计算合适的权重。</p>
<h3 id="预训练策略"><a href="#预训练策略" class="headerlink" title="预训练策略"></a>预训练策略</h3><p>在方法的实施中，采用了与训练策略。该论文首先只训练包内注意力模型，直到收敛为止。然后，添加包间注意模块，并进一步更新模型参数，直到再次收敛。初步的实验结果表明，与从一开始就考虑包间注意相比，这种策略可以带来更好的模型性能。</p>
<h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><h2 id="数据集与评估指标"><a href="#数据集与评估指标" class="headerlink" title="数据集与评估指标"></a>数据集与评估指标</h2><p>实验采用了NYT数据集。该数据集由Riedel等人首次发布，并已广泛用于之前的远程监督关系抽取研究中。这个数据集是通过将Freebase与NYT的语料库自动对其生成的，共有52个实际关系和一个特殊关系NA，表明两个实体之间没有关系。</p>
<p>在先前的研究之后，本论文在held out数据集测试集上评估模型。在他们的实验中，采用了精确率-召回率曲线，曲线下的面积值（AUC）与Precision@N值作为评估指标。他们的实验给出的所有数值结果都是10次重复训练的平均值，并且从重复中随机选择P-R曲线，因为它们之间没有明显的视觉差异。</p>
<h2 id="训练细节与超参数"><a href="#训练细节与超参数" class="headerlink" title="训练细节与超参数"></a>训练细节与超参数</h2><p>表2列出了实验中使用的所有超参数。其中，大多数遵循Lin等人的参数设置。初始化也采用了由Lin等人发布的50维单词嵌入。这些词汇包含了New York Times语料库中出现过100多次的词汇。</p>
<p><img src="/passages/2020-03-24-Distant-Supervision-Relation-Extraction-with-Intra-Bag-and-Inter-Bag-Attentions/Table2.jpg" alt="Table2" style="zoom:75%;"></p>
<p>两种不同批次大小$N<em>p$和$N_t$分别用于预训练和训练。在该论文的实验中，使用训练集进行网格搜索，以确定$n$,$N</em>{p}$和$N<em>t$在范围$n \in \lbrace 3,4,…,10\rbrace$，$N_p \in \lbrace 10,20,50,100,200 \rbrace$和$N</em>{t} \in \lbrace 5,10,20,50 \rbrace$。请注意，增加包组大小$n$可能会增强包间注意的效果，但会减少训练样本的数量。当$n=1$时，将失去包内注意的影响。为了进行优化，该论文采用了初始学习率为0.1的小批量SGD。学习速度每100000步下降到十分之一。在实验中，仅具有包内注意的预训练模型收敛在300000步以内。因此，用于训练袋间注意的模型的初始学习率设置为0.001。</p>
<h2 id="整体表现"><a href="#整体表现" class="headerlink" title="整体表现"></a>整体表现</h2><p>实现了8个模型进行比较。表3列出了这些模型的名称，其中CNN和PCNN分别表示在句子编码器中使用CNN或分段CNN，ATT-BL表示Lin等人提出的基线包内注意方法，ATT-RA表示本论文提出的基于关系的包内注意方法，BAG-ATT表示本论文提出的包间注意方法。在ATT-BL方法的训练阶段，用于注意权重计算的关系查询向量被固定为与每个包的远程监督标签关联的嵌入向量。在测试阶段，应用所有关系查询向量分别计算关系的后验概率，并选择概率最高的关系作为分类结果。这些模型的整个P-R曲线给出的AUC值的平均值和标准差如表3中所示，以进行定量比较。随后，本论文还在图2和图3中绘制了这些模型的P-R曲线，其召回率小于0.5以进行可视化比较。</p>
<p><img src="/passages/2020-03-24-Distant-Supervision-Relation-Extraction-with-Intra-Bag-and-Inter-Bag-Attentions/Fig2-Fig3.jpg" alt="Fig2-Fig3" style="zoom:75%;"></p>
<p><img src="/passages/2020-03-24-Distant-Supervision-Relation-Extraction-with-Intra-Bag-and-Inter-Bag-Attentions/Table3.jpg" alt="Table3" style="zoom:75%;"></p>
<p>从表3，图2和图3，本论文有以下观察结论：（1）与先前的Zeng等人研究成果相似，PCNN作为句子编码器比CNN更好。（2）使用CNN或PCNN句子编码器时，ATT-RA的性能均优于ATT-BL。这可以归因于ATT-BL方法在训练时推导包表示时只考虑了目标关系，而ATT-RA方法则使用所有关系嵌入作为查询来计算包内注意权重，从而提高了包表示的灵活性。（3）对于句子编码和两种包内注意方法，使用BAG-ATT的模型总是比不使用BAG-ATT的模型有更好的性能，这一结果验证了本论文提出的包间注意方法在远程监督关系提取中的有效性。（4）将PCNN句子编码器于本文提出的包内和包间注意相结合，可以获得最佳的AUC性能。</p>
<h2 id="与以往工作的比较"><a href="#与以往工作的比较" class="headerlink" title="与以往工作的比较"></a>与以往工作的比较</h2><h3 id="P-R曲线"><a href="#P-R曲线" class="headerlink" title="P-R曲线"></a>P-R曲线</h3><p>图4比较了先前工作中的几种模型和本论文的最佳模型PCNN+ATT-RA+BAG-ATT的P-R曲线，其中MIntz、MultiR和MIMLRE是常规基于特征的方法，以及Lin等人和Liu等人是基于PCNN的方法。为了与Lin等人和Liu等人进行公平比较，该论文还绘制了仅具有前2000个点的曲线。可以看到，本论文的模型取得了比所有其他模型都具有更好的P-R性能。</p>
<p><img src="/passages/2020-03-24-Distant-Supervision-Relation-Extraction-with-Intra-Bag-and-Inter-Bag-Attentions/Fig4.jpg" alt="Fig4" style="zoom:75%;"></p>
<h3 id="AUC值"><a href="#AUC值" class="headerlink" title="AUC值"></a>AUC值</h3><p>ATT-BL+DSGAN（QIn等人）和ATT-BL+RL（QIn等人）是近年来两个基于强化学习的数据过滤远程监督关系抽取的研究，报告了由前2000个点组成的P-R曲线的AUC值。表5比较了这两篇论文中报告的AUC值和本论文提出的模型的结果。可以看到，将所提出的ATT-RA和BAG-ATT方法引入到基线模型中比使用所提出的方法取得了更大的改进。</p>
<p><img src="/passages/2020-03-24-Distant-Supervision-Relation-Extraction-with-Intra-Bag-and-Inter-Bag-Attentions/Table5.jpg" alt="Table5" style="zoom:75%;"></p>
<h2 id="包内注意力的影响"><a href="#包内注意力的影响" class="headerlink" title="包内注意力的影响"></a>包内注意力的影响</h2><p>继Lin等人之后，该论文同样使用一个以上的训练句子来评估实体对模型。随机抽取每个测试实体对的1，2和所有句子，构建3个新的测试集。表2列出了这三个测试集上该论文提出的模型给出P@100、P@200、P@300值及其平均值，以及Lin等人和Liu等人的最佳结果。这里P@N是指关系分类结果的精度，在测试集中，前N个最高概率值。</p>
<p><img src="/passages/2020-03-24-Distant-Supervision-Relation-Extraction-with-Intra-Bag-and-Inter-Bag-Attentions/Table4.jpg" alt="Table4" style="zoom:75%;"></p>
<p>可以看到该论文提出的方法比以前的工作获得了更高的P@N值。此外，无论采用PCNN还是BAG-ATT或是ATT-RA方法在每个实体对只有一个句子的测试集上的表现均优于ATT-BL方法。注意，当包中只有一个句子时，ATT-BL和ATT-RA的解码过程是等价的。因此，从ATT-BL到ATT-RA的改进可以归因于ATT-RA在训练阶段以关系感知的方式计算了包内注意力权重。</p>
<h2 id="包间注意的权重分布"><a href="#包间注意的权重分布" class="headerlink" title="包间注意的权重分布"></a>包间注意的权重分布</h2><p>本论文根据每个包内的句子数将训练集分成5部分。对于每个包，记录由PCNN+ATT-RA+BAG-ATT模型给出的包间注意力权重。然后，计算训练集各部分的注意权重平均值和标准差，如表7所示。从这个表中我们可以看出，训练句子数较少的包通常被分配较低的包间注意权重。这一结果与Qin等人的发现一致，即训练句子较少的实体对更具有可能具有不正确的关系标签。</p>
<p><img src="/passages/2020-03-24-Distant-Supervision-Relation-Extraction-with-Intra-Bag-and-Inter-Bag-Attentions/Table7.jpg" alt="Table7" style="zoom:75%;"></p>
<h2 id="案例分析"><a href="#案例分析" class="headerlink" title="案例分析"></a>案例分析</h2><p>关系“/location/location/contains”的一个测试集示例如表6所示。包组中包括3个多示例包，分别由2句子、1句子和2句子组成。本论文使用PCNN+ATT-RA+BAG-ATT模型计算了该包组的包内和包间注意，目标关系的权重也显示在表6中。</p>
<p><img src="/passages/2020-03-24-Distant-Supervision-Relation-Extraction-with-Intra-Bag-and-Inter-Bag-Attentions/Table6.jpg" alt="Table6" style="zoom:75%;"></p>
<p>在本例中，第二个包是一个嘈杂的包，因为该包中的唯一一句话没有表示两个实体<strong>Naugatuck</strong>和<strong>Connecticut</strong>之间的“/location/location/contains”关系。在传统的训练方法中，这三个包被同等对待。引入包间注意机制后，如表6最后一列所示，该噪声包的权重显著降低。</p>
<h1 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h1><p>​        在本文中，提出了一种具有包间和包内注意力的神经网络，以解决远程监管关系提取中的嘈杂句子和嘈杂包问题。 首先，通过句子嵌入的加权总和来计算关系感知包表示，其中嘈杂的句子预期具有较小的权重。 此外，包间注意模块被设计为通过在模型训练期间动态计算示例包级注意权重来处理嘈杂的袋问题。 New York Times数据集上的实验结果表明，与仅使用常规包内注意力的模型相比，他们的模型取得了显著且一致的改进。 处理关系抽取的多标签问题并将外部知识集成到模型中将是他们未来工作的任务。</p>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      <categories>
        <category>文献阅读</category>
      </categories>
      <tags>
        <tag>Relation Extraction</tag>
        <tag>AAAI</tag>
      </tags>
  </entry>
  <entry>
    <title>算法之路</title>
    <url>/passages/%E7%AE%97%E6%B3%95%E4%B9%8B%E8%B7%AF/</url>
    <content><![CDATA[<blockquote class="pullquote mindmap mindmap-md"><ul>
<li>算法之路<ul>
<li>基础知识<ul>
<li>机器学习</li>
<li>深度学习</li>
<li>模型评估</li>
<li>数学基础</li>
</ul>
</li>
<li>搜索推荐<ul>
<li>特征工程<ul>
<li>用户特征<ul>
<li>基础画像</li>
<li>实时特征（客户端提供）</li>
<li>准实时特征（流式处理）</li>
<li>离线特征</li>
</ul>
</li>
<li>物料特征</li>
<li>场景特征   </li>
</ul>
</li>
<li>召回 <ul>
<li>索引召回</li>
<li>向量召回<ul>
<li>双塔模型<ul>
<li>单兴趣模型</li>
<li>多兴趣模型</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>粗排<ul>
<li>双塔模型</li>
<li>三塔模型</li>
</ul>
</li>
<li>精排<ul>
<li>独立建模</li>
<li>融合建模</li>
</ul>
</li>
<li>重排</li>
<li>混排</li>
<li>相关性分档/打分</li>
</ul>
</li>
</ul>
</li>
</ul>
</blockquote><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      <tags>
        <tag>大纲</tag>
      </tags>
  </entry>
</search>
